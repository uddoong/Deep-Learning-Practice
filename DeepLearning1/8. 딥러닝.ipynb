{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd2c7eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from common.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3992fb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim=(1,28,28)\n",
    "conv_param_1 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1}\n",
    "conv_param_2 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1}\n",
    "conv_param_3 = {'filter_num':32, 'filter_size':3, 'pad':1, 'stride':1}\n",
    "conv_param_4 = {'filter_num':32, 'filter_size':3, 'pad':2, 'stride':1}\n",
    "conv_param_5 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1}\n",
    "conv_param_6 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1}\n",
    "hidden_size=50\n",
    "output_size=10\n",
    "\n",
    "pre_node_nums = np.array([1*3*3, 16*3*3, 16*3*3, 32*3*3, 32*3*3, 64*3*3, 64*4*4, hidden_size])\n",
    "weight_init_scales = np.sqrt(2.0 / pre_node_nums)\n",
    "\n",
    "params = {}\n",
    "pre_channel_num = input_dim[0]\n",
    "\n",
    "for idx, conv_param in enumerate([conv_param_1, conv_param_2, conv_param_3, conv_param_4, conv_param_5, conv_param_6]):\n",
    "    params[f'W{idx + 1}'] = weight_init_scales[idx] * np.random.randn(conv_param['filter_num'], pre_channel_num, conv_param['filter_size'], conv_param['filter_size'])\n",
    "    params[f'b{idx + 1}'] = np.zeros(conv_param['filter_num'])\n",
    "    \n",
    "    pre_channel_num = conv_param['filter_num']\n",
    "\n",
    "params['W7'] = weight_init_scales[6] * np.random.randn(64*4*4, hidden_size)\n",
    "params['b7'] = np.zeros(hidden_size)\n",
    "params['W8'] = weight_init_scales[7] * np.random.randn(hidden_size, output_size)\n",
    "params['b8'] = np.zeros(output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bfc41284",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepConvNet:\n",
    "    def __init__(self, input_dim=(1,28,28),\n",
    "                conv_param_1 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                conv_param_2 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                conv_param_3 = {'filter_num':32, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                conv_param_4 = {'filter_num':32, 'filter_size':3, 'pad':2, 'stride':1},\n",
    "                conv_param_5 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                conv_param_6 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                hidden_size=50, output_size=10):\n",
    "        \n",
    "        pre_node_nums = np.array([1*3*3, 16*3*3, 16*3*3, 32*3*3, 32*3*3, 64*3*3, 64*4*4, hidden_size])\n",
    "        weight_init_scales = np.sqrt(2.0 / pre_node_nums)\n",
    "        \n",
    "        self.params = {}\n",
    "        pre_channel_num = input_dim[0]\n",
    "\n",
    "        for idx, conv_param in enumerate([conv_param_1, conv_param_2, conv_param_3, conv_param_4, conv_param_5, conv_param_6]):\n",
    "            self.params[f'W{idx + 1}'] = weight_init_scales[idx] * np.random.randn(conv_param['filter_num'], pre_channel_num, conv_param['filter_size'], conv_param['filter_size'])\n",
    "            self.params[f'b{idx + 1}'] = np.zeros(conv_param['filter_num'])\n",
    "            pre_channel_num = conv_param['filter_num']\n",
    "            \n",
    "        self.params['W7'] = weight_init_scales[6] * np.random.randn(64*4*4, hidden_size)\n",
    "        self.params['b7'] = np.zeros(hidden_size)\n",
    "        self.params['W8'] = weight_init_scales[7] * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b8'] = np.zeros(output_size)\n",
    "        \n",
    "        \n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'], conv_param_1['stride'], conv_param_1['pad'])\n",
    "        self.layers['ReLU1'] = Relu()\n",
    "\n",
    "        self.layers['Conv2'] = Convolution(self.params['W2'], self.params['b2'], conv_param_2['stride'], conv_param_2['pad'])\n",
    "        self.layers['ReLU2'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "\n",
    "        self.layers['Conv3'] = Convolution(self.params['W3'], self.params['b3'], conv_param_3['stride'], conv_param_3['pad'])\n",
    "        self.layers['ReLU3'] = Relu()\n",
    "\n",
    "        self.layers['Conv4'] = Convolution(self.params['W4'], self.params['b4'], conv_param_4['stride'], conv_param_4['pad'])\n",
    "        self.layers['ReLU4'] = Relu()\n",
    "        self.layers['Pool2'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "\n",
    "        self.layers['Conv5'] = Convolution(self.params['W5'], self.params['b5'], conv_param_5['stride'], conv_param_5['pad'])\n",
    "        self.layers['ReLU5'] = Relu()\n",
    "\n",
    "        self.layers['Conv6'] = Convolution(self.params['W6'], self.params['b6'], conv_param_6['stride'], conv_param_6['pad'])\n",
    "        self.layers['ReLU6'] = Relu()\n",
    "        self.layers['Pool3'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "\n",
    "        self.layers['Affine1'] = Affine(self.params['W7'], self.params['b7'])\n",
    "        self.layers['ReLU7'] = Relu()\n",
    "        self.layers['Dropout1'] = Dropout(0.5)\n",
    "\n",
    "        self.layers['Affine2'] = Affine(self.params['W8'], self.params['b8'])\n",
    "        self.layers['Dropout2'] = Dropout(0.5)\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x, train_flg=False):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Dropout):\n",
    "                x = layer.forward(x, train_flg)\n",
    "            else:\n",
    "                x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x, train_flg=True)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "\n",
    "        acc = 0.0\n",
    "\n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx, train_flg=False)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt)\n",
    "\n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        tmp_layers = self.layers.copy()\n",
    "        tmp_layers.reverse()\n",
    "        for layer in tmp_layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
    "            grads[f'W{i+1}'] = self.layers[layer_idx].dW\n",
    "            grads[f'W{i+1}'] = self.layers[layer_idx].db\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
    "            self.layers[layer_idx].W = self.params[f'W{i+1}']\n",
    "            self.layers[layer_idx].b = self.params[f'b{i+1}']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d81b41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "669170c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.mnist import load_mnist\n",
    "from common.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61a5c5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "243169f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'forward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bp/f4_wyqts1wq7j3vmy_06yxxc0000gn/T/ipykernel_9498/1968303953.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m trainer = Trainer(network, x_train, t_train, x_test, t_test, epochs=20, mini_batch_size=100, optimizer='Adam',\n\u001b[1;32m      3\u001b[0m        optimizer_param={'lr': 0.0001}, evaluate_sample_num_per_epoch=1000)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/DeepLearningFromScratch/deep-learning-from-scratch-master/ch08/../common/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepLearningFromScratch/deep-learning-from-scratch-master/ch08/../common/trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mt_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bp/f4_wyqts1wq7j3vmy_06yxxc0000gn/T/ipykernel_9498/1247433336.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bp/f4_wyqts1wq7j3vmy_06yxxc0000gn/T/ipykernel_9498/1247433336.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_flg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bp/f4_wyqts1wq7j3vmy_06yxxc0000gn/T/ipykernel_9498/1247433336.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, train_flg)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_flg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'forward'"
     ]
    }
   ],
   "source": [
    "network = DeepConvNet()\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test, epochs=20, mini_batch_size=100, optimizer='Adam',\n",
    "       optimizer_param={'lr': 0.0001}, evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d54ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepConvNet:\n",
    "    \"\"\"정확도 99% 이상의 고정밀 합성곱 신경망\n",
    "\n",
    "    네트워크 구성은 아래와 같음\n",
    "        conv - relu - conv- relu - pool -\n",
    "        conv - relu - conv- relu - pool -\n",
    "        conv - relu - conv- relu - pool -\n",
    "        affine - relu - dropout - affine - dropout - softmax\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28),\n",
    "                 conv_param_1 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_2 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_3 = {'filter_num':32, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_4 = {'filter_num':32, 'filter_size':3, 'pad':2, 'stride':1},\n",
    "                 conv_param_5 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_6 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 hidden_size=50, output_size=10):\n",
    "        # 가중치 초기화===========\n",
    "        # 각 층의 뉴런 하나당 앞 층의 몇 개 뉴런과 연결되는가（TODO: 자동 계산되게 바꿀 것）\n",
    "        pre_node_nums = np.array([1*3*3, 16*3*3, 16*3*3, 32*3*3, 32*3*3, 64*3*3, 64*4*4, hidden_size])\n",
    "        wight_init_scales = np.sqrt(2.0 / pre_node_nums)  # ReLU를 사용할 때의 권장 초깃값\n",
    "        \n",
    "        self.params = {}\n",
    "        pre_channel_num = input_dim[0]\n",
    "        for idx, conv_param in enumerate([conv_param_1, conv_param_2, conv_param_3, conv_param_4, conv_param_5, conv_param_6]):\n",
    "            self.params['W' + str(idx+1)] = wight_init_scales[idx] * np.random.randn(conv_param['filter_num'], pre_channel_num, conv_param['filter_size'], conv_param['filter_size'])\n",
    "            self.params['b' + str(idx+1)] = np.zeros(conv_param['filter_num'])\n",
    "            pre_channel_num = conv_param['filter_num']\n",
    "        self.params['W7'] = wight_init_scales[6] * np.random.randn(64*4*4, hidden_size)\n",
    "        self.params['b7'] = np.zeros(hidden_size)\n",
    "        self.params['W8'] = wight_init_scales[7] * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b8'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성===========\n",
    "        self.layers = []\n",
    "        self.layers.append(Convolution(self.params['W1'], self.params['b1'], \n",
    "                           conv_param_1['stride'], conv_param_1['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W2'], self.params['b2'], \n",
    "                           conv_param_2['stride'], conv_param_2['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Convolution(self.params['W3'], self.params['b3'], \n",
    "                           conv_param_3['stride'], conv_param_3['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W4'], self.params['b4'],\n",
    "                           conv_param_4['stride'], conv_param_4['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Convolution(self.params['W5'], self.params['b5'],\n",
    "                           conv_param_5['stride'], conv_param_5['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W6'], self.params['b6'],\n",
    "                           conv_param_6['stride'], conv_param_6['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Affine(self.params['W7'], self.params['b7']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Dropout(0.5))\n",
    "        self.layers.append(Affine(self.params['W8'], self.params['b8']))\n",
    "        self.layers.append(Dropout(0.5))\n",
    "        \n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x, train_flg=False):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Dropout):\n",
    "                x = layer.forward(x, train_flg)\n",
    "            else:\n",
    "                x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x, train_flg=True)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "\n",
    "        acc = 0.0\n",
    "\n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx, train_flg=False)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt)\n",
    "\n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        tmp_layers = self.layers.copy()\n",
    "        tmp_layers.reverse()\n",
    "        for layer in tmp_layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
    "            grads['W' + str(i+1)] = self.layers[layer_idx].dW\n",
    "            grads['b' + str(i+1)] = self.layers[layer_idx].db\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
    "            self.layers[layer_idx].W = self.params['W' + str(i+1)]\n",
    "            self.layers[layer_idx].b = self.params['b' + str(i+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3259ba8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3258490843582127\n",
      "=== epoch:1, train acc:0.125, test acc:0.107 ===\n",
      "train loss:2.3629406959846584\n",
      "train loss:2.3374859452857395\n",
      "train loss:2.3155852706013778\n",
      "train loss:2.3462588073021964\n",
      "train loss:2.407027948468714\n",
      "train loss:2.328936252674367\n",
      "train loss:2.30588806175774\n",
      "train loss:2.292637120926865\n",
      "train loss:2.3083755345057106\n",
      "train loss:2.3118817728025713\n",
      "train loss:2.300031909914821\n",
      "train loss:2.2935708182599623\n",
      "train loss:2.2890050200543643\n",
      "train loss:2.3098324863711746\n",
      "train loss:2.2869268308818578\n",
      "train loss:2.307569936058799\n",
      "train loss:2.282829031765878\n",
      "train loss:2.288528149844966\n",
      "train loss:2.2930295019159606\n",
      "train loss:2.2838499628013387\n",
      "train loss:2.2813892154717506\n",
      "train loss:2.2738533294281025\n",
      "train loss:2.284146227436389\n",
      "train loss:2.254198345937388\n",
      "train loss:2.2528988935068073\n",
      "train loss:2.2667716740112795\n",
      "train loss:2.275934245380075\n",
      "train loss:2.291495999638741\n",
      "train loss:2.257542921396383\n",
      "train loss:2.258572534168787\n",
      "train loss:2.2466543835208195\n",
      "train loss:2.230598557728523\n",
      "train loss:2.268511265015868\n",
      "train loss:2.248200505782054\n",
      "train loss:2.2443511684595383\n",
      "train loss:2.2175101951253757\n",
      "train loss:2.2319426748709685\n",
      "train loss:2.2414879838641366\n",
      "train loss:2.243384855464591\n",
      "train loss:2.234233391555775\n",
      "train loss:2.2427838642725293\n",
      "train loss:2.218624115121145\n",
      "train loss:2.2244169509926777\n",
      "train loss:2.2325291350548424\n",
      "train loss:2.2455011456603406\n",
      "train loss:2.211436075078208\n",
      "train loss:2.211073473197645\n",
      "train loss:2.2224646133888792\n",
      "train loss:2.1881018432323356\n",
      "train loss:2.2108445656699875\n",
      "train loss:2.2202851207898227\n",
      "train loss:2.1796189715880843\n",
      "train loss:2.2185279005374476\n",
      "train loss:2.1898551094266407\n",
      "train loss:2.190717165220735\n",
      "train loss:2.1695324548857498\n",
      "train loss:2.162186671391732\n",
      "train loss:2.149881176833175\n",
      "train loss:2.1683503861393287\n",
      "train loss:2.173017424841494\n",
      "train loss:2.1844926124478614\n",
      "train loss:2.1834897867494845\n",
      "train loss:2.1799751278480586\n",
      "train loss:2.1364174706722303\n",
      "train loss:2.1735462077440397\n",
      "train loss:2.180169345508207\n",
      "train loss:2.0940907766384185\n",
      "train loss:2.0874881188885834\n",
      "train loss:2.089336738003617\n",
      "train loss:2.143134854330676\n",
      "train loss:2.192982263520349\n",
      "train loss:2.158425744321942\n",
      "train loss:2.1141607066922323\n",
      "train loss:2.079647567534351\n",
      "train loss:2.130004700186972\n",
      "train loss:2.1348034616155402\n",
      "train loss:2.131925363810243\n",
      "train loss:2.144220665568914\n",
      "train loss:2.0775034808476813\n",
      "train loss:2.1097170059782653\n",
      "train loss:2.1476371232948583\n",
      "train loss:2.136581799713325\n",
      "train loss:2.1074200452728773\n",
      "train loss:2.109138389648985\n",
      "train loss:2.030233567620291\n",
      "train loss:2.081364901983663\n",
      "train loss:2.1007428392936616\n",
      "train loss:2.054285860344997\n",
      "train loss:2.0870667976282578\n",
      "train loss:2.1237904835811268\n",
      "train loss:2.04071144649021\n",
      "train loss:2.0392600836893573\n",
      "train loss:2.0220027823639013\n",
      "train loss:2.0746252802020226\n",
      "train loss:2.0745298439558773\n",
      "train loss:1.975741716543911\n",
      "train loss:2.0136723276210304\n",
      "train loss:2.034196561413549\n",
      "train loss:1.9769457862955797\n",
      "train loss:2.052205822063416\n",
      "train loss:2.0095371524298926\n",
      "train loss:2.070285233924817\n",
      "train loss:2.046236577037541\n",
      "train loss:2.0286683604654296\n",
      "train loss:1.9989428058798768\n",
      "train loss:1.9347350868268043\n",
      "train loss:1.9286661148641295\n",
      "train loss:1.965360705988715\n",
      "train loss:2.0033041705166186\n",
      "train loss:2.0041628244625276\n",
      "train loss:2.0441010878114367\n",
      "train loss:1.9040985268736528\n",
      "train loss:1.8717574352138586\n",
      "train loss:1.9470179964484715\n",
      "train loss:2.04559283637512\n",
      "train loss:1.9942857364470294\n",
      "train loss:1.9589563047260543\n",
      "train loss:1.8829081661458624\n",
      "train loss:2.0063156933559143\n",
      "train loss:1.8695653739268503\n",
      "train loss:1.8696523444179969\n",
      "train loss:2.023360664281528\n",
      "train loss:1.9724829945016134\n",
      "train loss:1.9115985719816482\n",
      "train loss:2.0538790020956306\n",
      "train loss:1.8631913197790015\n",
      "train loss:1.9759237153441995\n",
      "train loss:1.932081378501276\n",
      "train loss:1.8586456245323106\n",
      "train loss:1.887668594763701\n",
      "train loss:1.9058479411470837\n",
      "train loss:1.7958070938615358\n",
      "train loss:1.860893143804285\n",
      "train loss:1.8011604265275905\n",
      "train loss:1.8486775731488012\n",
      "train loss:1.859292428748168\n",
      "train loss:1.8840745002315584\n",
      "train loss:1.9259753171181737\n",
      "train loss:1.825445098584118\n",
      "train loss:1.79089588364848\n",
      "train loss:1.7726102470859768\n",
      "train loss:1.882642400317416\n",
      "train loss:1.7724849838091266\n",
      "train loss:1.8201931955901103\n",
      "train loss:1.8522592580807733\n",
      "train loss:1.8095439262330555\n",
      "train loss:1.87247805255299\n",
      "train loss:1.760112265419996\n",
      "train loss:1.8209060816073364\n",
      "train loss:1.7581683349360164\n",
      "train loss:1.858811760478261\n",
      "train loss:1.7235651754518309\n",
      "train loss:1.7272520317367077\n",
      "train loss:1.7268779257619613\n",
      "train loss:1.7755465589069144\n",
      "train loss:1.8076457664037242\n",
      "train loss:1.9457393307090327\n",
      "train loss:1.8292044363880566\n",
      "train loss:1.789327772956769\n",
      "train loss:1.8375486832931975\n",
      "train loss:1.848725010457248\n",
      "train loss:1.77587449587593\n",
      "train loss:1.8422470434275637\n",
      "train loss:1.7709685075386146\n",
      "train loss:1.7274780029242185\n",
      "train loss:1.7059619937253123\n",
      "train loss:1.7833089484080318\n",
      "train loss:1.6863951767459708\n",
      "train loss:1.7012914639707057\n",
      "train loss:1.7408457680135234\n",
      "train loss:1.7378993778384153\n",
      "train loss:1.678764511989111\n",
      "train loss:1.6850615270965625\n",
      "train loss:1.8378203081530224\n",
      "train loss:1.7850148384210032\n",
      "train loss:1.5488026510985535\n",
      "train loss:1.7459487240394993\n",
      "train loss:1.8331123676242114\n",
      "train loss:1.7906877506098016\n",
      "train loss:1.692498777484167\n",
      "train loss:1.8143971444775198\n",
      "train loss:1.6512647853356068\n",
      "train loss:1.8215363849751482\n",
      "train loss:1.6437236848687795\n",
      "train loss:1.8183449276437174\n",
      "train loss:1.77877990047378\n",
      "train loss:1.657558142728899\n",
      "train loss:1.779464643212491\n",
      "train loss:1.7798779711021755\n",
      "train loss:1.7140916505490764\n",
      "train loss:1.6818215781760584\n",
      "train loss:1.7564767798578802\n",
      "train loss:1.6705667119913057\n",
      "train loss:1.744476419835228\n",
      "train loss:1.5879207514639475\n",
      "train loss:1.6781407942585478\n",
      "train loss:1.588234805642336\n",
      "train loss:1.7895342779457968\n",
      "train loss:1.6729183367329978\n",
      "train loss:1.5435301101257677\n",
      "train loss:1.5654409400521607\n",
      "train loss:1.732158083248254\n",
      "train loss:1.6328604381747531\n",
      "train loss:1.7819820460037747\n",
      "train loss:1.6920654779523847\n",
      "train loss:1.6663785547624173\n",
      "train loss:1.7885195857004166\n",
      "train loss:1.625384331424291\n",
      "train loss:1.7863576892393058\n",
      "train loss:1.665839607015191\n",
      "train loss:1.6628201936308054\n",
      "train loss:1.7486973485768333\n",
      "train loss:1.8076766542659046\n",
      "train loss:1.6601421160998684\n",
      "train loss:1.641889276612489\n",
      "train loss:1.6813595443987046\n",
      "train loss:1.624398925721016\n",
      "train loss:1.5177832406602452\n",
      "train loss:1.5382514347040825\n",
      "train loss:1.5378176355721345\n",
      "train loss:1.4241109598610475\n",
      "train loss:1.74124971646046\n",
      "train loss:1.5721328692225662\n",
      "train loss:1.7989691589848937\n",
      "train loss:1.6864997434292204\n",
      "train loss:1.635884718026073\n",
      "train loss:1.6428614457293895\n",
      "train loss:1.7588493735442217\n",
      "train loss:1.4854592937471998\n",
      "train loss:1.6034118751268573\n",
      "train loss:1.81162669889431\n",
      "train loss:1.5659377817334705\n",
      "train loss:1.6292724400954182\n",
      "train loss:1.4951297205100758\n",
      "train loss:1.5632907330479895\n",
      "train loss:1.55418581663191\n",
      "train loss:1.679268176133261\n",
      "train loss:1.646348046575557\n",
      "train loss:1.68132682054281\n",
      "train loss:1.4228562648523544\n",
      "train loss:1.4686063728745493\n",
      "train loss:1.481535728152987\n",
      "train loss:1.608268739549409\n",
      "train loss:1.6508666844768425\n",
      "train loss:1.6752265476548496\n",
      "train loss:1.5520865006691076\n",
      "train loss:1.4664957786414816\n",
      "train loss:1.4974163216019105\n",
      "train loss:1.6494230792078293\n",
      "train loss:1.549159638390819\n",
      "train loss:1.5705794159635544\n",
      "train loss:1.6716128990229067\n",
      "train loss:1.5546373832035616\n",
      "train loss:1.7283999174983362\n",
      "train loss:1.5677758170638818\n",
      "train loss:1.5584622039845613\n",
      "train loss:1.600892086774542\n",
      "train loss:1.5496197238340579\n",
      "train loss:1.62558669702407\n",
      "train loss:1.7046592717771278\n",
      "train loss:1.506464946225171\n",
      "train loss:1.5766998607862153\n",
      "train loss:1.7274495836486565\n",
      "train loss:1.5495753411680477\n",
      "train loss:1.4775797618776132\n",
      "train loss:1.6763118504640855\n",
      "train loss:1.5643061718704812\n",
      "train loss:1.576240218757999\n",
      "train loss:1.5747540983328818\n",
      "train loss:1.4818212549206364\n",
      "train loss:1.630119698191917\n",
      "train loss:1.6293018392416356\n",
      "train loss:1.722234834305479\n",
      "train loss:1.7063932554355845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.5285008195896006\n",
      "train loss:1.6444081117203084\n",
      "train loss:1.733642162619706\n",
      "train loss:1.5246690618200018\n",
      "train loss:1.30242722125325\n",
      "train loss:1.630312708318722\n",
      "train loss:1.4183959115339753\n",
      "train loss:1.432823395625245\n",
      "train loss:1.5190413592798588\n",
      "train loss:1.5921289959810023\n",
      "train loss:1.5705748015948455\n",
      "train loss:1.604194876294475\n",
      "train loss:1.438748578815353\n",
      "train loss:1.5595890854324592\n",
      "train loss:1.5895526237136712\n",
      "train loss:1.5199335911032645\n",
      "train loss:1.3972557507255727\n",
      "train loss:1.6095131026732516\n",
      "train loss:1.5853897209847307\n",
      "train loss:1.5815010344664386\n",
      "train loss:1.1994584572692408\n",
      "train loss:1.3834714808259454\n",
      "train loss:1.499060998222238\n",
      "train loss:1.451516467986579\n",
      "train loss:1.698311786509855\n",
      "train loss:1.490200433349479\n",
      "train loss:1.4342631144927152\n",
      "train loss:1.6102904869216437\n",
      "train loss:1.4459333991562764\n",
      "train loss:1.5430233680015661\n",
      "train loss:1.5493157688748547\n",
      "train loss:1.5444072422059474\n",
      "train loss:1.401204098764825\n",
      "train loss:1.4206261916297331\n",
      "train loss:1.4929206212656227\n",
      "train loss:1.3353254583834644\n",
      "train loss:1.4149069289302991\n",
      "train loss:1.297325961196545\n",
      "train loss:1.6019512213273939\n",
      "train loss:1.4363024385204666\n",
      "train loss:1.45283074232767\n",
      "train loss:1.5203907961088836\n",
      "train loss:1.5313777564093898\n",
      "train loss:1.4878348868005409\n",
      "train loss:1.521806041101987\n",
      "train loss:1.4501142803619333\n",
      "train loss:1.5181532423425705\n",
      "train loss:1.5683023953246649\n",
      "train loss:1.3942277832393062\n",
      "train loss:1.4020669946509272\n",
      "train loss:1.5453881706817965\n",
      "train loss:1.705386867402674\n",
      "train loss:1.576561907331487\n",
      "train loss:1.5663116533525263\n",
      "train loss:1.6498690142949008\n",
      "train loss:1.3909811842689581\n",
      "train loss:1.5692804546403558\n",
      "train loss:1.499703725722872\n",
      "train loss:1.601459706164642\n",
      "train loss:1.5310914111044018\n",
      "train loss:1.3951853841687014\n",
      "train loss:1.5077425522025134\n",
      "train loss:1.475382283878675\n",
      "train loss:1.5306026326218165\n",
      "train loss:1.518947726073699\n",
      "train loss:1.4331858636955448\n",
      "train loss:1.5093075719650682\n",
      "train loss:1.5950763593998207\n",
      "train loss:1.5362241627463569\n",
      "train loss:1.4490346049361835\n",
      "train loss:1.436541241568249\n",
      "train loss:1.4169690442728498\n",
      "train loss:1.510054836763189\n",
      "train loss:1.475840489814815\n",
      "train loss:1.3731324736167294\n",
      "train loss:1.3836598880735658\n",
      "train loss:1.3919292984181644\n",
      "train loss:1.5044474398766594\n",
      "train loss:1.47100071124959\n",
      "train loss:1.4647555238482588\n",
      "train loss:1.5930607050759675\n",
      "train loss:1.5467094756116502\n",
      "train loss:1.49603197034126\n",
      "train loss:1.6742806389645823\n",
      "train loss:1.556368933684819\n",
      "train loss:1.310237785776715\n",
      "train loss:1.4816271715399907\n",
      "train loss:1.6643291341168136\n",
      "train loss:1.5050312016560938\n",
      "train loss:1.438623864059978\n",
      "train loss:1.5890748322097112\n",
      "train loss:1.4157826083883172\n",
      "train loss:1.577267476681624\n",
      "train loss:1.4771586144147637\n",
      "train loss:1.4209937999203681\n",
      "train loss:1.4716750146232733\n",
      "train loss:1.4603698460743806\n",
      "train loss:1.3792214609586653\n",
      "train loss:1.310141994225827\n",
      "train loss:1.4487566353658492\n",
      "train loss:1.570776949553983\n",
      "train loss:1.4990749896406441\n",
      "train loss:1.5898652561331792\n",
      "train loss:1.600136193030092\n",
      "train loss:1.4829341194917598\n",
      "train loss:1.540294039424087\n",
      "train loss:1.317187392377755\n",
      "train loss:1.4982601225311942\n",
      "train loss:1.5512588217878251\n",
      "train loss:1.3016939619111987\n",
      "train loss:1.4846634140327362\n",
      "train loss:1.474617380652793\n",
      "train loss:1.6007062918356232\n",
      "train loss:1.4969995014561832\n",
      "train loss:1.3715808342617726\n",
      "train loss:1.6108978607012383\n",
      "train loss:1.3259079771593025\n",
      "train loss:1.3635275939097122\n",
      "train loss:1.3364062723375667\n",
      "train loss:1.6557767700250372\n",
      "train loss:1.565260206989865\n",
      "train loss:1.4037592915567756\n",
      "train loss:1.417149713301385\n",
      "train loss:1.32423599536823\n",
      "train loss:1.2704036973473365\n",
      "train loss:1.2063764568000723\n",
      "train loss:1.3868070693011265\n",
      "train loss:1.5800172523282883\n",
      "train loss:1.4910958419845222\n",
      "train loss:1.3327679033672337\n",
      "train loss:1.4853309717015069\n",
      "train loss:1.5445428509186283\n",
      "train loss:1.412984646193703\n",
      "train loss:1.3393587228255763\n",
      "train loss:1.4948613186400024\n",
      "train loss:1.457305538698987\n",
      "train loss:1.490742508817659\n",
      "train loss:1.3524971527705492\n",
      "train loss:1.4727799560168002\n",
      "train loss:1.228103446828107\n",
      "train loss:1.4839047244548402\n",
      "train loss:1.4632057131144662\n",
      "train loss:1.3549767666349737\n",
      "train loss:1.381816981518821\n",
      "train loss:1.4453830916284225\n",
      "train loss:1.5362451262572727\n",
      "train loss:1.3670108429164798\n",
      "train loss:1.2964448775727573\n",
      "train loss:1.4871785961659127\n",
      "train loss:1.2506596219600932\n",
      "train loss:1.3358989736900149\n",
      "train loss:1.460525047936986\n",
      "train loss:1.311314930205572\n",
      "train loss:1.4472322056983784\n",
      "train loss:1.4807749050356787\n",
      "train loss:1.2405926632967093\n",
      "train loss:1.3208987744250291\n",
      "train loss:1.2995830164219464\n",
      "train loss:1.280782850138255\n",
      "train loss:1.345716767558726\n",
      "train loss:1.5667353989837156\n",
      "train loss:1.371804257936534\n",
      "train loss:1.4060257986499933\n",
      "train loss:1.51862759152928\n",
      "train loss:1.4676041198578422\n",
      "train loss:1.3288202157650404\n",
      "train loss:1.351965141817752\n",
      "train loss:1.2700284328732367\n",
      "train loss:1.5492379854034593\n",
      "train loss:1.4250499748789671\n",
      "train loss:1.239149508505684\n",
      "train loss:1.2854783062122974\n",
      "train loss:1.4173053099385013\n",
      "train loss:1.1946743639784545\n",
      "train loss:1.2019735833075669\n",
      "train loss:1.289785902716482\n",
      "train loss:1.3908586759381774\n",
      "train loss:1.4647089795962658\n",
      "train loss:1.3947334742006254\n",
      "train loss:1.5102786589731372\n",
      "train loss:1.3487550298654087\n",
      "train loss:1.4625616014991163\n",
      "train loss:1.252926506001391\n",
      "train loss:1.5033253585052029\n",
      "train loss:1.327626751298247\n",
      "train loss:1.4443538231516908\n",
      "train loss:1.4326670046393812\n",
      "train loss:1.3835151063248103\n",
      "train loss:1.420127201901831\n",
      "train loss:1.3825638486746012\n",
      "train loss:1.4005813975247383\n",
      "train loss:1.4500369870760363\n",
      "train loss:1.2358039593529002\n",
      "train loss:1.4451298929022596\n",
      "train loss:1.435998448929864\n",
      "train loss:1.1492507972600132\n",
      "train loss:1.3461006813261807\n",
      "train loss:1.6271152306908911\n",
      "train loss:1.308499107607428\n",
      "train loss:1.5339222376761414\n",
      "train loss:1.4117368950254225\n",
      "train loss:1.343779367903247\n",
      "train loss:1.3802448870537265\n",
      "train loss:1.5028592904294087\n",
      "train loss:1.61050298675845\n",
      "train loss:1.352009820155869\n",
      "train loss:1.2362763585799004\n",
      "train loss:1.383686964769943\n",
      "train loss:1.2550107686268432\n",
      "train loss:1.3022986511430559\n",
      "train loss:1.4786910786391367\n",
      "train loss:1.3668635650224121\n",
      "train loss:1.3636911536376528\n",
      "train loss:1.3816297807146258\n",
      "train loss:1.3609246369528067\n",
      "train loss:1.4101784095881087\n",
      "train loss:1.3985575224778863\n",
      "train loss:1.2017794084198834\n",
      "train loss:1.419049656757432\n",
      "train loss:1.296476960333752\n",
      "train loss:1.3694502796981722\n",
      "train loss:1.2514571948360693\n",
      "train loss:1.4226590862193844\n",
      "train loss:1.325392263634478\n",
      "train loss:1.4597535597058116\n",
      "train loss:1.421491521610668\n",
      "train loss:1.297745644105234\n",
      "train loss:1.4616872596677712\n",
      "train loss:1.45253026650907\n",
      "train loss:1.4973057021673142\n",
      "train loss:1.2234976362496535\n",
      "train loss:1.2697528554306512\n",
      "train loss:1.3846464684583717\n",
      "train loss:1.28706893638997\n",
      "train loss:1.0832413390741815\n",
      "train loss:1.3869147643374304\n",
      "train loss:1.394963498802982\n",
      "train loss:1.3069254135144908\n",
      "train loss:1.4904694545702477\n",
      "train loss:1.375148250010167\n",
      "train loss:1.255135557196255\n",
      "train loss:1.3773581385743756\n",
      "train loss:1.165090211847147\n",
      "train loss:1.246888292003667\n",
      "train loss:1.3080564782831028\n",
      "train loss:1.2535452682722823\n",
      "train loss:1.4722148719211514\n",
      "train loss:1.4108473501110779\n",
      "train loss:1.4555719120738542\n",
      "train loss:1.2632147929467337\n",
      "train loss:1.200564083552914\n",
      "train loss:1.358851142416565\n",
      "train loss:1.3817870863739683\n",
      "train loss:1.3114540625753168\n",
      "train loss:1.2902540356336527\n",
      "train loss:1.3534043335051027\n",
      "train loss:1.248544106713811\n",
      "train loss:1.1915400114488324\n",
      "train loss:1.337569140389307\n",
      "train loss:1.5598112211401514\n",
      "train loss:1.465426042750098\n",
      "train loss:1.4928067225103743\n",
      "train loss:1.260729874723789\n",
      "train loss:1.2695180521397165\n",
      "train loss:1.3901404072825614\n",
      "train loss:1.1743868533134791\n",
      "train loss:1.4601805180938632\n",
      "train loss:1.2868301293878956\n",
      "train loss:1.3571063856267551\n",
      "train loss:1.2350344716926682\n",
      "train loss:1.481784974530735\n",
      "train loss:1.4997311549159094\n",
      "train loss:1.4086996561201917\n",
      "train loss:1.3603490606139719\n",
      "train loss:1.1706352286711565\n",
      "train loss:1.3902257391181567\n",
      "train loss:1.2102080519794716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.3799027008700733\n",
      "train loss:1.424723366954522\n",
      "train loss:1.3631053249166774\n",
      "train loss:1.1470443889621618\n",
      "train loss:1.2996133760266309\n",
      "train loss:1.5083907105573393\n",
      "train loss:1.2609683793883033\n",
      "train loss:1.4375647940490168\n",
      "train loss:1.3435309661254358\n",
      "train loss:1.2693440501445763\n",
      "train loss:1.2990303686123374\n",
      "train loss:1.2326364997487096\n",
      "train loss:1.3135831400791755\n",
      "train loss:1.2004586440456397\n",
      "train loss:1.3684205005841281\n",
      "train loss:1.309060800611027\n",
      "train loss:1.4071892063095768\n",
      "train loss:1.4677087325826954\n",
      "train loss:1.2326375513858614\n",
      "train loss:1.2610721429185385\n",
      "train loss:1.2861327770482285\n",
      "train loss:1.465528743542279\n",
      "train loss:1.4882742181733744\n",
      "train loss:1.3740161650866982\n",
      "train loss:1.3192896538641563\n",
      "train loss:1.1867041918513968\n",
      "train loss:1.1906174959395017\n",
      "train loss:1.3141879283463564\n",
      "train loss:1.5100042721151363\n",
      "train loss:1.3199523097138148\n",
      "train loss:1.2099203569210846\n",
      "train loss:1.4354005910874212\n",
      "train loss:1.5422182978497956\n",
      "train loss:1.3204133915934455\n",
      "train loss:1.3380952052668418\n",
      "train loss:1.162278898344814\n",
      "train loss:1.4208808343841277\n",
      "train loss:1.4138709894878405\n",
      "train loss:1.3945428939991547\n",
      "train loss:1.4998330726719364\n",
      "train loss:1.3526624574602633\n",
      "train loss:1.214829955497719\n",
      "train loss:1.4056774873066709\n",
      "train loss:1.2215146396123628\n",
      "train loss:1.2550897630498858\n",
      "train loss:1.327548259855102\n",
      "train loss:1.5056174885322868\n",
      "train loss:1.2484916572217402\n",
      "train loss:1.4054908913647726\n",
      "=== epoch:2, train acc:0.934, test acc:0.929 ===\n",
      "train loss:1.316479274049353\n",
      "train loss:1.451500483169926\n",
      "train loss:1.3349918031170767\n",
      "train loss:1.1878919127049683\n",
      "train loss:1.3071974983088512\n",
      "train loss:1.3896568596152203\n",
      "train loss:1.2917929330308067\n",
      "train loss:1.5514096241918507\n",
      "train loss:1.3521062833922934\n",
      "train loss:1.4433116869197096\n",
      "train loss:1.186027293143327\n",
      "train loss:1.4752790723270781\n",
      "train loss:1.2981518833187153\n",
      "train loss:1.4290296494012933\n",
      "train loss:1.3220669595594365\n",
      "train loss:1.222082127551993\n",
      "train loss:1.2978933174134\n",
      "train loss:1.3372457681798366\n",
      "train loss:1.3411019052571043\n",
      "train loss:1.288406177344588\n",
      "train loss:1.384392978593043\n",
      "train loss:1.593315590422699\n",
      "train loss:1.2913785216189544\n",
      "train loss:1.2943655744840035\n",
      "train loss:1.5326043111405656\n",
      "train loss:1.4189294838036846\n",
      "train loss:1.1743272313500457\n",
      "train loss:1.2015974348929155\n",
      "train loss:1.3239350586009768\n",
      "train loss:1.33036794459627\n",
      "train loss:1.4840769376589966\n",
      "train loss:1.334411129820075\n",
      "train loss:1.4552220264323623\n",
      "train loss:1.2279559203258628\n",
      "train loss:1.312688101765158\n",
      "train loss:1.2696926569597458\n",
      "train loss:1.1938149772255455\n",
      "train loss:1.2822806034846692\n",
      "train loss:1.342853472416289\n",
      "train loss:1.2771129049916539\n",
      "train loss:1.4340295170188284\n",
      "train loss:1.1334886684276082\n",
      "train loss:1.3718984340034133\n",
      "train loss:1.325208925135908\n",
      "train loss:1.51336871531021\n",
      "train loss:1.4176378035037587\n",
      "train loss:1.3871637468423645\n",
      "train loss:1.3175131223501668\n",
      "train loss:1.2872467911579617\n",
      "train loss:1.3276210252108107\n",
      "train loss:1.4515773322403218\n",
      "train loss:1.3399105672493947\n",
      "train loss:1.1757760005666242\n",
      "train loss:1.0773184341012767\n",
      "train loss:0.9580924398590498\n",
      "train loss:1.3259682730321998\n",
      "train loss:1.310677486817838\n",
      "train loss:1.3773153344802802\n",
      "train loss:1.4253937654435305\n",
      "train loss:1.426138078269109\n",
      "train loss:1.3695304386359286\n",
      "train loss:1.242801471046824\n",
      "train loss:1.2549429066766713\n",
      "train loss:1.231163085492322\n",
      "train loss:1.4560465049103513\n",
      "train loss:1.2798029925244203\n",
      "train loss:1.3105713392257778\n",
      "train loss:1.2801458744983998\n",
      "train loss:1.1994433514128944\n",
      "train loss:1.058683903546594\n",
      "train loss:1.4569744276696874\n",
      "train loss:1.184241254933039\n",
      "train loss:1.2669014134661247\n",
      "train loss:1.2768902388589565\n",
      "train loss:1.3346398713418706\n",
      "train loss:1.249359576798365\n",
      "train loss:1.3354760547142392\n",
      "train loss:1.3505183356709278\n",
      "train loss:1.375391560076472\n",
      "train loss:1.322342580118528\n",
      "train loss:1.1831905909856049\n",
      "train loss:1.3261085020386312\n",
      "train loss:1.1400761927967682\n",
      "train loss:1.3495341814394373\n",
      "train loss:1.3260940092232627\n",
      "train loss:1.3507850774835868\n",
      "train loss:1.3613875913364004\n",
      "train loss:1.4373148259221222\n",
      "train loss:1.519607057677841\n",
      "train loss:1.2692668541907397\n",
      "train loss:1.3204826726373966\n",
      "train loss:1.2841039435235788\n",
      "train loss:1.2113504269782684\n",
      "train loss:1.306908999749579\n",
      "train loss:1.2304600727680657\n",
      "train loss:1.2402215814934727\n",
      "train loss:1.2630253768554345\n",
      "train loss:1.316192439089038\n",
      "train loss:1.184422050871402\n",
      "train loss:1.008954030229012\n",
      "train loss:1.3561035406846056\n",
      "train loss:1.1815333774526686\n",
      "train loss:1.2861694536757546\n",
      "train loss:1.2163741201769305\n",
      "train loss:1.2892477330137546\n",
      "train loss:1.355426696805198\n",
      "train loss:1.243770104826556\n",
      "train loss:1.3877291667009708\n",
      "train loss:1.2914795409122948\n",
      "train loss:1.282165410901099\n",
      "train loss:1.4291779267384368\n",
      "train loss:1.4183681290620465\n",
      "train loss:1.2731162984650222\n",
      "train loss:1.2026127881363249\n",
      "train loss:1.2672620406524784\n",
      "train loss:1.4353403770361675\n",
      "train loss:1.123772952774253\n",
      "train loss:1.2561490513303684\n",
      "train loss:1.160142434477695\n",
      "train loss:1.3762463888151997\n",
      "train loss:1.2458405834949524\n",
      "train loss:1.274336732236223\n",
      "train loss:1.284643175809089\n",
      "train loss:1.2597158334761198\n",
      "train loss:1.2211788482477444\n",
      "train loss:1.4741623106376949\n",
      "train loss:1.2738970404913312\n",
      "train loss:1.311447715926963\n",
      "train loss:1.0775109775162637\n",
      "train loss:1.1538665340666876\n",
      "train loss:1.1943274749746513\n",
      "train loss:1.3361719596864259\n",
      "train loss:1.262539725817316\n",
      "train loss:1.3669221941890688\n",
      "train loss:1.1729051700310682\n",
      "train loss:1.2947472280079209\n",
      "train loss:1.3424066610860022\n",
      "train loss:1.1916858083649025\n",
      "train loss:1.1039898362813425\n",
      "train loss:1.16473937621528\n",
      "train loss:1.1876406821685404\n",
      "train loss:1.159750356096233\n",
      "train loss:1.1386632972692712\n",
      "train loss:1.1844676099216729\n",
      "train loss:1.4500555717231742\n",
      "train loss:1.3096048565970515\n",
      "train loss:1.4908060292295275\n",
      "train loss:1.304915005992683\n",
      "train loss:1.223528090044839\n",
      "train loss:1.1875345910399207\n",
      "train loss:1.2548894522354321\n",
      "train loss:1.3073396966286743\n",
      "train loss:1.2664965217976978\n",
      "train loss:1.1524994766603458\n",
      "train loss:1.3847549508778498\n",
      "train loss:1.4834172416606703\n",
      "train loss:1.232389388105422\n",
      "train loss:1.1965968481418003\n",
      "train loss:1.0593312994302457\n",
      "train loss:1.3856989886426603\n",
      "train loss:1.2625896051244097\n",
      "train loss:1.2326708748943034\n",
      "train loss:1.254194894331362\n",
      "train loss:1.0860516576968515\n",
      "train loss:1.3088744868005884\n",
      "train loss:1.314257868526704\n",
      "train loss:1.288326343235189\n",
      "train loss:1.0161508804163684\n",
      "train loss:1.0906305682781292\n",
      "train loss:1.4673267789838373\n",
      "train loss:1.3727822633404194\n",
      "train loss:1.216800524874561\n",
      "train loss:1.2096889292693567\n",
      "train loss:1.262121668553177\n",
      "train loss:1.5355380861672812\n",
      "train loss:1.3358190547017639\n",
      "train loss:1.4138544543680587\n",
      "train loss:1.1862992163716277\n",
      "train loss:1.231242678556644\n",
      "train loss:1.5078789051542676\n",
      "train loss:1.4249820331809622\n",
      "train loss:1.3155542004614267\n",
      "train loss:1.3083725190506106\n",
      "train loss:1.0794489170975272\n",
      "train loss:1.4009009908474903\n",
      "train loss:1.2736651713756004\n",
      "train loss:1.319762277280682\n",
      "train loss:1.406464389678677\n",
      "train loss:1.2408044036535062\n",
      "train loss:1.2826549510789067\n",
      "train loss:1.2010156525521667\n",
      "train loss:1.2944225735997044\n",
      "train loss:1.28172010401513\n",
      "train loss:1.3203371015811474\n",
      "train loss:1.259724854122109\n",
      "train loss:1.1765278068281864\n",
      "train loss:1.2740260868894904\n",
      "train loss:1.3092454066414054\n",
      "train loss:1.3393190327381297\n",
      "train loss:1.103000378844528\n",
      "train loss:1.3549960529157332\n",
      "train loss:1.2637702916031217\n",
      "train loss:1.1666501051528264\n",
      "train loss:1.2482758271940382\n",
      "train loss:1.419935891287591\n",
      "train loss:1.2241576158351277\n",
      "train loss:1.3700934844448032\n",
      "train loss:1.1437385564684248\n",
      "train loss:1.2655541026427088\n",
      "train loss:1.4299100655699022\n",
      "train loss:1.078218246991099\n",
      "train loss:1.0626671272287762\n",
      "train loss:1.3901453612170078\n",
      "train loss:1.2427762190875034\n",
      "train loss:1.2271286548529479\n",
      "train loss:1.0028027522840406\n",
      "train loss:1.1506085894586657\n",
      "train loss:1.2191072069810085\n",
      "train loss:1.1183628137957626\n",
      "train loss:1.0692837969594362\n",
      "train loss:1.1485996069269226\n",
      "train loss:1.3862620841277555\n",
      "train loss:1.2466750245026939\n",
      "train loss:1.2666329214769307\n",
      "train loss:1.314636055602299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.1879127401205545\n",
      "train loss:1.1894763903524603\n",
      "train loss:1.1614764550237764\n",
      "train loss:1.0686773792916147\n",
      "train loss:1.1072132410808797\n",
      "train loss:1.1713442376320573\n",
      "train loss:1.2111262194070351\n",
      "train loss:1.2834719459511605\n",
      "train loss:1.2470698162181735\n",
      "train loss:1.3072688826197898\n",
      "train loss:1.3876682347698792\n",
      "train loss:1.1948734555141451\n",
      "train loss:1.266315063506236\n",
      "train loss:1.1325555892167274\n",
      "train loss:1.1992676257240482\n",
      "train loss:1.383820375850522\n",
      "train loss:1.2258468970092362\n",
      "train loss:1.172940086492634\n",
      "train loss:1.4737635474179713\n",
      "train loss:1.0588373759998069\n",
      "train loss:1.258098905912693\n",
      "train loss:1.2479278546634718\n",
      "train loss:1.3328419007518741\n",
      "train loss:1.3926177197475678\n",
      "train loss:1.1597225705020564\n",
      "train loss:1.088452441780901\n",
      "train loss:1.1831571303073884\n",
      "train loss:1.3121363181957892\n",
      "train loss:1.2598308608643862\n",
      "train loss:1.2363394683621665\n",
      "train loss:1.295251384040067\n",
      "train loss:1.2464945815165764\n",
      "train loss:1.299536606935729\n",
      "train loss:1.3778081450900126\n",
      "train loss:1.3182963982648122\n",
      "train loss:1.0469863036194798\n",
      "train loss:1.3629811132651433\n",
      "train loss:1.329624759128885\n",
      "train loss:1.2925465650670105\n",
      "train loss:1.178708262906911\n",
      "train loss:1.1556916831222461\n",
      "train loss:1.2249572787384857\n",
      "train loss:1.3198928150583482\n",
      "train loss:1.194277253780336\n",
      "train loss:1.3372901875272902\n",
      "train loss:1.2424077789693626\n",
      "train loss:0.9753706967347986\n",
      "train loss:1.2132519837951683\n",
      "train loss:1.2115940238735528\n",
      "train loss:1.1410586168178447\n",
      "train loss:1.2603910091992456\n",
      "train loss:1.2063432758736807\n",
      "train loss:1.110263984577735\n",
      "train loss:1.2168715090114608\n",
      "train loss:1.3901960255801344\n",
      "train loss:1.4331132204882036\n",
      "train loss:1.206225688960182\n",
      "train loss:1.1130845290424092\n",
      "train loss:1.3412273442293858\n",
      "train loss:1.4128872738980751\n",
      "train loss:1.2080156160291033\n",
      "train loss:1.1529373758250494\n",
      "train loss:1.1766482072591609\n",
      "train loss:1.2735297900045333\n",
      "train loss:1.2261888028172716\n",
      "train loss:1.2250700705430673\n",
      "train loss:1.237968178328272\n",
      "train loss:1.3663220275170729\n",
      "train loss:1.3180856346837055\n",
      "train loss:1.3248933607067832\n",
      "train loss:1.13760547233552\n",
      "train loss:1.1345603991327398\n",
      "train loss:1.1570485047396115\n",
      "train loss:1.123964080233047\n",
      "train loss:1.427980057975001\n",
      "train loss:1.1327253817168488\n",
      "train loss:1.3381666977712832\n",
      "train loss:1.4412028781743595\n",
      "train loss:1.2169248679357239\n",
      "train loss:1.225172548640981\n",
      "train loss:1.1196313784991356\n",
      "train loss:1.2499939119722416\n",
      "train loss:1.1600262050320027\n",
      "train loss:0.9371495704445624\n",
      "train loss:0.9286966551418968\n",
      "train loss:1.1137449406896522\n",
      "train loss:1.235583036976461\n",
      "train loss:1.2029329721373856\n",
      "train loss:1.3324256145266375\n",
      "train loss:1.2883953538426156\n",
      "train loss:1.2350676927485704\n",
      "train loss:1.2492984115362216\n",
      "train loss:1.2527610620116154\n",
      "train loss:1.2853240503701537\n",
      "train loss:0.9952664425231051\n",
      "train loss:1.2998238327100298\n",
      "train loss:1.3829882465662373\n",
      "train loss:1.4888281776411512\n",
      "train loss:1.2077155362696192\n",
      "train loss:1.4102876442852361\n",
      "train loss:1.3532635817844179\n",
      "train loss:1.0901752575228536\n",
      "train loss:1.115761633097028\n",
      "train loss:1.2083145170109317\n",
      "train loss:1.0325334583653023\n",
      "train loss:1.2114812779098907\n",
      "train loss:1.522525978759738\n",
      "train loss:1.257473317895772\n",
      "train loss:1.1003497310633426\n",
      "train loss:1.2626778275380304\n",
      "train loss:1.290068386289563\n",
      "train loss:1.1991978878004195\n",
      "train loss:1.2947625628275625\n",
      "train loss:1.2618772728367964\n",
      "train loss:1.0720034547715636\n",
      "train loss:1.2633824178894855\n",
      "train loss:1.241851000222867\n",
      "train loss:1.1555460943081162\n",
      "train loss:1.3329482017449608\n",
      "train loss:1.2550637970706733\n",
      "train loss:1.2831852613007104\n",
      "train loss:1.192877200873166\n",
      "train loss:1.1497872667810842\n",
      "train loss:1.2518861488029773\n",
      "train loss:1.0508015355075877\n",
      "train loss:1.280233333107625\n",
      "train loss:1.1709681497223745\n",
      "train loss:1.264803400519674\n",
      "train loss:1.1952772761669181\n",
      "train loss:1.2201864865590737\n",
      "train loss:1.2643532411595602\n",
      "train loss:1.1680158438784962\n",
      "train loss:1.2712747404540463\n",
      "train loss:1.1353260740765492\n",
      "train loss:1.3548367033756978\n",
      "train loss:1.047626322614458\n",
      "train loss:1.2824332759325747\n",
      "train loss:1.3356607123946957\n",
      "train loss:1.194973638038388\n",
      "train loss:1.1995088273915868\n",
      "train loss:1.2888600782953374\n",
      "train loss:0.9826152813567662\n",
      "train loss:1.2202566008821694\n",
      "train loss:1.0518883794718399\n",
      "train loss:1.2068774656360264\n",
      "train loss:1.0896915290079505\n",
      "train loss:1.0642184953629796\n",
      "train loss:1.2567188023923321\n",
      "train loss:1.2587098552411915\n",
      "train loss:1.1899854501691067\n",
      "train loss:1.0928008916178849\n",
      "train loss:1.1135003851296323\n",
      "train loss:1.3871414663172161\n",
      "train loss:1.2311257756732865\n",
      "train loss:1.2079026025487056\n",
      "train loss:1.2199092280519255\n",
      "train loss:1.1558052922025888\n",
      "train loss:1.3065390749545436\n",
      "train loss:1.231761835197386\n",
      "train loss:1.341472441039646\n",
      "train loss:1.1676716128291458\n",
      "train loss:1.2812262832657737\n",
      "train loss:1.147825113795741\n",
      "train loss:1.211474245283522\n",
      "train loss:1.2501951765073849\n",
      "train loss:1.0262602337156297\n",
      "train loss:1.1013309063307768\n",
      "train loss:1.3318177393399424\n",
      "train loss:1.0779636608103909\n",
      "train loss:1.3332042701052464\n",
      "train loss:1.0527001368208504\n",
      "train loss:1.1412370062959711\n",
      "train loss:1.4194610547162396\n",
      "train loss:1.3790389630548154\n",
      "train loss:1.3167717107143924\n",
      "train loss:1.3189060922561637\n",
      "train loss:1.2801322499378733\n",
      "train loss:1.1919373459206133\n",
      "train loss:1.0077204562520183\n",
      "train loss:1.2590515451469049\n",
      "train loss:1.3244727632403988\n",
      "train loss:1.0544017506663048\n",
      "train loss:1.2116340427120413\n",
      "train loss:1.1819209811033715\n",
      "train loss:1.2741236302803203\n",
      "train loss:1.3801262054919914\n",
      "train loss:1.2362438884990257\n",
      "train loss:1.2063309080932172\n",
      "train loss:1.0765746523194577\n",
      "train loss:1.430178281320989\n",
      "train loss:1.2887648931487066\n",
      "train loss:0.9546154250789174\n",
      "train loss:1.3400109827656912\n",
      "train loss:1.0746868146115378\n",
      "train loss:1.2303078004993047\n",
      "train loss:1.1028646924713357\n",
      "train loss:1.103091477891796\n",
      "train loss:1.2489756770580707\n",
      "train loss:1.3145484860010594\n",
      "train loss:1.1693206509466543\n",
      "train loss:1.1020708132657162\n",
      "train loss:1.1574019883444127\n",
      "train loss:1.1862953971778973\n",
      "train loss:1.1799034218556033\n",
      "train loss:1.1484224105166583\n",
      "train loss:1.2544301055883897\n",
      "train loss:1.3175718504015435\n",
      "train loss:1.012132119832699\n",
      "train loss:1.1804402056677399\n",
      "train loss:1.176981149581649\n",
      "train loss:1.217111686550663\n",
      "train loss:1.1699867954092094\n",
      "train loss:1.2607523228186872\n",
      "train loss:1.1371138383982855\n",
      "train loss:1.2619369792835027\n",
      "train loss:1.328864168662692\n",
      "train loss:1.327665546288527\n",
      "train loss:1.1564408453695905\n",
      "train loss:1.0694291946535364\n",
      "train loss:1.1451924095133743\n",
      "train loss:1.2993452245908412\n",
      "train loss:1.2753546490300751\n",
      "train loss:1.3444921432819277\n",
      "train loss:1.2091753644183805\n",
      "train loss:0.9424248476990131\n",
      "train loss:1.1852094035842733\n",
      "train loss:1.0532345765145923\n",
      "train loss:1.2414526830320158\n",
      "train loss:1.1749937336146992\n",
      "train loss:1.248900320309237\n",
      "train loss:1.173417143658241\n",
      "train loss:1.2550590845346867\n",
      "train loss:1.2627463097296454\n",
      "train loss:1.168837141066246\n",
      "train loss:1.1028432377428536\n",
      "train loss:1.4016597877813057\n",
      "train loss:1.1892269466085499\n",
      "train loss:1.190305781622999\n",
      "train loss:1.2641754821213307\n",
      "train loss:1.2801481027581634\n",
      "train loss:1.3396729227831425\n",
      "train loss:1.1770052367376354\n",
      "train loss:1.3365602532070207\n",
      "train loss:1.281325668155757\n",
      "train loss:1.1612326473492696\n",
      "train loss:1.082314990279718\n",
      "train loss:1.2022681481723447\n",
      "train loss:1.1931792233459786\n",
      "train loss:1.1807110320046625\n",
      "train loss:1.2330300521150723\n",
      "train loss:1.0972524112426874\n",
      "train loss:1.2003166157958993\n",
      "train loss:1.2905369304554268\n",
      "train loss:1.2620665102345139\n",
      "train loss:1.2668252941050044\n",
      "train loss:1.2077836810663325\n",
      "train loss:1.1996496302848803\n",
      "train loss:1.0842167327917267\n",
      "train loss:1.0966022983925174\n",
      "train loss:1.1035334731297708\n",
      "train loss:1.2018609372546116\n",
      "train loss:1.2944861789564572\n",
      "train loss:1.1638879391394972\n",
      "train loss:1.2300948492923391\n",
      "train loss:1.0679348498689722\n",
      "train loss:1.1470216126564265\n",
      "train loss:1.0670923483143289\n",
      "train loss:1.2452792120902627\n",
      "train loss:1.111524197292725\n",
      "train loss:1.3806524020578343\n",
      "train loss:1.1456873410761823\n",
      "train loss:1.1130746392124882\n",
      "train loss:1.187510673949636\n",
      "train loss:0.9705950283470082\n",
      "train loss:1.1689759089947738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.1222983752273634\n",
      "train loss:1.0885618555728591\n",
      "train loss:1.198461845834542\n",
      "train loss:1.1298160276677955\n",
      "train loss:1.130980137463674\n",
      "train loss:1.0734738034370148\n",
      "train loss:1.238032951558474\n",
      "train loss:1.1839394921924586\n",
      "train loss:1.1289638828681814\n",
      "train loss:1.2030521687408258\n",
      "train loss:1.0509486419198821\n",
      "train loss:1.2632302298867313\n",
      "train loss:1.1814982020196545\n",
      "train loss:1.1326292497837245\n",
      "train loss:1.0030441145467968\n",
      "train loss:1.114580820203353\n",
      "train loss:1.235190722065218\n",
      "train loss:1.1036564858106974\n",
      "train loss:1.3508499271494352\n",
      "train loss:1.2077683722310455\n",
      "train loss:1.2015676126706039\n",
      "train loss:1.044261910350494\n",
      "train loss:1.2604144731060332\n",
      "train loss:1.259428752454408\n",
      "train loss:1.2311949230304022\n",
      "train loss:1.0871857522865924\n",
      "train loss:1.3796078718298377\n",
      "train loss:1.0780280138628333\n",
      "train loss:1.1842057724027222\n",
      "train loss:1.1463908645106797\n",
      "train loss:1.190306228837472\n",
      "train loss:1.140837057223375\n",
      "train loss:1.1758926995708463\n",
      "train loss:1.3228351270873686\n",
      "train loss:1.1946655161902024\n",
      "train loss:1.0540677681591897\n",
      "train loss:1.092740926117895\n",
      "train loss:1.3994395303824572\n",
      "train loss:1.1430179558643543\n",
      "train loss:1.3005589838154747\n",
      "train loss:1.178978274676079\n",
      "train loss:1.034131093456068\n",
      "train loss:1.1433316639863798\n",
      "train loss:1.3108235406061264\n",
      "train loss:1.1237481325157563\n",
      "train loss:1.1280332348025377\n",
      "train loss:1.1939793161679457\n",
      "train loss:1.0994178593564004\n",
      "train loss:0.9872584751102059\n",
      "train loss:1.201126511996554\n",
      "train loss:1.4910495690657763\n",
      "train loss:1.2228980914048817\n",
      "train loss:1.2523987743600844\n",
      "train loss:1.243882260527509\n",
      "train loss:1.0886206780668326\n",
      "train loss:1.436620473117734\n",
      "train loss:1.169854272330654\n",
      "train loss:1.1381676893695636\n",
      "train loss:1.301114075523455\n",
      "train loss:1.0696294943852211\n",
      "train loss:1.2810817729508621\n",
      "train loss:1.153260428459091\n",
      "train loss:1.116093418019078\n",
      "train loss:1.0589623381491815\n",
      "train loss:1.2136225356738914\n",
      "train loss:1.0783039940185608\n",
      "train loss:1.2058089217184216\n",
      "train loss:1.2835652355819966\n",
      "train loss:1.232952862562832\n",
      "train loss:1.2853661485545802\n",
      "train loss:1.1798437700376387\n",
      "train loss:1.2719667519300848\n",
      "train loss:0.9871291398367606\n",
      "train loss:1.1087826679084551\n",
      "train loss:1.0963109623936704\n",
      "train loss:1.3306184077852605\n",
      "train loss:1.2525721647090398\n",
      "train loss:1.2605233814867387\n",
      "train loss:1.0047839803674825\n",
      "train loss:1.2549875054888604\n",
      "train loss:1.311783509187129\n",
      "train loss:1.2665774124121594\n",
      "train loss:1.1597467163162067\n",
      "train loss:1.15346522828495\n",
      "train loss:1.0860614784559839\n",
      "train loss:1.2010673309166122\n",
      "train loss:1.133998700463066\n",
      "train loss:0.9816525324296349\n",
      "train loss:1.3708086917951834\n",
      "train loss:1.094581256943496\n",
      "train loss:0.8778311647369182\n",
      "train loss:1.1359886368440926\n",
      "train loss:1.337059333670632\n",
      "train loss:1.2194993810716446\n",
      "train loss:1.2283976128560985\n",
      "train loss:1.3325246925199066\n",
      "train loss:1.1645190578343512\n",
      "train loss:1.4514366932528013\n",
      "train loss:1.1251259505480922\n",
      "train loss:1.293887992733834\n",
      "=== epoch:3, train acc:0.957, test acc:0.959 ===\n",
      "train loss:1.0015245317663384\n",
      "train loss:1.2570649442317412\n",
      "train loss:1.0993371270135597\n",
      "train loss:1.0524026078996283\n",
      "train loss:1.1534600869422194\n",
      "train loss:1.009807327590014\n",
      "train loss:0.9964613379870493\n",
      "train loss:1.2678522244576584\n",
      "train loss:1.1608662334402637\n",
      "train loss:1.079667815950586\n",
      "train loss:1.1803261466308554\n",
      "train loss:1.2459664684837235\n",
      "train loss:1.1579002617391572\n",
      "train loss:1.1189144772442416\n",
      "train loss:1.1964462133401346\n",
      "train loss:1.1237971790255223\n",
      "train loss:1.291094352513786\n",
      "train loss:1.0306877331536128\n",
      "train loss:1.1562617027931688\n",
      "train loss:1.250148679144509\n",
      "train loss:0.9855411613184384\n",
      "train loss:1.0492512797606859\n",
      "train loss:1.1602925875248067\n",
      "train loss:1.2106428116517352\n",
      "train loss:1.3736607365202125\n",
      "train loss:0.9864550027268791\n",
      "train loss:1.128818920974994\n",
      "train loss:1.1072639020560877\n",
      "train loss:1.225749830171065\n",
      "train loss:1.1849924083235086\n",
      "train loss:1.1860603967504826\n",
      "train loss:1.0407120884142589\n",
      "train loss:1.2646855177558347\n",
      "train loss:1.134507888238139\n",
      "train loss:1.1105121478178086\n",
      "train loss:1.0313342474531282\n",
      "train loss:1.289520066107944\n",
      "train loss:1.1046245819758596\n",
      "train loss:0.9511288042233486\n",
      "train loss:1.0218358888386379\n",
      "train loss:1.356088740785089\n",
      "train loss:1.1491268665674124\n",
      "train loss:1.0474054022175467\n",
      "train loss:1.2679865942375914\n",
      "train loss:1.1649276751437838\n",
      "train loss:1.0572686589906817\n",
      "train loss:1.1790981717211297\n",
      "train loss:1.280617172796474\n",
      "train loss:1.1954394542839488\n",
      "train loss:1.1325615273520433\n",
      "train loss:1.169877835135103\n",
      "train loss:1.170714997042417\n",
      "train loss:1.1784162944577752\n",
      "train loss:1.1355982327542329\n",
      "train loss:1.161388838599129\n",
      "train loss:1.2259587779373542\n",
      "train loss:1.2310158541103433\n",
      "train loss:1.0816556901734302\n",
      "train loss:1.1148777310683613\n",
      "train loss:1.0750369085658285\n",
      "train loss:1.24495268747856\n",
      "train loss:1.1903993396414385\n",
      "train loss:1.268662185337436\n",
      "train loss:1.1135058520931875\n",
      "train loss:1.3473633177921411\n",
      "train loss:1.146959884390112\n",
      "train loss:1.0829042577814194\n",
      "train loss:1.1388102965142475\n",
      "train loss:1.333011472950109\n",
      "train loss:1.2176084964427212\n",
      "train loss:1.1607304651819401\n",
      "train loss:1.1267386484614041\n",
      "train loss:1.3304976514462064\n",
      "train loss:1.2326403910599348\n",
      "train loss:1.169150752019928\n",
      "train loss:1.2109058208030854\n",
      "train loss:1.1340721895832788\n",
      "train loss:1.1991572711782927\n",
      "train loss:1.3710005210639165\n",
      "train loss:1.1525592515067673\n",
      "train loss:0.9191965756944067\n",
      "train loss:1.2198783577984182\n",
      "train loss:1.2157654217771614\n",
      "train loss:1.31504886798664\n",
      "train loss:1.2980692803565999\n",
      "train loss:1.1251424940582146\n",
      "train loss:1.1547912594100056\n",
      "train loss:1.3750521817710588\n",
      "train loss:1.3061343838679513\n",
      "train loss:1.247267779024712\n",
      "train loss:1.2593778590779832\n",
      "train loss:1.238504556148453\n",
      "train loss:1.3345620941359941\n",
      "train loss:1.247001324722696\n",
      "train loss:1.1582141844559413\n",
      "train loss:1.0843509345047602\n",
      "train loss:1.044458309982835\n",
      "train loss:1.014282542783157\n",
      "train loss:1.0530654466049094\n",
      "train loss:1.138279514539315\n",
      "train loss:1.3820497390299251\n",
      "train loss:1.0928684945790963\n",
      "train loss:1.3284462072398424\n",
      "train loss:1.2648477687893322\n",
      "train loss:1.0678570003439727\n",
      "train loss:1.1096048657173072\n",
      "train loss:1.1660608895403368\n",
      "train loss:1.1179788453006652\n",
      "train loss:1.1807150929533319\n",
      "train loss:0.9188468119869974\n",
      "train loss:1.0682602699521795\n",
      "train loss:1.3410931833125992\n",
      "train loss:1.167934898968971\n",
      "train loss:1.0146703153652095\n",
      "train loss:1.2151614764369045\n",
      "train loss:1.09162601045824\n",
      "train loss:0.8898175484604639\n",
      "train loss:1.0652569971918133\n",
      "train loss:1.1038221231155727\n",
      "train loss:1.2302790293861887\n",
      "train loss:1.0657359357496121\n",
      "train loss:1.1233094041932814\n",
      "train loss:1.2534411254659703\n",
      "train loss:1.305302752723528\n",
      "train loss:1.2008587864126847\n",
      "train loss:1.171681016928877\n",
      "train loss:1.2461541063889\n",
      "train loss:1.1802398300888461\n",
      "train loss:1.1808467610090965\n",
      "train loss:1.1493812967201817\n",
      "train loss:1.1480361333315583\n",
      "train loss:1.4034433702138025\n",
      "train loss:1.1660292310136111\n",
      "train loss:1.2042669388147658\n",
      "train loss:1.1377531942569366\n",
      "train loss:1.1957867439769434\n",
      "train loss:1.2450194028912045\n",
      "train loss:1.2688535026117602\n",
      "train loss:1.1028617312281122\n",
      "train loss:1.3170699114596638\n",
      "train loss:1.0470491039051562\n",
      "train loss:1.272750997865372\n",
      "train loss:1.1392602694806018\n",
      "train loss:1.1779265497268852\n",
      "train loss:1.0419356114406089\n",
      "train loss:1.222941909132762\n",
      "train loss:1.1872637565834738\n",
      "train loss:1.0144338474883114\n",
      "train loss:1.0963950548416925\n",
      "train loss:0.999603081506039\n",
      "train loss:1.2850858605530404\n",
      "train loss:1.124756832174462\n",
      "train loss:1.0928527093186804\n",
      "train loss:1.2790447215907694\n",
      "train loss:1.0206979220402304\n",
      "train loss:1.1080024259398178\n",
      "train loss:1.141814671193478\n",
      "train loss:1.169071323311631\n",
      "train loss:1.008681594328235\n",
      "train loss:1.0403687677535327\n",
      "train loss:0.9905007495480457\n",
      "train loss:1.0616749761246007\n",
      "train loss:1.0785380942775697\n",
      "train loss:1.1582380644955108\n",
      "train loss:1.20717696057116\n",
      "train loss:1.1773361080849063\n",
      "train loss:1.2960650611892819\n",
      "train loss:1.2482323009120604\n",
      "train loss:1.0694396779979123\n",
      "train loss:1.0706779998556437\n",
      "train loss:1.167535491825903\n",
      "train loss:1.2925191098309083\n",
      "train loss:1.0925968855780044\n",
      "train loss:1.3753712524236286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.289648983784929\n",
      "train loss:1.0394147594605092\n",
      "train loss:1.1465808205150105\n",
      "train loss:1.2293600649906073\n",
      "train loss:1.1667355453354675\n",
      "train loss:1.0199523494964415\n",
      "train loss:1.0718015869334032\n",
      "train loss:1.2328216186660539\n",
      "train loss:1.193560875691335\n",
      "train loss:1.1523532964319323\n",
      "train loss:1.0637531796535749\n",
      "train loss:1.1898022419202723\n",
      "train loss:1.135603377229959\n",
      "train loss:1.0188576816309\n",
      "train loss:0.995268903344637\n",
      "train loss:1.0140632519754162\n",
      "train loss:1.160947252762016\n",
      "train loss:1.1217881512732264\n",
      "train loss:1.2659535688792665\n",
      "train loss:1.1442060981345512\n",
      "train loss:1.0764278443243604\n",
      "train loss:1.2158215655403053\n",
      "train loss:1.1163104237389476\n",
      "train loss:1.0319834375796941\n",
      "train loss:1.1829253132300217\n",
      "train loss:1.0403835449570378\n",
      "train loss:1.1981778933142038\n",
      "train loss:1.1688638906210722\n",
      "train loss:1.0214812351602276\n",
      "train loss:1.1396426054428148\n",
      "train loss:1.1742558881297267\n",
      "train loss:1.338403970404477\n",
      "train loss:1.0923660643487323\n",
      "train loss:0.9615823964350771\n",
      "train loss:1.1610543678860186\n",
      "train loss:1.2046166711256272\n",
      "train loss:1.0452313372674338\n",
      "train loss:1.1306121975158367\n",
      "train loss:1.0972449150939003\n",
      "train loss:1.1114475492976117\n",
      "train loss:1.2014228909745395\n",
      "train loss:1.269221453034002\n",
      "train loss:1.0355241249125793\n",
      "train loss:1.1056350061264193\n",
      "train loss:1.0159564771942866\n",
      "train loss:1.0903871357489852\n",
      "train loss:1.0745717315086625\n",
      "train loss:1.1624572396555068\n",
      "train loss:1.209022567010055\n",
      "train loss:0.9371272882609789\n",
      "train loss:1.1683214245503806\n",
      "train loss:1.2557683231189218\n",
      "train loss:1.21356960868401\n",
      "train loss:1.214855108850384\n",
      "train loss:1.1564220218729822\n",
      "train loss:1.128494253438217\n",
      "train loss:1.100363852304813\n",
      "train loss:1.3632608056659643\n",
      "train loss:1.2102136239397394\n",
      "train loss:1.248727656209959\n",
      "train loss:1.4090151963459496\n",
      "train loss:1.133114459943216\n",
      "train loss:0.9675956221101203\n",
      "train loss:1.2016262258611239\n",
      "train loss:1.011068208221266\n",
      "train loss:1.3078246977127923\n",
      "train loss:1.217468979351287\n",
      "train loss:1.179610304538066\n",
      "train loss:1.019331567200407\n",
      "train loss:1.3283721672467974\n",
      "train loss:1.255006061072656\n",
      "train loss:1.2652242024436366\n",
      "train loss:1.0634318238339033\n",
      "train loss:1.133694957088337\n",
      "train loss:1.0078054799762013\n",
      "train loss:1.066730776558022\n",
      "train loss:1.0303432313958287\n",
      "train loss:1.042617453459105\n",
      "train loss:1.0663780119564301\n",
      "train loss:1.2736492040210545\n",
      "train loss:1.0982470816289012\n",
      "train loss:0.8748495481209692\n",
      "train loss:1.116287134020364\n",
      "train loss:1.2668548217364854\n",
      "train loss:1.245704691252801\n",
      "train loss:1.2735711145387631\n",
      "train loss:0.9431698441512478\n",
      "train loss:1.2475803217663195\n",
      "train loss:0.9645961840024857\n",
      "train loss:1.1490379587955069\n",
      "train loss:1.0792024767399961\n",
      "train loss:0.9969406564189787\n",
      "train loss:1.2575334761971018\n",
      "train loss:1.1032551962413342\n",
      "train loss:1.058696548844882\n",
      "train loss:1.1663842812177725\n",
      "train loss:1.1672623644930933\n",
      "train loss:1.1840426286771768\n",
      "train loss:1.109707155392249\n",
      "train loss:0.9881148500977013\n",
      "train loss:1.1323684121271644\n",
      "train loss:1.2249786413505448\n",
      "train loss:1.3587735832024135\n",
      "train loss:1.185271156895625\n",
      "train loss:1.1295432495595792\n",
      "train loss:1.2315419003997372\n",
      "train loss:0.9904844831259253\n",
      "train loss:1.1354663526073727\n",
      "train loss:1.1879834648433762\n",
      "train loss:1.0865588886158257\n",
      "train loss:1.1699108389519237\n",
      "train loss:1.3000081127043734\n",
      "train loss:1.0025740763543416\n",
      "train loss:1.098325612613356\n",
      "train loss:1.0654643517439484\n",
      "train loss:1.2324682086898275\n",
      "train loss:0.9696321975223278\n",
      "train loss:1.1308905136698748\n",
      "train loss:1.1698046712912924\n",
      "train loss:1.3224328556499836\n",
      "train loss:1.0754440270302361\n",
      "train loss:1.0191443497569863\n",
      "train loss:1.1993599680988674\n",
      "train loss:1.030073513119179\n",
      "train loss:1.0140487814010721\n",
      "train loss:1.011429020287791\n",
      "train loss:0.9141571171057826\n",
      "train loss:1.2422917035248313\n",
      "train loss:0.9473099658445382\n",
      "train loss:1.103313841779486\n",
      "train loss:1.121220278984699\n",
      "train loss:1.2315484399310486\n",
      "train loss:1.1641551989439405\n",
      "train loss:1.0058497456729532\n",
      "train loss:1.1407394809049\n",
      "train loss:1.1626629997574673\n",
      "train loss:1.244052481273733\n",
      "train loss:1.237348914654179\n",
      "train loss:1.3523945305190403\n",
      "train loss:1.0301848680708918\n",
      "train loss:1.1145732860149236\n",
      "train loss:1.0507729927101412\n",
      "train loss:1.0930259016249366\n",
      "train loss:1.1059913445724268\n",
      "train loss:1.087990567441764\n",
      "train loss:1.2822488416318096\n",
      "train loss:1.1647296329058725\n",
      "train loss:0.990280951540117\n",
      "train loss:1.041899204661359\n",
      "train loss:1.0718189211300704\n",
      "train loss:1.1536154911797738\n",
      "train loss:1.191175319752516\n",
      "train loss:1.0713995286905427\n",
      "train loss:1.037494167575276\n",
      "train loss:1.312251219376704\n",
      "train loss:1.109307763727435\n",
      "train loss:1.0444469918991535\n",
      "train loss:1.1368825044025286\n",
      "train loss:1.1591173443896476\n",
      "train loss:1.070129363956449\n",
      "train loss:1.0226555404436652\n",
      "train loss:1.1435890556209634\n",
      "train loss:1.0499829177791482\n",
      "train loss:1.2039925349006912\n",
      "train loss:1.305879179176753\n",
      "train loss:1.2280483475401291\n",
      "train loss:1.292599247421365\n",
      "train loss:1.0641788960863088\n",
      "train loss:1.0189500916741694\n",
      "train loss:1.1490163015570776\n",
      "train loss:1.0276058875454996\n",
      "train loss:1.1349067548771794\n",
      "train loss:1.084174432712702\n",
      "train loss:1.109048688515283\n",
      "train loss:1.2813966011608888\n",
      "train loss:1.0410581596656732\n",
      "train loss:1.0756104984455952\n",
      "train loss:1.080462138966214\n",
      "train loss:1.2159878609905177\n",
      "train loss:1.1313373337445631\n",
      "train loss:1.3590799279986836\n",
      "train loss:1.199815884540554\n",
      "train loss:1.1951087588316867\n",
      "train loss:1.0321507019922749\n",
      "train loss:1.0071294273933404\n",
      "train loss:1.1801887128443347\n",
      "train loss:1.205944936617898\n",
      "train loss:1.0093155115223755\n",
      "train loss:0.9552227997247426\n",
      "train loss:1.0168883093054097\n",
      "train loss:1.0924327415739084\n",
      "train loss:1.0386249550494984\n",
      "train loss:1.0029261649900547\n",
      "train loss:1.049635355662074\n",
      "train loss:1.123219751908068\n",
      "train loss:1.1808433445423647\n",
      "train loss:1.1136911447968536\n",
      "train loss:1.3118469652814093\n",
      "train loss:1.0688265843953129\n",
      "train loss:0.9326210366477473\n",
      "train loss:1.140511083537351\n",
      "train loss:1.005617420833064\n",
      "train loss:1.181088655247387\n",
      "train loss:1.0524513356396268\n",
      "train loss:1.1675533674689\n",
      "train loss:1.3354796807001872\n",
      "train loss:0.9241431565092197\n",
      "train loss:1.1435220812304197\n",
      "train loss:1.0574027436062814\n",
      "train loss:1.0163581494718925\n",
      "train loss:1.177888622471361\n",
      "train loss:0.895588530808134\n",
      "train loss:1.1895224916563532\n",
      "train loss:1.1375759648095505\n",
      "train loss:1.3104215381301314\n",
      "train loss:1.1656157745887865\n",
      "train loss:0.9580066807732629\n",
      "train loss:1.0935113951618534\n",
      "train loss:1.2103587424554691\n",
      "train loss:1.2053866578286914\n",
      "train loss:1.2350949284626567\n",
      "train loss:1.186006892318346\n",
      "train loss:1.295637248557807\n",
      "train loss:1.0253478556629019\n",
      "train loss:1.1641704816703125\n",
      "train loss:1.1237205765658356\n",
      "train loss:1.1524411289002807\n",
      "train loss:1.2781418500239823\n",
      "train loss:1.0946535195755311\n",
      "train loss:1.1426849927691094\n",
      "train loss:1.1729639866255281\n",
      "train loss:1.039426952312223\n",
      "train loss:0.9967503287918303\n",
      "train loss:0.9928590871697629\n",
      "train loss:1.157800969836556\n",
      "train loss:1.1829092751108\n",
      "train loss:1.0828989166418055\n",
      "train loss:1.106561229788332\n",
      "train loss:1.2597856752902608\n",
      "train loss:1.2422264309644255\n",
      "train loss:1.1260696089443463\n",
      "train loss:1.193023364153703\n",
      "train loss:0.9897195871820176\n",
      "train loss:0.9344449873962857\n",
      "train loss:1.093239155077396\n",
      "train loss:0.9785978486205309\n",
      "train loss:1.0045369242189741\n",
      "train loss:0.9349621513370208\n",
      "train loss:1.1721058802194246\n",
      "train loss:1.2070251603957467\n",
      "train loss:0.9796492386813813\n",
      "train loss:1.1558875243659614\n",
      "train loss:1.2343018878083\n",
      "train loss:1.2461477239630114\n",
      "train loss:1.095720389320613\n",
      "train loss:1.1876558743040875\n",
      "train loss:1.0120210348326275\n",
      "train loss:1.0288234540448833\n",
      "train loss:0.9584325914284529\n",
      "train loss:1.0678230355048488\n",
      "train loss:1.0380756748002977\n",
      "train loss:1.0520827866087419\n",
      "train loss:1.0570809854941623\n",
      "train loss:1.0893096683126218\n",
      "train loss:1.1816552086366567\n",
      "train loss:1.1627541546710922\n",
      "train loss:1.129372050281934\n",
      "train loss:1.1219627990459484\n",
      "train loss:1.061307348285959\n",
      "train loss:1.0873773875379737\n",
      "train loss:1.150472267674548\n",
      "train loss:1.1892049273624041\n",
      "train loss:1.0677456422247642\n",
      "train loss:1.2850466188981384\n",
      "train loss:1.2863975681085678\n",
      "train loss:0.9078106099298902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.147884215514296\n",
      "train loss:1.3133329620176073\n",
      "train loss:0.8737173434785389\n",
      "train loss:1.218693762002414\n",
      "train loss:1.3240964250149987\n",
      "train loss:1.0403449232639987\n",
      "train loss:1.1625567909292474\n",
      "train loss:1.1466754076028138\n",
      "train loss:1.1634824674051696\n",
      "train loss:1.1111887454690654\n",
      "train loss:0.9429481003455009\n",
      "train loss:1.2358715391319794\n",
      "train loss:1.0496930671542395\n",
      "train loss:1.2269642700232781\n",
      "train loss:1.1923557052121376\n",
      "train loss:1.0041954115092835\n",
      "train loss:1.045830324175167\n",
      "train loss:1.1302190837497914\n",
      "train loss:1.1289870698213647\n",
      "train loss:1.0810969316154297\n",
      "train loss:1.1487518066166025\n",
      "train loss:1.1451912918555618\n",
      "train loss:1.1727414359861148\n",
      "train loss:1.0845286667961862\n",
      "train loss:1.1342609763305067\n",
      "train loss:1.109876549168025\n",
      "train loss:1.2707103418009857\n",
      "train loss:1.026752040792051\n",
      "train loss:1.0582944863666444\n",
      "train loss:1.1184286783316493\n",
      "train loss:1.0526785289232103\n",
      "train loss:1.1551398410144778\n",
      "train loss:1.0012603443043409\n",
      "train loss:1.122111385685384\n",
      "train loss:0.9137607405195408\n",
      "train loss:1.077957133713945\n",
      "train loss:1.005330506560999\n",
      "train loss:1.0654339975157554\n",
      "train loss:1.0518753850837768\n",
      "train loss:0.8446880991286837\n",
      "train loss:0.9933776018207565\n",
      "train loss:1.3129153781767051\n",
      "train loss:1.102311869345795\n",
      "train loss:1.358256199861667\n",
      "train loss:1.1177342492395395\n",
      "train loss:1.095554793586719\n",
      "train loss:1.1607615207534858\n",
      "train loss:1.1980280844365765\n",
      "train loss:1.1690236587657197\n",
      "train loss:1.0694509766658822\n",
      "train loss:1.0565000441789154\n",
      "train loss:1.206041517192643\n",
      "train loss:1.2401513759390312\n",
      "train loss:1.1488555589774794\n",
      "train loss:1.071278945527627\n",
      "train loss:1.1188096233949836\n",
      "train loss:1.2357428213709376\n",
      "train loss:1.2145824318185339\n",
      "train loss:1.0842925714618488\n",
      "train loss:1.0258559819386406\n",
      "train loss:1.08947733854026\n",
      "train loss:1.0289077693484796\n",
      "train loss:1.0264523993967523\n",
      "train loss:1.1195686402634393\n",
      "train loss:1.1440906930648802\n",
      "train loss:1.3134231314304905\n",
      "train loss:1.175795892487975\n",
      "train loss:1.08436385395306\n",
      "train loss:1.0565544340608488\n",
      "train loss:1.2785002211168517\n",
      "train loss:1.225950448881444\n",
      "train loss:1.0641760118113834\n",
      "train loss:1.1622234689118427\n",
      "train loss:1.0168493626250403\n",
      "train loss:1.0103932961665152\n",
      "train loss:1.1157542599032815\n",
      "train loss:1.0998282239290453\n",
      "train loss:1.2989479254170246\n",
      "train loss:1.0221332280987114\n",
      "train loss:1.1285814376295837\n",
      "train loss:0.986956989689299\n",
      "train loss:1.2021857945918404\n",
      "train loss:1.1574669983699146\n",
      "train loss:1.075821578215077\n",
      "train loss:1.0509679019519957\n",
      "train loss:1.0440129282159227\n",
      "train loss:1.0684256523594724\n",
      "train loss:1.0494273129592888\n",
      "train loss:0.9485873993272537\n",
      "train loss:1.1069802094248822\n",
      "train loss:1.1058627562405103\n",
      "train loss:1.0005761251433583\n",
      "train loss:0.9435759464205716\n",
      "train loss:0.8831288677916431\n",
      "train loss:1.1402473409152014\n",
      "train loss:1.0321862748016264\n",
      "train loss:0.9781929973658725\n",
      "train loss:1.2128035946358617\n",
      "train loss:1.2712827011554402\n",
      "train loss:1.0983221482346042\n",
      "train loss:1.3961314967577265\n",
      "train loss:1.1075003911670576\n",
      "train loss:1.1464555119149955\n",
      "train loss:1.1832011161393143\n",
      "train loss:0.9999527329066623\n",
      "train loss:1.0332853543190845\n",
      "train loss:1.1170462440272582\n",
      "train loss:1.178811956847801\n",
      "train loss:1.1505340087044433\n",
      "train loss:1.1981205251849214\n",
      "train loss:1.0763379219018827\n",
      "train loss:1.0970838694532596\n",
      "train loss:1.0948493831293846\n",
      "train loss:1.1738700254485845\n",
      "train loss:1.0693576263209443\n",
      "train loss:1.3604500198716765\n",
      "train loss:1.3342809346322002\n",
      "train loss:1.1913998071312701\n",
      "train loss:1.0167220724674588\n",
      "train loss:1.1916665483110744\n",
      "train loss:1.1883856333310738\n",
      "train loss:0.9768268745186672\n",
      "train loss:1.1477958593301343\n",
      "train loss:1.0839348098602182\n",
      "train loss:0.9457176164814999\n",
      "train loss:1.1901722016182898\n",
      "train loss:1.0155091486534888\n",
      "train loss:1.108309076919995\n",
      "train loss:1.095824002729685\n",
      "train loss:1.2784258406100737\n",
      "train loss:1.1673532769054866\n",
      "train loss:1.0617162534674576\n",
      "train loss:1.0965866833410542\n",
      "train loss:1.1357624170299025\n",
      "train loss:1.1910895904433356\n",
      "train loss:1.1274484727790643\n",
      "train loss:1.0406939030713678\n",
      "train loss:1.1754453611989057\n",
      "train loss:1.0613059238577447\n",
      "train loss:1.1028188096823641\n",
      "train loss:1.1051502249522431\n",
      "train loss:1.3058144601083526\n",
      "train loss:1.0361490930709751\n",
      "train loss:1.1797947517196414\n",
      "train loss:1.104269707592114\n",
      "train loss:1.007754688167379\n",
      "train loss:1.1345996986762474\n",
      "train loss:0.7273210955113679\n",
      "train loss:1.1616840360561718\n",
      "train loss:1.1402318627919312\n",
      "=== epoch:4, train acc:0.969, test acc:0.965 ===\n",
      "train loss:1.0001196548745752\n",
      "train loss:1.1367709167630962\n",
      "train loss:1.0265021019530323\n",
      "train loss:1.0924135503515247\n",
      "train loss:1.0147541460297438\n",
      "train loss:1.0260939014816055\n",
      "train loss:1.1407662808110477\n",
      "train loss:1.1869987181367885\n",
      "train loss:1.156368599877711\n",
      "train loss:1.0318257127047417\n",
      "train loss:1.1359813445228195\n",
      "train loss:0.9443905163321393\n",
      "train loss:1.2524882371718307\n",
      "train loss:1.1218592995319696\n",
      "train loss:0.9225873825240046\n",
      "train loss:1.0681493950785286\n",
      "train loss:1.1625024436582359\n",
      "train loss:1.0881282768990859\n",
      "train loss:1.2036574253232746\n",
      "train loss:1.1806707607838611\n",
      "train loss:1.1391374667202718\n",
      "train loss:1.1151708529243718\n",
      "train loss:1.2271721228355323\n",
      "train loss:1.0342701527971503\n",
      "train loss:0.8474357965068171\n",
      "train loss:1.1085106143659644\n",
      "train loss:1.10614764571463\n",
      "train loss:1.0556442340944938\n",
      "train loss:0.9489532812781509\n",
      "train loss:1.1843070452044115\n",
      "train loss:1.1124086084473583\n",
      "train loss:1.093593884655834\n",
      "train loss:1.1698052655212907\n",
      "train loss:1.1890093912623783\n",
      "train loss:0.9567436392467389\n",
      "train loss:1.0610328847582386\n",
      "train loss:1.128633716767635\n",
      "train loss:1.1513775515212832\n",
      "train loss:1.1537402176728606\n",
      "train loss:1.1549638757075436\n",
      "train loss:1.0507825228747711\n",
      "train loss:0.8576481154401883\n",
      "train loss:1.2274763156291713\n",
      "train loss:1.104808141157262\n",
      "train loss:1.0668908910604642\n",
      "train loss:0.8878643571338949\n",
      "train loss:1.1548994622616264\n",
      "train loss:1.1497682533678042\n",
      "train loss:0.9806343648073009\n",
      "train loss:1.100329655602202\n",
      "train loss:0.9473109680367606\n",
      "train loss:1.2446447417584419\n",
      "train loss:1.22011018078234\n",
      "train loss:1.1217394967049126\n",
      "train loss:0.892010654845423\n",
      "train loss:1.10740132297937\n",
      "train loss:1.0425459980212741\n",
      "train loss:1.0851606186556668\n",
      "train loss:1.0726325062544277\n",
      "train loss:1.0307117544370186\n",
      "train loss:1.161119233107201\n",
      "train loss:1.1834965029421758\n",
      "train loss:1.0713157837765088\n",
      "train loss:1.1778490798888581\n",
      "train loss:1.1399014162559944\n",
      "train loss:1.0077593955501836\n",
      "train loss:0.9878429581932209\n",
      "train loss:1.1175392979739927\n",
      "train loss:0.8423018389352704\n",
      "train loss:1.0516831493493575\n",
      "train loss:1.1759171027886026\n",
      "train loss:1.025745147810107\n",
      "train loss:1.0002387582104373\n",
      "train loss:1.3439127453963389\n",
      "train loss:1.0679994395280203\n",
      "train loss:1.1352407261481303\n",
      "train loss:1.16532954218677\n",
      "train loss:1.1299560781439784\n",
      "train loss:1.1647620260166038\n",
      "train loss:1.0038727582466394\n",
      "train loss:1.0768382043765086\n",
      "train loss:1.0650299588773846\n",
      "train loss:1.1332580584946215\n",
      "train loss:1.1970143857480242\n",
      "train loss:1.2513869345926083\n",
      "train loss:1.1953568418714762\n",
      "train loss:1.0086030765597125\n",
      "train loss:1.1870464665718894\n",
      "train loss:0.9737754760959035\n",
      "train loss:1.215066830981287\n",
      "train loss:1.13644022483046\n",
      "train loss:0.9407274480910779\n",
      "train loss:0.9645730906345491\n",
      "train loss:1.0918353583878642\n",
      "train loss:1.1415005711369177\n",
      "train loss:0.9837567677816685\n",
      "train loss:1.050467411505164\n",
      "train loss:1.0693438077335262\n",
      "train loss:1.0007620565820625\n",
      "train loss:1.100218962616903\n",
      "train loss:0.914284562260451\n",
      "train loss:1.022412530860005\n",
      "train loss:1.1491493383496267\n",
      "train loss:1.134884299909092\n",
      "train loss:1.2463180202341269\n",
      "train loss:1.1539728766485022\n",
      "train loss:0.9812745961083371\n",
      "train loss:1.010936029645817\n",
      "train loss:1.1361148911445684\n",
      "train loss:0.9257037940512555\n",
      "train loss:1.0147062141368137\n",
      "train loss:1.1586356612211428\n",
      "train loss:1.1436248079551765\n",
      "train loss:1.0487198024028683\n",
      "train loss:1.0520421980591148\n",
      "train loss:0.9755737196030065\n",
      "train loss:1.0050404095007726\n",
      "train loss:1.272906909802317\n",
      "train loss:0.9011641255781454\n",
      "train loss:1.2154436644102582\n",
      "train loss:1.0270727033554328\n",
      "train loss:1.0292011021051135\n",
      "train loss:1.1095421072062923\n",
      "train loss:1.2490033211207696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.1163694612018147\n",
      "train loss:1.1400838606931516\n",
      "train loss:0.9662093855685677\n",
      "train loss:1.0003819024997027\n",
      "train loss:1.0365910463132841\n",
      "train loss:1.1383133743964238\n",
      "train loss:1.2012799950633395\n",
      "train loss:1.171079651220588\n",
      "train loss:1.1765827400375874\n",
      "train loss:1.1379867446180763\n",
      "train loss:1.1371425592656685\n",
      "train loss:0.8990800405750591\n",
      "train loss:1.3317937502247241\n",
      "train loss:1.1161106144091644\n",
      "train loss:1.1523086393821904\n",
      "train loss:1.0964566176653963\n",
      "train loss:1.1420214220417941\n",
      "train loss:0.9907843618882332\n",
      "train loss:1.0628745657155172\n",
      "train loss:0.9420716972990616\n",
      "train loss:1.0405597366496877\n",
      "train loss:1.199626907014601\n",
      "train loss:1.135069624249644\n",
      "train loss:1.049308030221376\n",
      "train loss:1.2502951963517386\n",
      "train loss:1.039927693755947\n",
      "train loss:1.0722098552102517\n",
      "train loss:0.9547164413567988\n",
      "train loss:1.0371503825644692\n",
      "train loss:1.0502883973520023\n",
      "train loss:1.079771374709674\n",
      "train loss:1.074024355631182\n",
      "train loss:0.995388326978634\n",
      "train loss:1.1083373557564031\n",
      "train loss:1.1220261454824725\n",
      "train loss:1.078368485170079\n",
      "train loss:1.234784666420648\n",
      "train loss:1.143240899517197\n",
      "train loss:1.120786576070562\n",
      "train loss:1.0028296592603256\n",
      "train loss:1.0657200673514147\n",
      "train loss:0.8253246076646299\n",
      "train loss:1.2971467657274252\n",
      "train loss:1.1581858809503955\n",
      "train loss:1.322702450336556\n",
      "train loss:1.0758744058141358\n",
      "train loss:1.0627081204678044\n",
      "train loss:1.1393267451876947\n",
      "train loss:0.999687381145878\n",
      "train loss:1.182005911453684\n",
      "train loss:1.130450587562056\n",
      "train loss:0.9973372427396582\n",
      "train loss:1.091946965257299\n",
      "train loss:1.1366599024615105\n",
      "train loss:1.3176171598518756\n",
      "train loss:1.2069752632848594\n",
      "train loss:1.0629374500648212\n",
      "train loss:1.1887718866272154\n",
      "train loss:1.0580863307988786\n",
      "train loss:1.0042457403539975\n",
      "train loss:1.3262820607978123\n",
      "train loss:1.2465718095134042\n",
      "train loss:1.0756483274323385\n",
      "train loss:1.253934070219754\n",
      "train loss:1.1116642913715993\n",
      "train loss:1.1268635871405315\n",
      "train loss:1.1102041354510601\n",
      "train loss:1.005971387524318\n",
      "train loss:1.0517022257014776\n",
      "train loss:1.1458315415175189\n",
      "train loss:1.0380165749047279\n",
      "train loss:0.9886676911664964\n",
      "train loss:1.048124805363878\n",
      "train loss:1.1919162556569711\n",
      "train loss:1.1442334782101051\n",
      "train loss:0.9909898293008504\n",
      "train loss:1.1275977212122816\n",
      "train loss:0.9618363533860419\n",
      "train loss:1.1232116169087296\n",
      "train loss:1.0604402789537823\n",
      "train loss:0.9078956899812597\n",
      "train loss:0.9669011886391686\n",
      "train loss:1.1370301660914297\n",
      "train loss:1.0074464592996715\n",
      "train loss:1.0813191904919457\n",
      "train loss:1.2185676272721788\n",
      "train loss:1.0911871431812152\n",
      "train loss:1.0008461244321962\n",
      "train loss:1.015829844603455\n",
      "train loss:1.0337691590131672\n",
      "train loss:1.19075025930137\n",
      "train loss:1.180747513784184\n",
      "train loss:1.104667982124709\n",
      "train loss:1.252285953234497\n",
      "train loss:0.962926246474526\n",
      "train loss:1.0213982614102914\n",
      "train loss:0.9373276603804216\n",
      "train loss:1.099072943249962\n",
      "train loss:0.9172764259577271\n",
      "train loss:1.099840264731034\n",
      "train loss:1.0516008728637514\n",
      "train loss:1.1351889846951868\n",
      "train loss:1.03550236781972\n",
      "train loss:1.0629607493719413\n",
      "train loss:0.9633148113689936\n",
      "train loss:1.1189761159895164\n",
      "train loss:1.0869394119787414\n",
      "train loss:1.0834919258189337\n",
      "train loss:0.920647676377796\n",
      "train loss:0.9166056995771678\n",
      "train loss:0.9961142365586264\n",
      "train loss:1.1916523613477707\n",
      "train loss:1.0853565936067466\n",
      "train loss:0.9808572115983363\n",
      "train loss:1.0881116030704667\n",
      "train loss:1.1184104140093636\n",
      "train loss:0.9680230204331213\n",
      "train loss:1.0536769840719922\n",
      "train loss:1.0662335933019798\n",
      "train loss:1.0836580579021544\n",
      "train loss:1.0183795052563014\n",
      "train loss:1.0419562735237713\n",
      "train loss:1.135791292511947\n",
      "train loss:1.1685010817509276\n",
      "train loss:1.2201324464326322\n",
      "train loss:1.185698038029349\n",
      "train loss:1.2106734640499022\n",
      "train loss:0.9433375762467222\n",
      "train loss:0.978572375055777\n",
      "train loss:1.1383205670629866\n",
      "train loss:1.0038752058469382\n",
      "train loss:1.038352726824106\n",
      "train loss:1.0353164873403453\n",
      "train loss:1.0633370865889586\n",
      "train loss:0.9527928343307043\n",
      "train loss:1.0408818314174055\n",
      "train loss:1.130083362414255\n",
      "train loss:1.1118010607132927\n",
      "train loss:1.076022790451927\n",
      "train loss:1.2405284189179369\n",
      "train loss:1.0506949684735951\n",
      "train loss:1.3543461015152138\n",
      "train loss:0.8626089482657189\n",
      "train loss:0.9764463672270415\n",
      "train loss:0.8622027668199008\n",
      "train loss:1.1453603188045556\n",
      "train loss:1.0856809558048517\n",
      "train loss:1.0421279498168807\n",
      "train loss:1.0001816295270654\n",
      "train loss:1.1624723930397105\n",
      "train loss:1.2302027905938706\n",
      "train loss:1.053882248291284\n",
      "train loss:1.0654061352028237\n",
      "train loss:1.0441394517308262\n",
      "train loss:1.0244066594105647\n",
      "train loss:1.1784016939719235\n",
      "train loss:1.1910867500991962\n",
      "train loss:1.1622110871213431\n",
      "train loss:1.033891730327967\n",
      "train loss:1.0793265966437366\n",
      "train loss:0.8733216920405666\n",
      "train loss:0.9897417596525806\n",
      "train loss:1.1607270202154658\n",
      "train loss:1.1072793883542495\n",
      "train loss:1.0755149571244884\n",
      "train loss:0.9130354774960122\n",
      "train loss:1.0478717542064269\n",
      "train loss:1.246708987284228\n",
      "train loss:1.038540216183506\n",
      "train loss:0.9145099204122817\n",
      "train loss:1.0845017024882033\n",
      "train loss:1.0093678541392264\n",
      "train loss:1.009325252186524\n",
      "train loss:1.1920469485514777\n",
      "train loss:1.0913106051437216\n",
      "train loss:1.1493631728660187\n",
      "train loss:1.18223140302431\n",
      "train loss:0.9674041973851234\n",
      "train loss:1.0506271281441708\n",
      "train loss:1.173873840861699\n",
      "train loss:1.237004214458898\n",
      "train loss:0.9448990803366923\n",
      "train loss:1.0504885822414969\n",
      "train loss:0.8859366223136833\n",
      "train loss:1.0560223206436914\n",
      "train loss:1.0689650507447555\n",
      "train loss:1.0019881684857426\n",
      "train loss:1.0322718951864804\n",
      "train loss:1.1024114084443424\n",
      "train loss:1.2789896153177276\n",
      "train loss:1.0431202421824526\n",
      "train loss:1.1581536102600272\n",
      "train loss:1.213446592042987\n",
      "train loss:1.0960052008791052\n",
      "train loss:1.0142507137294257\n",
      "train loss:1.1165650748126272\n",
      "train loss:1.0472704615463078\n",
      "train loss:1.2808440048016883\n",
      "train loss:1.1598185568129047\n",
      "train loss:1.0112457361905312\n",
      "train loss:0.932023415707247\n",
      "train loss:0.9963994631917863\n",
      "train loss:0.9329114506198019\n",
      "train loss:1.0890943351708033\n",
      "train loss:1.1101731915996762\n",
      "train loss:1.1460383381934018\n",
      "train loss:1.0072141319874366\n",
      "train loss:1.0426146208031788\n",
      "train loss:1.1153786660224159\n",
      "train loss:0.9195370195353298\n",
      "train loss:1.1705785604097374\n",
      "train loss:1.008952250118207\n",
      "train loss:1.0209864891764402\n",
      "train loss:1.044448046617535\n",
      "train loss:1.2413991942275573\n",
      "train loss:1.159059305796382\n",
      "train loss:1.2801742373021006\n",
      "train loss:1.0454042613404322\n",
      "train loss:1.0778018785514392\n",
      "train loss:1.092834001056581\n",
      "train loss:1.1160584990223907\n",
      "train loss:1.0892764926830905\n",
      "train loss:0.9908405746527089\n",
      "train loss:1.0957543552908782\n",
      "train loss:0.975112755248154\n",
      "train loss:1.0462626247455058\n",
      "train loss:1.0811908411334092\n",
      "train loss:1.042629299493731\n",
      "train loss:1.0359124778734923\n",
      "train loss:1.1888410319924214\n",
      "train loss:1.2293166736757692\n",
      "train loss:1.106940409014948\n",
      "train loss:0.8963964707203067\n",
      "train loss:1.0361092815657431\n",
      "train loss:1.131217959759265\n",
      "train loss:1.0004790786816724\n",
      "train loss:1.2044767538682142\n",
      "train loss:0.9891489985067052\n",
      "train loss:1.1050371559354852\n",
      "train loss:0.9300703463674442\n",
      "train loss:1.0203205058189109\n",
      "train loss:0.9847335166476172\n",
      "train loss:1.0725464205402095\n",
      "train loss:1.1034896355286956\n",
      "train loss:1.09964612035513\n",
      "train loss:1.037518318742373\n",
      "train loss:1.0117452102731008\n",
      "train loss:1.0308663012221053\n",
      "train loss:1.0456308650123771\n",
      "train loss:0.9456581432280893\n",
      "train loss:1.0305776237834987\n",
      "train loss:1.1521272922755839\n",
      "train loss:1.1235367779097531\n",
      "train loss:1.2950746642429078\n",
      "train loss:1.0324546839801902\n",
      "train loss:0.9411764287771561\n",
      "train loss:1.0721514592860453\n",
      "train loss:1.1461359004200242\n",
      "train loss:0.9344960488472044\n",
      "train loss:0.9842410750360137\n",
      "train loss:1.3831671605340483\n",
      "train loss:1.0508109884744663\n",
      "train loss:1.066513015572153\n",
      "train loss:0.998588056081136\n",
      "train loss:1.024386609289589\n",
      "train loss:1.091353918971813\n",
      "train loss:1.0138312350477512\n",
      "train loss:0.8998764196326615\n",
      "train loss:0.9974025519666668\n",
      "train loss:1.1017754003220417\n",
      "train loss:0.9824964541230478\n",
      "train loss:1.1982005449669837\n",
      "train loss:1.333643853693711\n",
      "train loss:1.0429014706510573\n",
      "train loss:1.039299833100077\n",
      "train loss:1.1075241228446566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.0706575894614818\n",
      "train loss:1.1077572500543709\n",
      "train loss:1.1440960429007294\n",
      "train loss:1.106623741196917\n",
      "train loss:1.0528161155554665\n",
      "train loss:1.0395692726322219\n",
      "train loss:0.9239235539921701\n",
      "train loss:1.0459235273880259\n",
      "train loss:1.1067865937165193\n",
      "train loss:0.9907969411795412\n",
      "train loss:1.0333934997050134\n",
      "train loss:1.0214911179677428\n",
      "train loss:0.9501166351217265\n",
      "train loss:0.8842607202941066\n",
      "train loss:1.0202413593455661\n",
      "train loss:0.9854450203848341\n",
      "train loss:0.8197134734416577\n",
      "train loss:1.0059179989852896\n",
      "train loss:1.0444726987703925\n",
      "train loss:0.9848287365679163\n",
      "train loss:1.1090673563140478\n",
      "train loss:0.9499296558137991\n",
      "train loss:1.0430411084126456\n",
      "train loss:0.9772583039914603\n",
      "train loss:0.9636107075888043\n",
      "train loss:1.0594884256829509\n",
      "train loss:0.9205304822027274\n",
      "train loss:1.1105906341465028\n",
      "train loss:1.1301676720862133\n",
      "train loss:1.0895656055303469\n",
      "train loss:0.963562926269174\n",
      "train loss:1.0822689122717224\n",
      "train loss:1.1481697634948942\n",
      "train loss:1.0643338497764459\n",
      "train loss:0.9735942472533888\n",
      "train loss:1.1443595820987857\n",
      "train loss:1.0647420663621339\n",
      "train loss:0.9374627718758427\n",
      "train loss:1.1071169058462238\n",
      "train loss:1.188445360481088\n",
      "train loss:1.1284066293281634\n",
      "train loss:1.0789100466968349\n",
      "train loss:1.2183217413395966\n",
      "train loss:1.052865902643239\n",
      "train loss:1.039993815538926\n",
      "train loss:1.114712320381045\n",
      "train loss:1.0232828115624248\n",
      "train loss:1.2040252353767507\n",
      "train loss:0.9992553057236827\n",
      "train loss:0.9866747759067137\n",
      "train loss:1.0442107755019898\n",
      "train loss:1.048257052313514\n",
      "train loss:1.0860778086317506\n",
      "train loss:1.0357477408772793\n",
      "train loss:1.2369236128965404\n",
      "train loss:1.1472396577659858\n",
      "train loss:0.9325132192542376\n",
      "train loss:0.9096867370037641\n",
      "train loss:0.9269455914209809\n",
      "train loss:1.0170208592755048\n",
      "train loss:1.1798988181248526\n",
      "train loss:1.174816362899361\n",
      "train loss:0.8479025654908366\n",
      "train loss:1.2196512904303334\n",
      "train loss:1.1985895173862284\n",
      "train loss:1.082345939333419\n",
      "train loss:0.9771779989551262\n",
      "train loss:1.1418537307030847\n",
      "train loss:1.0494289471898726\n",
      "train loss:1.0611480297793812\n",
      "train loss:1.1209437679727825\n",
      "train loss:1.2192717047031452\n",
      "train loss:1.1385947908486218\n",
      "train loss:0.948622158331207\n",
      "train loss:1.2003070198998358\n",
      "train loss:1.148049993670246\n",
      "train loss:0.9492444030056838\n",
      "train loss:0.9755705507865803\n",
      "train loss:1.069361053982866\n",
      "train loss:0.9035442299731048\n",
      "train loss:0.996939379629077\n",
      "train loss:1.1634275072080391\n",
      "train loss:1.0631793284510003\n",
      "train loss:1.0942769471554123\n",
      "train loss:0.8527636701829764\n",
      "train loss:1.0120680083385922\n",
      "train loss:0.8495627962354503\n",
      "train loss:1.1107697203711593\n",
      "train loss:1.005547837838956\n",
      "train loss:1.0846244863747063\n",
      "train loss:1.1120071252386348\n",
      "train loss:1.1275275128264242\n",
      "train loss:1.36981946868973\n",
      "train loss:1.196516120736141\n",
      "train loss:1.0742700142507817\n",
      "train loss:1.133853513099256\n",
      "train loss:1.0404398402964403\n",
      "train loss:1.0344786452648966\n",
      "train loss:0.9359496344324504\n",
      "train loss:0.9467175598710486\n",
      "train loss:1.1323994501167576\n",
      "train loss:1.1554248637199835\n",
      "train loss:1.0851871676159168\n",
      "train loss:1.123644341779388\n",
      "train loss:1.0265240453152875\n",
      "train loss:1.0276412322908097\n",
      "train loss:0.9550737255282908\n",
      "train loss:1.0129046589678652\n",
      "train loss:1.0148914491522785\n",
      "train loss:1.0293239999495605\n",
      "train loss:1.0825896263541928\n",
      "train loss:0.939579801623697\n",
      "train loss:1.145336917341677\n",
      "train loss:1.1071648713259916\n",
      "train loss:1.07443223364968\n",
      "train loss:1.0529463778457635\n",
      "train loss:1.1044569024335045\n",
      "train loss:1.0772647924763545\n",
      "train loss:1.118821555685791\n",
      "train loss:0.9422993148937414\n",
      "train loss:1.2200652410087711\n",
      "train loss:1.0232308995969135\n",
      "train loss:1.0352687590762626\n",
      "train loss:0.937673447328504\n",
      "train loss:1.0903677979644424\n",
      "train loss:1.1283355895451908\n",
      "train loss:0.9274128056909628\n",
      "train loss:1.2552867082517742\n",
      "train loss:1.1941804925169186\n",
      "train loss:1.0982354697931886\n",
      "train loss:1.0850407193410745\n",
      "train loss:0.9977976074568908\n",
      "train loss:0.931618734069404\n",
      "train loss:0.9848020827584224\n",
      "train loss:0.9723505617333494\n",
      "train loss:1.0925540483453462\n",
      "train loss:1.199122500999553\n",
      "train loss:1.080449862790509\n",
      "train loss:1.2443937703608454\n",
      "train loss:1.173528113287076\n",
      "train loss:0.9395674166531209\n",
      "train loss:1.1029430613064684\n",
      "train loss:1.2103257665307794\n",
      "train loss:0.9769216628429919\n",
      "train loss:1.0882114114812718\n",
      "train loss:1.1253228874249728\n",
      "train loss:1.1869778797237995\n",
      "train loss:1.218482484153113\n",
      "train loss:0.9774792344162567\n",
      "train loss:1.113881646636681\n",
      "train loss:1.1340761501370664\n",
      "train loss:1.0672704176236494\n",
      "train loss:1.0182541773265812\n",
      "train loss:0.8993639856039601\n",
      "train loss:0.9201314468466785\n",
      "train loss:0.884338762710083\n",
      "train loss:1.169451669132543\n",
      "train loss:0.9761758347245713\n",
      "train loss:1.0105064302709836\n",
      "train loss:1.1207982227086823\n",
      "train loss:1.068734129333408\n",
      "train loss:1.1902403896934914\n",
      "train loss:1.1060904898324024\n",
      "train loss:1.1378377970361457\n",
      "train loss:0.9691332698639495\n",
      "train loss:0.9638468147407798\n",
      "train loss:1.2060347093962671\n",
      "train loss:1.2087286987675503\n",
      "train loss:0.9328666158690327\n",
      "train loss:0.9907032670185775\n",
      "train loss:1.1354087046683536\n",
      "train loss:1.2096641649433897\n",
      "train loss:1.0698267156838583\n",
      "train loss:0.9795187274392108\n",
      "train loss:0.9776086577281287\n",
      "train loss:1.020789385241584\n",
      "train loss:0.9285064588131506\n",
      "train loss:1.1112058395358424\n",
      "train loss:1.045720964632725\n",
      "train loss:0.9214829213827813\n",
      "train loss:1.1368470601161738\n",
      "train loss:1.138711061151804\n",
      "train loss:1.0330274066794292\n",
      "train loss:0.9202087371500981\n",
      "train loss:1.0020006181246577\n",
      "train loss:1.1443633896010388\n",
      "train loss:0.9000066716850305\n",
      "train loss:1.0403564680518236\n",
      "train loss:1.1229322218297462\n",
      "train loss:1.1179510388321714\n",
      "train loss:0.9812499062955341\n",
      "train loss:1.1277557313349105\n",
      "train loss:1.0956875149657612\n",
      "train loss:1.1440383520234272\n",
      "train loss:0.9362834452044149\n",
      "train loss:0.9983935158148417\n",
      "train loss:0.9261483144180493\n",
      "train loss:0.8963805285195696\n",
      "train loss:1.0081791474941866\n",
      "train loss:1.1182965635647921\n",
      "=== epoch:5, train acc:0.972, test acc:0.968 ===\n",
      "train loss:1.0905589942483218\n",
      "train loss:0.9948999184140626\n",
      "train loss:1.0273058811763705\n",
      "train loss:1.1778151217452724\n",
      "train loss:1.019436492916019\n",
      "train loss:1.0620746247308426\n",
      "train loss:0.9527923691695235\n",
      "train loss:1.0240923982888288\n",
      "train loss:0.9235756069142057\n",
      "train loss:0.9667619401402804\n",
      "train loss:1.0410978028241886\n",
      "train loss:1.0609800732420869\n",
      "train loss:1.218193223844712\n",
      "train loss:0.9481369861811983\n",
      "train loss:1.2229199827807344\n",
      "train loss:1.0677134038439602\n",
      "train loss:0.9989332339911465\n",
      "train loss:1.0073409650426484\n",
      "train loss:1.0636178972284407\n",
      "train loss:1.076258762737379\n",
      "train loss:0.9535657125268596\n",
      "train loss:1.2147748719532168\n",
      "train loss:0.9464763756124934\n",
      "train loss:1.1682462474531723\n",
      "train loss:1.2104305782607148\n",
      "train loss:0.8031728977284459\n",
      "train loss:1.0745961502165429\n",
      "train loss:1.0747087065174123\n",
      "train loss:1.067867743032164\n",
      "train loss:1.0205278923273096\n",
      "train loss:0.9060460361802924\n",
      "train loss:0.98211425227573\n",
      "train loss:0.870935860219571\n",
      "train loss:1.163510753717613\n",
      "train loss:0.9991106501891241\n",
      "train loss:1.2910052432966048\n",
      "train loss:0.9463930516216421\n",
      "train loss:1.1572052268259962\n",
      "train loss:1.186409795338006\n",
      "train loss:0.9388236103352371\n",
      "train loss:1.057902130627843\n",
      "train loss:1.0889509342506196\n",
      "train loss:1.1306693408496578\n",
      "train loss:0.97994074928702\n",
      "train loss:0.9659884609275302\n",
      "train loss:0.9353221904799564\n",
      "train loss:1.1248618019929064\n",
      "train loss:0.8977954304858495\n",
      "train loss:1.1745279642698698\n",
      "train loss:0.9770412824680433\n",
      "train loss:0.9475158894026525\n",
      "train loss:0.9920626361490446\n",
      "train loss:0.9243108191027276\n",
      "train loss:0.9425232504656322\n",
      "train loss:0.9518608474453767\n",
      "train loss:1.0698760617577654\n",
      "train loss:0.9111084052430796\n",
      "train loss:1.0189747930694937\n",
      "train loss:1.0759227023302917\n",
      "train loss:1.0551414854516148\n",
      "train loss:1.0719033196728942\n",
      "train loss:1.0724218697606869\n",
      "train loss:1.1587758228867555\n",
      "train loss:1.0946887811763115\n",
      "train loss:0.9721147966242434\n",
      "train loss:1.1082272680846403\n",
      "train loss:1.0938953826924698\n",
      "train loss:0.8154333654575763\n",
      "train loss:0.9705786329728372\n",
      "train loss:1.1128718902591554\n",
      "train loss:1.091935767060105\n",
      "train loss:1.1566473179030095\n",
      "train loss:1.080089832011755\n",
      "train loss:1.158213713107305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.1056170716605418\n",
      "train loss:1.1149274102426268\n",
      "train loss:1.1331736226365414\n",
      "train loss:0.7953080026614434\n",
      "train loss:0.9981601080465953\n",
      "train loss:1.1894952044679212\n",
      "train loss:1.0107692276890552\n",
      "train loss:1.0178585886395095\n",
      "train loss:0.9785408420642431\n",
      "train loss:1.042551167896959\n",
      "train loss:1.0368286217955835\n",
      "train loss:1.1404785794566352\n",
      "train loss:1.3189314600189908\n",
      "train loss:0.9960842123762191\n",
      "train loss:0.8671796771666967\n",
      "train loss:1.2139181736495532\n",
      "train loss:1.2311712952974665\n",
      "train loss:0.9510264865864128\n",
      "train loss:0.9202244728073516\n",
      "train loss:0.9185636018641931\n",
      "train loss:0.9285168975694705\n",
      "train loss:0.9160396974250287\n",
      "train loss:1.1757371446483988\n",
      "train loss:1.100425421099342\n",
      "train loss:1.0626814308975285\n",
      "train loss:0.9434555731528224\n",
      "train loss:0.9803427355366078\n",
      "train loss:1.160279974522969\n",
      "train loss:0.8899016299438798\n",
      "train loss:1.1202891928145404\n",
      "train loss:1.0546988297533315\n",
      "train loss:1.0124182296036057\n",
      "train loss:1.15750649560302\n",
      "train loss:0.9606353479069444\n",
      "train loss:1.1194613445802526\n",
      "train loss:0.962309497441793\n",
      "train loss:0.8547409799612603\n",
      "train loss:1.1552360783413158\n",
      "train loss:1.2275367445985461\n",
      "train loss:1.065720790663803\n",
      "train loss:1.1261615156179745\n",
      "train loss:1.2053985029380991\n",
      "train loss:1.0460832866756513\n",
      "train loss:1.016664573004674\n",
      "train loss:0.9363097604504098\n",
      "train loss:1.1001685466686253\n",
      "train loss:1.1602383342298521\n",
      "train loss:0.9489966943613919\n",
      "train loss:1.0851783222860443\n",
      "train loss:1.0572863427139865\n",
      "train loss:1.0777838367961774\n",
      "train loss:1.0232584331207528\n",
      "train loss:1.0048343247619533\n",
      "train loss:1.0716273609406077\n",
      "train loss:0.9298504603445241\n",
      "train loss:1.1098630556107456\n",
      "train loss:1.1411178364453098\n",
      "train loss:0.9601285053263269\n",
      "train loss:1.1663035574282856\n",
      "train loss:1.0630033583779015\n",
      "train loss:0.9773050303351148\n",
      "train loss:1.1238537417845893\n",
      "train loss:1.1746526611880967\n",
      "train loss:1.0383198025545055\n",
      "train loss:1.0286028940062653\n",
      "train loss:1.0751333474737095\n",
      "train loss:1.034536668600769\n",
      "train loss:0.9907227415764827\n",
      "train loss:0.9440759794699679\n",
      "train loss:0.988813956507477\n",
      "train loss:0.9458965622677149\n",
      "train loss:0.7222222934375625\n",
      "train loss:1.0311356649792416\n",
      "train loss:1.053711939752266\n",
      "train loss:1.0413076167587603\n",
      "train loss:0.9744324708136334\n",
      "train loss:0.8189822545946102\n",
      "train loss:1.0211926097278292\n",
      "train loss:1.1523186797720495\n",
      "train loss:1.0686568060848334\n",
      "train loss:1.2319753764402954\n",
      "train loss:1.127617189746312\n",
      "train loss:1.0234791176205313\n",
      "train loss:0.9210586958299198\n",
      "train loss:0.8125930184830061\n",
      "train loss:1.056178753495981\n",
      "train loss:0.8764996024833874\n",
      "train loss:1.154357871292508\n",
      "train loss:0.9322613956490525\n",
      "train loss:1.049519862653565\n",
      "train loss:1.0060451344296093\n",
      "train loss:1.081846030559938\n",
      "train loss:1.2556105157181099\n",
      "train loss:1.0398904574366754\n",
      "train loss:1.0117859929083302\n",
      "train loss:0.9762480419038679\n",
      "train loss:1.076804835988316\n",
      "train loss:0.9728223438467724\n",
      "train loss:1.0486502182323625\n",
      "train loss:1.0965443349101043\n",
      "train loss:0.9829556853386032\n",
      "train loss:1.1391048661421417\n",
      "train loss:1.2542520220930728\n",
      "train loss:1.1151385761157\n",
      "train loss:1.1533216312117218\n",
      "train loss:0.8367922190830014\n",
      "train loss:0.9630720027086322\n",
      "train loss:0.9580415320250201\n",
      "train loss:1.0507000652411216\n",
      "train loss:1.1262581311726165\n",
      "train loss:1.0282296307580254\n",
      "train loss:1.1636684755165725\n",
      "train loss:0.99276552631657\n",
      "train loss:1.150669360782896\n",
      "train loss:0.9327303511789045\n",
      "train loss:1.026585622294087\n",
      "train loss:0.980445577389351\n",
      "train loss:1.134222107739172\n",
      "train loss:1.1048802931661532\n",
      "train loss:1.034630286160713\n",
      "train loss:1.0745106669574125\n",
      "train loss:1.1196424442320196\n",
      "train loss:1.1735885445664629\n",
      "train loss:1.176019648924527\n",
      "train loss:1.1254519442538191\n",
      "train loss:0.8969106384998029\n",
      "train loss:1.1759513871565148\n",
      "train loss:0.9824969227473517\n",
      "train loss:1.1260374628209708\n",
      "train loss:1.2422137905043253\n",
      "train loss:1.0509576863191092\n",
      "train loss:1.1677034995289441\n",
      "train loss:1.0831720803109572\n",
      "train loss:1.1278780254830978\n",
      "train loss:1.1043735907131031\n",
      "train loss:0.9478452186558118\n",
      "train loss:0.8900611157755772\n",
      "train loss:0.9939448448815804\n",
      "train loss:0.8557798377279303\n",
      "train loss:1.0833123150525077\n",
      "train loss:1.0768988813913005\n",
      "train loss:1.051040116728437\n",
      "train loss:0.9892297263327744\n",
      "train loss:1.0808956088681725\n",
      "train loss:0.9973803758535484\n",
      "train loss:0.8857256846004289\n",
      "train loss:1.1770397131847548\n",
      "train loss:1.1501226832238707\n",
      "train loss:1.093188461385842\n",
      "train loss:1.0284863517333855\n",
      "train loss:0.8700529039583139\n",
      "train loss:1.1936732298010364\n",
      "train loss:0.9391554204666993\n",
      "train loss:1.2759538799861678\n",
      "train loss:1.036778724238527\n",
      "train loss:1.045089764288782\n",
      "train loss:0.9711016584959558\n",
      "train loss:1.14214044816733\n",
      "train loss:1.0629427892941705\n",
      "train loss:1.0438187007398354\n",
      "train loss:1.0900514195008915\n",
      "train loss:1.121626682113312\n",
      "train loss:1.0526939560690252\n",
      "train loss:1.0750653782549506\n",
      "train loss:1.138051734040089\n",
      "train loss:1.1397683424141174\n",
      "train loss:1.0595898695352526\n",
      "train loss:0.830776493534768\n",
      "train loss:1.0684324033534984\n",
      "train loss:1.1554722377898736\n",
      "train loss:1.1843549018590087\n",
      "train loss:1.0206142801098954\n",
      "train loss:0.9718631477259158\n",
      "train loss:1.035664101259899\n",
      "train loss:1.1297996456608375\n",
      "train loss:1.2528807226445342\n",
      "train loss:0.9504265080368252\n",
      "train loss:1.004648333699985\n",
      "train loss:0.8838576984092826\n",
      "train loss:1.064271603680831\n",
      "train loss:0.9675128726099537\n",
      "train loss:1.0480487148119795\n",
      "train loss:1.0740200789983279\n",
      "train loss:1.142139796799796\n",
      "train loss:1.0722582382525188\n",
      "train loss:0.9726237726648832\n",
      "train loss:0.8226657087112029\n",
      "train loss:1.1093224403481399\n",
      "train loss:1.032321908811914\n",
      "train loss:1.105926446185258\n",
      "train loss:1.0308370014165729\n",
      "train loss:1.0567847114012323\n",
      "train loss:1.097001008185064\n",
      "train loss:1.1847492200684189\n",
      "train loss:1.1666076497985645\n",
      "train loss:0.9611240270029282\n",
      "train loss:0.9669229381996413\n",
      "train loss:0.9685362722382742\n",
      "train loss:0.9381591986000173\n",
      "train loss:1.0905061479334492\n",
      "train loss:1.0511483621035278\n",
      "train loss:1.1356579070521409\n",
      "train loss:1.0635122990748613\n",
      "train loss:1.0016743934684567\n",
      "train loss:1.0051503512013296\n",
      "train loss:1.0625171384865113\n",
      "train loss:1.2261721550467501\n",
      "train loss:1.106151941408024\n",
      "train loss:1.028668553593451\n",
      "train loss:1.093512639890356\n",
      "train loss:1.0062725492815034\n",
      "train loss:0.896079567910684\n",
      "train loss:1.057905821162481\n",
      "train loss:0.9312607897162244\n",
      "train loss:1.0347714211974048\n",
      "train loss:1.0374814791970541\n",
      "train loss:0.8611429594183688\n",
      "train loss:1.1215757630135286\n",
      "train loss:0.9904901642457563\n",
      "train loss:1.0370870003031976\n",
      "train loss:1.0809754014732023\n",
      "train loss:1.0657562017098687\n",
      "train loss:1.2536713971608306\n",
      "train loss:0.8697445535653903\n",
      "train loss:1.0220884326892519\n",
      "train loss:1.0023488697738776\n",
      "train loss:1.0472680752006645\n",
      "train loss:1.0944032092703813\n",
      "train loss:0.8606798851377662\n",
      "train loss:1.2087686504111774\n",
      "train loss:0.9807688166825854\n",
      "train loss:1.1541682768123769\n",
      "train loss:0.8844092200337801\n",
      "train loss:0.9191564454605582\n",
      "train loss:0.8449729008714391\n",
      "train loss:1.159296348291293\n",
      "train loss:0.8676186489199134\n",
      "train loss:1.117620541359016\n",
      "train loss:1.0633679726562058\n",
      "train loss:1.2395913000671996\n",
      "train loss:1.096267568805731\n",
      "train loss:1.1068618411690185\n",
      "train loss:1.2285054917647564\n",
      "train loss:1.0291965237677636\n",
      "train loss:1.1318216699537786\n",
      "train loss:1.061579068753384\n",
      "train loss:0.9353287455643045\n",
      "train loss:1.1206915690151735\n",
      "train loss:1.0175347375511492\n",
      "train loss:1.1682997452009274\n",
      "train loss:1.1883977648387696\n",
      "train loss:0.9280259299405225\n",
      "train loss:0.884844669108177\n",
      "train loss:1.0725446338504314\n",
      "train loss:1.016761938745958\n",
      "train loss:0.954377317245209\n",
      "train loss:1.192988239795648\n",
      "train loss:1.1664206984833054\n",
      "train loss:0.9834944804512924\n",
      "train loss:1.0481495629810866\n",
      "train loss:0.9273411002386486\n",
      "train loss:0.9495748847261299\n",
      "train loss:0.8739600029978672\n",
      "train loss:1.1727336788697353\n",
      "train loss:1.110822860403622\n",
      "train loss:0.9573700492747892\n",
      "train loss:0.9007618630260231\n",
      "train loss:1.1362818981310716\n",
      "train loss:1.0408802637782426\n",
      "train loss:1.0645981034180054\n",
      "train loss:1.07386141416512\n",
      "train loss:0.9620708134604223\n",
      "train loss:1.104238612135936\n",
      "train loss:1.0631906548388823\n",
      "train loss:0.9816025364660379\n",
      "train loss:1.0201700083376601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.1781696522780742\n",
      "train loss:0.878893305881687\n",
      "train loss:0.9157420259246727\n",
      "train loss:0.9776335035197968\n",
      "train loss:1.04514118692639\n",
      "train loss:1.2362894593327445\n",
      "train loss:0.8293858435626492\n",
      "train loss:0.8645194240907584\n",
      "train loss:1.037958066938028\n",
      "train loss:0.950383335223315\n",
      "train loss:1.0848336457993728\n",
      "train loss:1.2121381361171657\n",
      "train loss:1.0936989742599499\n",
      "train loss:1.3060029030652982\n",
      "train loss:1.0998558435762837\n",
      "train loss:1.069645814789577\n",
      "train loss:1.070342216287478\n",
      "train loss:0.7873201496376353\n",
      "train loss:1.0717717111472362\n",
      "train loss:0.8319285561106003\n",
      "train loss:1.1565700643681567\n",
      "train loss:1.093979475280276\n",
      "train loss:1.129031861736219\n",
      "train loss:1.037856838940382\n",
      "train loss:1.0781186204799242\n",
      "train loss:1.0314474183714764\n",
      "train loss:1.2135598280431734\n",
      "train loss:1.0357219553682395\n",
      "train loss:1.0889145679420158\n",
      "train loss:0.9434746482968673\n",
      "train loss:1.137371684480733\n",
      "train loss:1.159952586454664\n",
      "train loss:1.0450564512231797\n",
      "train loss:1.0417647750350978\n",
      "train loss:0.9114800909923764\n",
      "train loss:0.9608691011574543\n",
      "train loss:1.0019051016112324\n",
      "train loss:1.0726344576336009\n",
      "train loss:0.9845713124108281\n",
      "train loss:0.9926898461715371\n",
      "train loss:0.9455434322941187\n",
      "train loss:1.058575384202246\n",
      "train loss:1.0130056471122706\n",
      "train loss:1.0119836814930665\n",
      "train loss:1.038030184649314\n",
      "train loss:1.156788846888207\n",
      "train loss:1.0656881227479453\n",
      "train loss:0.9562597240510616\n",
      "train loss:1.1829717016172727\n",
      "train loss:1.049253660867118\n",
      "train loss:1.255509321597217\n",
      "train loss:1.113753971454191\n",
      "train loss:1.0779342101682476\n",
      "train loss:1.0498031860532973\n",
      "train loss:1.035248339463332\n",
      "train loss:0.9850300324451426\n",
      "train loss:1.1279597524742235\n",
      "train loss:0.9127244054701475\n",
      "train loss:0.9621057799131597\n",
      "train loss:0.9798715932934549\n",
      "train loss:1.227946096131487\n",
      "train loss:1.0289474803383658\n",
      "train loss:0.9269775613542017\n",
      "train loss:0.8289218977498524\n",
      "train loss:1.015562844371622\n",
      "train loss:0.9090617084985824\n",
      "train loss:1.050457784568439\n",
      "train loss:0.9445889109278527\n",
      "train loss:1.1202281223961055\n",
      "train loss:1.0295473952906566\n",
      "train loss:1.0125964940059624\n",
      "train loss:1.2110337162154938\n",
      "train loss:1.010394859578667\n",
      "train loss:0.9843254899632082\n",
      "train loss:1.0660932999115256\n",
      "train loss:1.0260573521857468\n",
      "train loss:1.141359274215531\n",
      "train loss:0.9007214839079494\n",
      "train loss:0.9242317503979224\n",
      "train loss:1.0800447410782137\n",
      "train loss:0.947321979978733\n",
      "train loss:0.9662508238334026\n",
      "train loss:1.014404790239549\n",
      "train loss:1.1715628431155618\n",
      "train loss:0.9865379484998195\n",
      "train loss:1.0996688323411574\n",
      "train loss:1.23670049004955\n",
      "train loss:1.3491630112869926\n",
      "train loss:1.033528656494951\n",
      "train loss:0.9689773687566335\n",
      "train loss:1.0670085314972553\n",
      "train loss:1.0785888366751764\n",
      "train loss:0.955530550515359\n",
      "train loss:1.0153750816851608\n",
      "train loss:1.1439589442299023\n",
      "train loss:1.044361351772193\n",
      "train loss:0.9541328549753616\n",
      "train loss:0.9613342291895584\n",
      "train loss:0.8989540434089391\n",
      "train loss:1.1664484804465933\n",
      "train loss:0.9832936445503503\n",
      "train loss:0.8922626287542181\n",
      "train loss:1.0263621325234\n",
      "train loss:1.0159375172856748\n",
      "train loss:0.8835748505177325\n",
      "train loss:1.1091311699348159\n",
      "train loss:0.8563927828676305\n",
      "train loss:0.9918935349518265\n",
      "train loss:0.8897698833209194\n",
      "train loss:1.0713095444963787\n",
      "train loss:0.9414288684938262\n",
      "train loss:1.0129902469061949\n",
      "train loss:1.1372033391788186\n",
      "train loss:0.8386022665553158\n",
      "train loss:1.106362778466924\n",
      "train loss:1.0375666172748725\n",
      "train loss:1.0298909557809284\n",
      "train loss:0.9286274240823219\n",
      "train loss:0.9603917076093531\n",
      "train loss:1.0678963414072005\n",
      "train loss:0.7627000150087294\n",
      "train loss:1.0220026473348078\n",
      "train loss:0.9825763277502456\n",
      "train loss:1.1314691161864538\n",
      "train loss:1.186333521430066\n",
      "train loss:0.945696702227114\n",
      "train loss:1.0152927482724134\n",
      "train loss:1.082055823037172\n",
      "train loss:1.070844906960835\n",
      "train loss:0.9744921138006258\n",
      "train loss:1.0436849008918376\n",
      "train loss:0.941896162949482\n",
      "train loss:1.2940280925189633\n",
      "train loss:1.0296274263429455\n",
      "train loss:1.238527526846164\n",
      "train loss:0.8865336027104455\n",
      "train loss:1.0268708273921607\n",
      "train loss:1.0555293998735797\n",
      "train loss:1.0560738737794282\n",
      "train loss:1.0972971528504545\n",
      "train loss:0.9518550270306985\n",
      "train loss:1.0431775511764412\n",
      "train loss:1.0117864740342677\n",
      "train loss:1.0098016144943678\n",
      "train loss:1.0515269486166499\n",
      "train loss:0.9990256028637694\n",
      "train loss:0.9864229101801559\n",
      "train loss:1.0784690737080986\n",
      "train loss:1.278782123472376\n",
      "train loss:0.947367289964374\n",
      "train loss:1.0829911026048746\n",
      "train loss:0.9296188208445818\n",
      "train loss:1.1065587191054167\n",
      "train loss:0.9089867274963557\n",
      "train loss:1.0872167850650347\n",
      "train loss:0.9788565707723744\n",
      "train loss:1.0026067930261473\n",
      "train loss:0.939384419027667\n",
      "train loss:1.0858168133443744\n",
      "train loss:1.022738689523169\n",
      "train loss:0.9768679751250295\n",
      "train loss:1.0328159536544086\n",
      "train loss:1.0477329186828213\n",
      "train loss:1.0785413227853191\n",
      "train loss:0.989938138136079\n",
      "train loss:0.9570646037733094\n",
      "train loss:0.9668536675982266\n",
      "train loss:0.909963011474322\n",
      "train loss:0.986623930822999\n",
      "train loss:0.9252167774540352\n",
      "train loss:0.8896043876747014\n",
      "train loss:1.1154455792118112\n",
      "train loss:1.089809487122945\n",
      "train loss:1.0531923370818277\n",
      "train loss:1.1333815446751385\n",
      "train loss:1.1070318433486097\n",
      "train loss:1.02021701807955\n",
      "train loss:1.0057499262514598\n",
      "train loss:1.1807297733661832\n",
      "train loss:1.1717959710100754\n",
      "train loss:1.2845087989165125\n",
      "train loss:0.846939085325519\n",
      "train loss:1.0354501225875357\n",
      "train loss:1.1337666134428956\n",
      "train loss:1.2515845407738961\n",
      "train loss:1.0495985235629268\n",
      "train loss:0.9264836059300761\n",
      "train loss:0.9754609577938969\n",
      "train loss:1.1850265310789387\n",
      "train loss:1.0340420457373098\n",
      "train loss:0.9051854834309965\n",
      "train loss:1.0946489593035305\n",
      "train loss:1.1698636210353162\n",
      "train loss:0.9702861787458212\n",
      "train loss:1.056911131492801\n",
      "train loss:1.2409968658877701\n",
      "train loss:1.0286115932120463\n",
      "train loss:1.035171424992729\n",
      "train loss:0.966353729066962\n",
      "train loss:1.171741142785208\n",
      "train loss:0.8371666617280353\n",
      "train loss:0.935035853529614\n",
      "train loss:1.071125762511442\n",
      "train loss:1.113367058409703\n",
      "train loss:1.2358152150816946\n",
      "train loss:1.105066856873765\n",
      "train loss:1.0150291459100003\n",
      "train loss:1.115445946351714\n",
      "train loss:1.0700351872090117\n",
      "train loss:1.06001772544167\n",
      "train loss:1.1568480255258904\n",
      "train loss:0.9845695981307171\n",
      "train loss:1.0079637232510021\n",
      "train loss:1.1014112460694268\n",
      "train loss:1.0687968039958429\n",
      "train loss:1.0504799902621245\n",
      "train loss:1.0776279387227328\n",
      "train loss:0.9223301456442374\n",
      "train loss:1.0710839244229677\n",
      "train loss:1.0532226280393424\n",
      "train loss:0.8973326738508409\n",
      "train loss:1.0041568975310968\n",
      "train loss:0.9773462216444213\n",
      "train loss:1.0987307970378497\n",
      "train loss:0.9393604825179298\n",
      "train loss:1.0141168191136856\n",
      "train loss:1.1817358946256273\n",
      "train loss:0.9858802266815266\n",
      "train loss:1.0308846521230377\n",
      "train loss:0.8458107822922153\n",
      "train loss:0.9981405388549427\n",
      "train loss:0.9179113295539101\n",
      "train loss:1.0406951508877538\n",
      "train loss:0.8792505261794799\n",
      "train loss:0.898659811132535\n",
      "train loss:0.9658109223433159\n",
      "train loss:0.9742450964554594\n",
      "train loss:1.3081633590250152\n",
      "train loss:0.9367236755364785\n",
      "train loss:0.8514701545590121\n",
      "train loss:1.3125944099005014\n",
      "train loss:1.0080039898095017\n",
      "train loss:1.0328370372034754\n",
      "train loss:1.1462988455740253\n",
      "train loss:1.127504658012226\n",
      "train loss:1.1215030152786172\n",
      "train loss:1.1212055307076587\n",
      "train loss:1.1284691378228342\n",
      "train loss:0.988839650938596\n",
      "train loss:1.1116447815329464\n",
      "=== epoch:6, train acc:0.972, test acc:0.975 ===\n",
      "train loss:1.06542690837459\n",
      "train loss:0.8517885192786079\n",
      "train loss:1.0656424941463007\n",
      "train loss:1.0022881280111964\n",
      "train loss:1.1214669334124272\n",
      "train loss:1.1219457848233843\n",
      "train loss:0.938050907341713\n",
      "train loss:1.0058583372157581\n",
      "train loss:0.9567490114892201\n",
      "train loss:1.1082708668236834\n",
      "train loss:0.8607881279139559\n",
      "train loss:0.952060089727608\n",
      "train loss:1.2873321160780846\n",
      "train loss:0.9854127029573735\n",
      "train loss:0.9431108793948587\n",
      "train loss:0.9772520816488202\n",
      "train loss:0.969674174416726\n",
      "train loss:1.1962813117774134\n",
      "train loss:0.8188609896145299\n",
      "train loss:0.8653411295334392\n",
      "train loss:1.0565311572872458\n",
      "train loss:1.057960807332124\n",
      "train loss:1.0448235026895398\n",
      "train loss:1.0539753086869517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.993627481536985\n",
      "train loss:1.105193223377222\n",
      "train loss:1.0653556514891473\n",
      "train loss:0.921926847430304\n",
      "train loss:1.1701322170425688\n",
      "train loss:1.043805809579635\n",
      "train loss:1.20052734596833\n",
      "train loss:0.9985868088592277\n",
      "train loss:1.0537426923688284\n",
      "train loss:1.040290632006428\n",
      "train loss:1.07455680451457\n",
      "train loss:1.2142964695856096\n",
      "train loss:0.9462789726623361\n",
      "train loss:0.9686204360143686\n",
      "train loss:1.169939209116296\n",
      "train loss:0.9186174250437567\n",
      "train loss:0.8478929612615054\n",
      "train loss:1.1387630195523228\n",
      "train loss:0.9790622771430134\n",
      "train loss:1.1141786378763643\n",
      "train loss:1.1206859817185288\n",
      "train loss:0.9876982559523485\n",
      "train loss:1.040204000380227\n",
      "train loss:0.9757386423257463\n",
      "train loss:0.9194345562674304\n",
      "train loss:1.137250019525624\n",
      "train loss:0.9573741147343192\n",
      "train loss:1.0849752998936315\n",
      "train loss:1.0813642593633899\n",
      "train loss:1.2156752283778645\n",
      "train loss:0.9858155440559889\n",
      "train loss:0.9801903231602093\n",
      "train loss:0.8862700936842682\n",
      "train loss:1.181418673810586\n",
      "train loss:0.961045733100898\n",
      "train loss:0.9692013496617862\n",
      "train loss:0.8600734402517641\n",
      "train loss:0.9472000321255359\n",
      "train loss:0.87233510806052\n",
      "train loss:0.9135832177957457\n",
      "train loss:1.093598133050166\n",
      "train loss:0.7737173940210431\n",
      "train loss:1.163331629720885\n",
      "train loss:0.9191823484374834\n",
      "train loss:0.9377261388449817\n",
      "train loss:1.1963828076580727\n",
      "train loss:0.9160584499782627\n",
      "train loss:0.9624428831277814\n",
      "train loss:0.9510920677151392\n",
      "train loss:1.0642379636079566\n",
      "train loss:1.0823203240525021\n",
      "train loss:1.039939766165203\n",
      "train loss:0.837622604601891\n",
      "train loss:1.0355301441732865\n",
      "train loss:1.0911753279787424\n",
      "train loss:1.1911806741153632\n",
      "train loss:0.8887287233049678\n",
      "train loss:1.109641097004712\n",
      "train loss:1.0452514223177247\n",
      "train loss:1.01394520388061\n",
      "train loss:1.0938733708683988\n",
      "train loss:1.0213389342390087\n",
      "train loss:0.9930393426633382\n",
      "train loss:0.9604896780637638\n",
      "train loss:0.9846198322226464\n",
      "train loss:1.143757062364451\n",
      "train loss:0.8618228087076792\n",
      "train loss:1.0165030792706429\n",
      "train loss:1.1620756524317635\n",
      "train loss:0.9389203873389094\n",
      "train loss:1.1256838652797843\n",
      "train loss:0.8335448806008415\n",
      "train loss:1.1048277554511723\n",
      "train loss:0.9668774017971157\n",
      "train loss:1.1499889021720977\n",
      "train loss:1.0456778574461487\n",
      "train loss:0.7441197541999179\n",
      "train loss:1.1327629125244392\n",
      "train loss:1.0850449206935453\n",
      "train loss:0.8609596642584243\n",
      "train loss:1.0686704258522364\n",
      "train loss:0.9089256185184825\n",
      "train loss:0.9679272742419337\n",
      "train loss:1.1471076477020883\n",
      "train loss:1.1031066562439447\n",
      "train loss:1.0670279904096522\n",
      "train loss:0.9377613220531853\n",
      "train loss:1.0399656638068189\n",
      "train loss:1.0718645954319796\n",
      "train loss:0.9370157708427618\n",
      "train loss:0.8763989170579697\n",
      "train loss:0.9137358865284544\n",
      "train loss:1.0589842587340612\n",
      "train loss:1.0732083470868283\n",
      "train loss:1.118846136215158\n",
      "train loss:0.9798646622428488\n",
      "train loss:1.014490882764633\n",
      "train loss:1.218371466555383\n",
      "train loss:1.0828891230159041\n",
      "train loss:1.0598025181511561\n",
      "train loss:0.8477125689566057\n",
      "train loss:0.9718292953139873\n",
      "train loss:0.9993618768882488\n",
      "train loss:1.0119416970191746\n",
      "train loss:0.9633171799541493\n",
      "train loss:1.1380596194089114\n",
      "train loss:1.2566036346938623\n",
      "train loss:0.8075840512883574\n",
      "train loss:0.913893019039582\n",
      "train loss:1.1120425799354905\n",
      "train loss:0.9394490191855634\n",
      "train loss:1.0355801372982123\n",
      "train loss:0.9654499871899529\n",
      "train loss:1.0106957094416067\n",
      "train loss:1.2182026144019036\n",
      "train loss:0.9584949976362215\n",
      "train loss:1.0596180350344881\n",
      "train loss:0.9072096945423287\n",
      "train loss:0.9123557859795771\n",
      "train loss:0.973885237821727\n",
      "train loss:1.0334531383377825\n",
      "train loss:1.1103263848415132\n",
      "train loss:0.8803766089184633\n",
      "train loss:1.0729283883474179\n",
      "train loss:1.0538722502706097\n",
      "train loss:0.9320563883909686\n",
      "train loss:1.00201789960893\n",
      "train loss:0.9295897265311227\n",
      "train loss:0.83539814147085\n",
      "train loss:0.9953384355630197\n",
      "train loss:1.0621790293247346\n",
      "train loss:1.1104499056365063\n",
      "train loss:0.8265172469375124\n",
      "train loss:0.8592047643575599\n",
      "train loss:1.0090111994491715\n",
      "train loss:1.030025349427208\n",
      "train loss:1.0436964241808433\n",
      "train loss:0.9109054555149505\n",
      "train loss:1.1295309371851416\n",
      "train loss:1.0083398026468302\n",
      "train loss:0.9912621217818349\n",
      "train loss:1.1334966773988207\n",
      "train loss:1.064122405335316\n",
      "train loss:0.9166440413832706\n",
      "train loss:1.118338287764028\n",
      "train loss:1.191046840458586\n",
      "train loss:1.1690511343058596\n",
      "train loss:1.0903789165228097\n",
      "train loss:1.008236914212067\n",
      "train loss:0.9635971883169954\n",
      "train loss:1.1728050398001826\n",
      "train loss:1.0989945810897312\n",
      "train loss:1.0268692080607118\n",
      "train loss:0.8578202809904302\n",
      "train loss:1.0509354587912587\n",
      "train loss:0.9845520983839775\n",
      "train loss:0.8043017623094408\n",
      "train loss:0.9389698101785888\n",
      "train loss:1.0600736034138043\n",
      "train loss:0.9019889448508919\n",
      "train loss:0.8774521019353743\n",
      "train loss:1.0861857495730596\n",
      "train loss:0.7853122205833089\n",
      "train loss:0.9625407328490984\n",
      "train loss:0.9642173250009329\n",
      "train loss:1.0277958244927237\n",
      "train loss:0.9764619787141232\n",
      "train loss:1.0706647731784096\n",
      "train loss:0.8121875935040687\n",
      "train loss:1.0044605244925608\n",
      "train loss:1.0762479709819741\n",
      "train loss:1.166486684327309\n",
      "train loss:1.008891067688161\n",
      "train loss:1.1555251293548436\n",
      "train loss:0.9840524988037441\n",
      "train loss:0.8823722453845149\n",
      "train loss:1.0009811780079507\n",
      "train loss:1.1256790814300954\n",
      "train loss:0.9806491257494813\n",
      "train loss:1.1462664377093525\n",
      "train loss:1.0559329457881872\n",
      "train loss:1.2199040982385478\n",
      "train loss:0.8835048716545775\n",
      "train loss:1.0326524385237281\n",
      "train loss:1.0022808500180913\n",
      "train loss:1.0143204741418548\n",
      "train loss:1.0227957051162455\n",
      "train loss:0.9494662958483946\n",
      "train loss:1.1356247115049478\n",
      "train loss:0.9728460948265095\n",
      "train loss:1.1729479561497949\n",
      "train loss:1.1161304842199664\n",
      "train loss:1.1386445882946308\n",
      "train loss:0.9303272827507969\n",
      "train loss:1.2044071118836956\n",
      "train loss:0.9910525051709985\n",
      "train loss:1.1312585849801073\n",
      "train loss:1.0492219388230533\n",
      "train loss:1.0115348663144852\n",
      "train loss:1.0041381593230012\n",
      "train loss:1.1463575238612875\n",
      "train loss:0.925642696530976\n",
      "train loss:0.9564955710038235\n",
      "train loss:0.9601916862731936\n",
      "train loss:1.1201519230972439\n",
      "train loss:0.9890173738391694\n",
      "train loss:1.244987797883316\n",
      "train loss:0.8663615361346858\n",
      "train loss:0.980770102392945\n",
      "train loss:1.0816664510760334\n",
      "train loss:0.9844174873541855\n",
      "train loss:1.1095356742163598\n",
      "train loss:1.0574865922815242\n",
      "train loss:1.0739308967170769\n",
      "train loss:1.0810683534746475\n",
      "train loss:1.0499569504357833\n",
      "train loss:1.2050132527878041\n",
      "train loss:1.06748703067406\n",
      "train loss:1.0854596071562497\n",
      "train loss:0.9238712292877231\n",
      "train loss:1.155173897894401\n",
      "train loss:1.1560170862936612\n",
      "train loss:0.9944641792767542\n",
      "train loss:1.012851671674619\n",
      "train loss:1.0253952825172754\n",
      "train loss:0.816963164446942\n",
      "train loss:1.0661879719255858\n",
      "train loss:1.1460184025932558\n",
      "train loss:1.0220638753145055\n",
      "train loss:1.0789555081529434\n",
      "train loss:0.9699768518305469\n",
      "train loss:0.9928394633724611\n",
      "train loss:1.070108090733408\n",
      "train loss:0.9780063444708839\n",
      "train loss:1.0501592933959356\n",
      "train loss:0.9835014818519379\n",
      "train loss:1.083242636967027\n",
      "train loss:1.1183645042403585\n",
      "train loss:0.9073950373340438\n",
      "train loss:1.094489435339296\n",
      "train loss:1.0317875102630358\n",
      "train loss:1.031333912824379\n",
      "train loss:0.9640460488172722\n",
      "train loss:1.0216687544916463\n",
      "train loss:1.2701283464450712\n",
      "train loss:1.0529773759864554\n",
      "train loss:1.2078341121584726\n",
      "train loss:0.9439105145517676\n",
      "train loss:1.1517006187791798\n",
      "train loss:0.938104956423776\n",
      "train loss:0.9393629929444426\n",
      "train loss:0.9872492537601357\n",
      "train loss:1.0073798676942167\n",
      "train loss:1.0409735441335908\n",
      "train loss:1.0148768372059207\n",
      "train loss:0.8616568194820066\n",
      "train loss:1.0686947724557059\n",
      "train loss:0.9312442863677036\n",
      "train loss:1.0554802385538355\n",
      "train loss:0.8441804279583177\n",
      "train loss:0.8507792456937148\n",
      "train loss:1.0868318407281474\n",
      "train loss:0.8290770702239187\n",
      "train loss:0.983863257024746\n",
      "train loss:0.9963621209890742\n",
      "train loss:0.9456710520115095\n",
      "train loss:1.1147999639069313\n",
      "train loss:1.1563658546543574\n",
      "train loss:1.0911588395904124\n",
      "train loss:0.9722386749445393\n",
      "train loss:1.044800812265342\n",
      "train loss:0.8704655639586112\n",
      "train loss:0.859673065261203\n",
      "train loss:1.0588052749541528\n",
      "train loss:0.9447835257058393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.0308335714284795\n",
      "train loss:1.076282986042038\n",
      "train loss:0.9496139731829\n",
      "train loss:1.1244750085995852\n",
      "train loss:1.038309260121911\n",
      "train loss:1.10590590881181\n",
      "train loss:1.090149011304133\n",
      "train loss:1.0429197777673387\n",
      "train loss:0.933683869788654\n",
      "train loss:1.03163775266411\n",
      "train loss:1.0471016031851432\n",
      "train loss:1.0667848771067712\n",
      "train loss:1.029637272609291\n",
      "train loss:0.9601145614050642\n",
      "train loss:1.2261423476637274\n",
      "train loss:1.1087993884496863\n",
      "train loss:1.1083704477476501\n",
      "train loss:0.8746250926711646\n",
      "train loss:1.0078987041317755\n",
      "train loss:1.013038587483546\n",
      "train loss:0.9435909097038482\n",
      "train loss:1.0950194407848357\n",
      "train loss:1.0161925381013743\n",
      "train loss:1.010619516937928\n",
      "train loss:1.1130089681856683\n",
      "train loss:0.8797078699535015\n",
      "train loss:0.9037796294531384\n",
      "train loss:1.0122866960089936\n",
      "train loss:1.0965344978563822\n",
      "train loss:1.038439662566625\n",
      "train loss:0.9467935614380534\n",
      "train loss:1.0380142446755836\n",
      "train loss:1.1769482436980088\n",
      "train loss:1.0722961255617267\n",
      "train loss:0.9844640407128021\n",
      "train loss:0.9948294003935991\n",
      "train loss:0.9446148246285206\n",
      "train loss:0.8990126556076841\n",
      "train loss:0.9609772027329845\n",
      "train loss:0.8061602588988874\n",
      "train loss:1.044462199423535\n",
      "train loss:0.9283947905944323\n",
      "train loss:0.9472674409550152\n",
      "train loss:1.059489646966974\n",
      "train loss:1.0900060262988702\n",
      "train loss:1.0592646400086978\n",
      "train loss:1.1003094557893978\n",
      "train loss:1.2250913779945651\n",
      "train loss:1.2127309354629217\n",
      "train loss:1.0071170128662386\n",
      "train loss:1.0839883683584453\n",
      "train loss:0.8790224236573541\n",
      "train loss:0.883118696022323\n",
      "train loss:0.9635858730627689\n",
      "train loss:1.089287310655869\n",
      "train loss:0.9252546032266582\n",
      "train loss:1.0036528903791793\n",
      "train loss:0.819194120678096\n",
      "train loss:0.8479257720141282\n",
      "train loss:1.2410277591194951\n",
      "train loss:1.064413468690976\n",
      "train loss:1.0832581732298698\n",
      "train loss:0.9882313899822383\n",
      "train loss:1.083440091241358\n",
      "train loss:0.9996883409374562\n",
      "train loss:0.9111678565015514\n",
      "train loss:1.0851412879593756\n",
      "train loss:1.1045610995528488\n",
      "train loss:0.8817606293990718\n",
      "train loss:0.9236618733434717\n",
      "train loss:1.0092319863001487\n",
      "train loss:0.917430596345195\n",
      "train loss:0.9430177635638327\n",
      "train loss:1.0611993647740834\n",
      "train loss:0.7947672818798242\n",
      "train loss:1.1508500845563778\n",
      "train loss:1.1383365196605204\n",
      "train loss:1.0989013185588792\n",
      "train loss:1.1174082388205953\n",
      "train loss:0.9882715974285655\n",
      "train loss:1.127024290199359\n",
      "train loss:1.0388796335826722\n",
      "train loss:1.026787707254912\n",
      "train loss:0.8672138606049091\n",
      "train loss:0.9893424999713573\n",
      "train loss:1.0082019721773867\n",
      "train loss:0.8490582286287576\n",
      "train loss:1.1397004633764496\n",
      "train loss:0.9207928283887769\n",
      "train loss:0.9610185962525774\n",
      "train loss:1.009760891903336\n",
      "train loss:0.96031364819242\n",
      "train loss:0.8898479617504926\n",
      "train loss:0.8497255036543995\n",
      "train loss:1.1023244684098372\n",
      "train loss:1.0720595702634401\n",
      "train loss:0.9788053858386101\n",
      "train loss:1.007140276884144\n",
      "train loss:1.0945291716342458\n",
      "train loss:1.0629603162359382\n",
      "train loss:1.1224204759275562\n",
      "train loss:1.0703647089265227\n",
      "train loss:0.8625177962325055\n",
      "train loss:0.8390274554674666\n",
      "train loss:1.0877766736825198\n",
      "train loss:0.927160223789498\n",
      "train loss:0.9873834220761368\n",
      "train loss:1.0710447370592464\n",
      "train loss:1.0596073915316782\n",
      "train loss:0.9035278840077717\n",
      "train loss:1.0365976747848993\n",
      "train loss:0.9951263113299063\n",
      "train loss:1.0736921721824009\n",
      "train loss:1.040597462481802\n",
      "train loss:0.879479698610824\n",
      "train loss:1.0284003596000866\n",
      "train loss:1.059898323644462\n",
      "train loss:0.9666453792750938\n",
      "train loss:0.9150890822284226\n",
      "train loss:1.089061503959817\n",
      "train loss:0.9115902783693707\n",
      "train loss:0.9505902042415082\n",
      "train loss:1.033575202708201\n",
      "train loss:0.9597391242513875\n",
      "train loss:0.9605121706116557\n",
      "train loss:1.1940952788749641\n",
      "train loss:0.9836423432604032\n",
      "train loss:1.035254225882546\n",
      "train loss:0.9634946010183207\n",
      "train loss:1.046054466446025\n",
      "train loss:1.1306088930140568\n",
      "train loss:1.0606703868199343\n",
      "train loss:0.9022730952247479\n",
      "train loss:0.9031351523843543\n",
      "train loss:1.106882239645927\n",
      "train loss:1.088911474715614\n",
      "train loss:1.0456732182775716\n",
      "train loss:0.9944907056093143\n",
      "train loss:1.1056619874018403\n",
      "train loss:0.9578753132971299\n",
      "train loss:1.0373293079256307\n",
      "train loss:1.1676236189290996\n",
      "train loss:0.9136502172392487\n",
      "train loss:1.1431657913351059\n",
      "train loss:0.9241012225656047\n",
      "train loss:0.9921439067606727\n",
      "train loss:0.9138486535852263\n",
      "train loss:1.0200518588583989\n",
      "train loss:0.9703832302789092\n",
      "train loss:0.931649922862088\n",
      "train loss:1.0880749952013327\n",
      "train loss:0.9907441921818332\n",
      "train loss:0.982392702710226\n",
      "train loss:0.9669727499113105\n",
      "train loss:0.7902414318674071\n",
      "train loss:1.0334725208919462\n",
      "train loss:1.292642043873664\n",
      "train loss:1.0514904601340855\n",
      "train loss:1.07971508597113\n",
      "train loss:0.9505410288198887\n",
      "train loss:0.9874262456502707\n",
      "train loss:1.0110474332546489\n",
      "train loss:0.9522697638226593\n",
      "train loss:1.253850869302826\n",
      "train loss:1.051738784405768\n",
      "train loss:0.9847501524618119\n",
      "train loss:1.0185739230430095\n",
      "train loss:1.0517679511940579\n",
      "train loss:0.94317198957905\n",
      "train loss:1.0559107375273182\n",
      "train loss:1.1966962296728452\n",
      "train loss:1.013157879831404\n",
      "train loss:0.8554169638734767\n",
      "train loss:1.0436644871057266\n",
      "train loss:1.022657489871539\n",
      "train loss:1.1945214743366646\n",
      "train loss:0.9528576177044248\n",
      "train loss:0.9057325248192477\n",
      "train loss:1.1159470036520722\n",
      "train loss:0.9559697793367876\n",
      "train loss:1.2483721664150607\n",
      "train loss:0.9014674540961797\n",
      "train loss:0.8578714074220486\n",
      "train loss:1.0157231733003913\n",
      "train loss:0.9299998690013672\n",
      "train loss:1.059115814051039\n",
      "train loss:1.2726655126772386\n",
      "train loss:0.8987686449057822\n",
      "train loss:0.9588516454219509\n",
      "train loss:0.9782653888668214\n",
      "train loss:1.130909205026643\n",
      "train loss:0.9499524527207305\n",
      "train loss:1.2100984204759009\n",
      "train loss:1.058301139250509\n",
      "train loss:0.7984271339080089\n",
      "train loss:0.9290428584067152\n",
      "train loss:1.1480044286676356\n",
      "train loss:0.926168820862618\n",
      "train loss:0.9992774685378844\n",
      "train loss:1.1011822721928302\n",
      "train loss:1.048745805254007\n",
      "train loss:0.9781605975066738\n",
      "train loss:1.2283300554811105\n",
      "train loss:0.9178512251373938\n",
      "train loss:1.0943985264298772\n",
      "train loss:0.976421343950626\n",
      "train loss:1.0383254655129648\n",
      "train loss:0.8527634814099848\n",
      "train loss:0.8130193677983577\n",
      "train loss:1.2725102753056736\n",
      "train loss:1.0218697906036105\n",
      "train loss:1.1568227182774693\n",
      "train loss:1.1024193675700569\n",
      "train loss:0.8566055788632858\n",
      "train loss:1.0496677412667195\n",
      "train loss:1.0469910791119919\n",
      "train loss:0.9515409463106831\n",
      "train loss:0.9661168660265329\n",
      "train loss:1.0408049167981959\n",
      "train loss:1.0916998755392688\n",
      "train loss:0.8751672085665391\n",
      "train loss:1.049259206860177\n",
      "train loss:1.065374577225474\n",
      "train loss:1.0237521968313437\n",
      "train loss:0.9044368005806492\n",
      "train loss:0.8871859617138892\n",
      "train loss:1.1031743037170765\n",
      "train loss:1.1354926855427256\n",
      "train loss:0.9920710086872297\n",
      "train loss:1.1113483406974287\n",
      "train loss:1.1036861826992876\n",
      "train loss:1.0096081796774052\n",
      "train loss:1.003819850652973\n",
      "train loss:1.1773315168511302\n",
      "train loss:0.9811976917658114\n",
      "train loss:1.1999679105115835\n",
      "train loss:0.902235926096084\n",
      "train loss:1.049453455480642\n",
      "train loss:1.1688344298993996\n",
      "train loss:1.3203892742859207\n",
      "train loss:1.0958684526576712\n",
      "train loss:1.0600559850555293\n",
      "train loss:1.02461350795749\n",
      "train loss:1.074989120974279\n",
      "train loss:0.7957688323376325\n",
      "train loss:1.0832306691652025\n",
      "train loss:1.1370521968446052\n",
      "train loss:1.0477245696975646\n",
      "train loss:1.1434701292793559\n",
      "train loss:1.0065597708947565\n",
      "train loss:1.000134728526753\n",
      "train loss:1.1939407534640762\n",
      "train loss:1.1319367985422604\n",
      "train loss:1.0130435218582472\n",
      "train loss:1.0817787030952224\n",
      "train loss:0.9872290286711103\n",
      "train loss:1.0832210277491783\n",
      "train loss:1.1516502909426591\n",
      "train loss:1.142706981082944\n",
      "train loss:1.0676824764637591\n",
      "train loss:1.0630715272103184\n",
      "train loss:0.9718045497255849\n",
      "train loss:0.9819928088265126\n",
      "train loss:1.006939047710954\n",
      "train loss:1.187905720838676\n",
      "train loss:0.9146463876150355\n",
      "train loss:1.0126732040152695\n",
      "train loss:1.0344265708389002\n",
      "train loss:1.1064235245528706\n",
      "train loss:0.8450572165481991\n",
      "train loss:1.1552566063789313\n",
      "train loss:0.9595916818044493\n",
      "train loss:0.9252139565784518\n",
      "train loss:0.8559859310509579\n",
      "train loss:0.9660943037445792\n",
      "train loss:0.9505582810388472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9010574860039472\n",
      "train loss:0.8121227502396532\n",
      "train loss:1.0525326532730073\n",
      "train loss:0.9977917110272381\n",
      "train loss:1.117322245556071\n",
      "train loss:0.85776946524962\n",
      "train loss:1.1095353551218974\n",
      "train loss:1.0107881434386927\n",
      "train loss:1.2230378096653234\n",
      "train loss:0.9863216065509763\n",
      "train loss:0.9816244101029049\n",
      "train loss:0.9336786124543971\n",
      "train loss:1.0589744549950226\n",
      "train loss:0.9897613924050213\n",
      "train loss:1.12610142681029\n",
      "train loss:0.9673510004468155\n",
      "train loss:0.995084315770367\n",
      "train loss:1.1423598894845468\n",
      "train loss:1.0677211141170802\n",
      "train loss:0.9632221812891925\n",
      "train loss:1.019010312822324\n",
      "train loss:0.9320078206234492\n",
      "train loss:0.9667224905998535\n",
      "train loss:1.1221482429010474\n",
      "train loss:1.036223031999186\n",
      "=== epoch:7, train acc:0.98, test acc:0.978 ===\n",
      "train loss:1.1371152116319168\n",
      "train loss:1.1316633513410779\n",
      "train loss:0.9511254592110574\n",
      "train loss:1.1697732726880072\n",
      "train loss:0.9762968104407418\n",
      "train loss:0.9657705060231973\n",
      "train loss:0.9123593986586536\n",
      "train loss:0.8970155859915198\n",
      "train loss:1.1837458166584147\n",
      "train loss:1.114616529333819\n",
      "train loss:1.1047284478932349\n",
      "train loss:1.0469748499342981\n",
      "train loss:0.9321500777915869\n",
      "train loss:0.770735575284659\n",
      "train loss:1.031320912348499\n",
      "train loss:1.1977577248585651\n",
      "train loss:1.0490328493386536\n",
      "train loss:0.9258906652719877\n",
      "train loss:1.0453694216983846\n",
      "train loss:0.8638059440911576\n",
      "train loss:1.0808988701363405\n",
      "train loss:0.9961782456595265\n",
      "train loss:0.8035481104909544\n",
      "train loss:0.9305674188451962\n",
      "train loss:0.9784612995224872\n",
      "train loss:0.7801248245177114\n",
      "train loss:0.9937586496333166\n",
      "train loss:1.0350276233130349\n",
      "train loss:1.1044110076730735\n",
      "train loss:1.0260927240598616\n",
      "train loss:0.9386368569679433\n",
      "train loss:0.9804158339066157\n",
      "train loss:1.182900564668083\n",
      "train loss:0.8554861485301772\n",
      "train loss:1.1901158173992548\n",
      "train loss:1.078257147923302\n",
      "train loss:1.0119343486967005\n",
      "train loss:0.963974897846331\n",
      "train loss:1.2089646335873458\n",
      "train loss:1.104204330930277\n",
      "train loss:0.7619889895384236\n",
      "train loss:0.9526817528717061\n",
      "train loss:1.0039517485824616\n",
      "train loss:0.936091706480034\n",
      "train loss:1.1099036500781552\n",
      "train loss:0.9236063488638829\n",
      "train loss:0.9802833485996193\n",
      "train loss:0.9049034470267029\n",
      "train loss:1.1148614990143768\n",
      "train loss:0.9603556985644459\n",
      "train loss:1.1970660934215682\n",
      "train loss:0.9890375696229232\n",
      "train loss:0.9664886422568878\n",
      "train loss:0.9749127125854784\n",
      "train loss:0.9747305027542069\n",
      "train loss:0.83985858454122\n",
      "train loss:1.060765518779031\n",
      "train loss:1.0416558610374793\n",
      "train loss:1.0521993159874719\n",
      "train loss:0.9978301103616775\n",
      "train loss:0.9901327660380488\n",
      "train loss:0.9647161120431804\n",
      "train loss:0.9983700497390687\n",
      "train loss:1.0036630480302873\n",
      "train loss:0.7835723753363255\n",
      "train loss:0.9917560690994139\n",
      "train loss:0.904317200596518\n",
      "train loss:1.0201273084351896\n",
      "train loss:1.064936860685747\n",
      "train loss:1.0113031424747965\n",
      "train loss:1.1052366567677434\n",
      "train loss:1.0569018034472484\n",
      "train loss:1.0979924736815434\n",
      "train loss:1.065329034395332\n",
      "train loss:1.001927503426979\n",
      "train loss:0.8431659372134733\n",
      "train loss:1.06210335518468\n",
      "train loss:1.0843315855980544\n",
      "train loss:0.968660972991738\n",
      "train loss:0.9324867070065214\n",
      "train loss:1.0300490440627115\n",
      "train loss:1.0023511399292533\n",
      "train loss:1.108425232005454\n",
      "train loss:1.068258062023083\n",
      "train loss:0.9695497821911637\n",
      "train loss:0.9785871874651001\n",
      "train loss:1.1000672783874856\n",
      "train loss:1.0575160476162844\n",
      "train loss:1.0017105375823339\n",
      "train loss:1.1140976279255463\n",
      "train loss:1.0545808172148445\n",
      "train loss:0.9345099603903506\n",
      "train loss:1.097751761055457\n",
      "train loss:0.917782362827921\n",
      "train loss:0.945794674376213\n",
      "train loss:1.002483894975893\n",
      "train loss:1.074163946235282\n",
      "train loss:0.9938505710267705\n",
      "train loss:0.8652668842338369\n",
      "train loss:0.8072069657585769\n",
      "train loss:1.1325509850359388\n",
      "train loss:0.8959083964740239\n",
      "train loss:0.8803861298474791\n",
      "train loss:0.9339754154737\n",
      "train loss:0.8746586444453976\n",
      "train loss:1.1227286287545208\n",
      "train loss:0.9843873992090153\n",
      "train loss:1.0185046095469874\n",
      "train loss:1.0579114584175024\n",
      "train loss:0.9811929211396788\n",
      "train loss:1.178744317105082\n",
      "train loss:1.0162751274415849\n",
      "train loss:0.99341727541155\n",
      "train loss:0.9536367618190957\n",
      "train loss:0.914613504178136\n",
      "train loss:0.9730126385113309\n",
      "train loss:1.001993660086555\n",
      "train loss:0.8094619570809866\n",
      "train loss:1.0995887337016723\n",
      "train loss:1.1146426283440698\n",
      "train loss:0.9032423791663722\n",
      "train loss:0.9480410344812472\n",
      "train loss:1.070869161591262\n",
      "train loss:0.9275171409117856\n",
      "train loss:1.071883229171217\n",
      "train loss:0.9646986604494363\n",
      "train loss:0.9973510545850054\n",
      "train loss:0.9131050504377339\n",
      "train loss:1.0270475418947442\n",
      "train loss:1.0051319552701379\n",
      "train loss:0.9540420250864322\n",
      "train loss:1.1261912730815435\n",
      "train loss:1.0396726270653205\n",
      "train loss:1.0671395658220537\n",
      "train loss:0.9048507411388997\n",
      "train loss:0.8625514654323689\n",
      "train loss:0.993425040258698\n",
      "train loss:0.970518563971898\n",
      "train loss:1.1401449094534637\n",
      "train loss:1.0015688719985851\n",
      "train loss:1.1767056457848135\n",
      "train loss:0.8608186407636049\n",
      "train loss:0.9792391999682111\n",
      "train loss:1.0794677024397608\n",
      "train loss:1.007062090339216\n",
      "train loss:1.0270370571148315\n",
      "train loss:0.9980101698853641\n",
      "train loss:1.0769104559405778\n",
      "train loss:0.9277547856436671\n",
      "train loss:1.021850927374408\n",
      "train loss:1.0687185450045293\n",
      "train loss:1.0938411092663545\n",
      "train loss:0.8943900721575088\n",
      "train loss:0.9415904159352877\n",
      "train loss:0.9212810391225825\n",
      "train loss:1.0084336278636572\n",
      "train loss:1.096934357683203\n",
      "train loss:0.9442695880643289\n",
      "train loss:0.9253063444828221\n",
      "train loss:0.9255390933788396\n",
      "train loss:0.6995165463549208\n",
      "train loss:0.8950840583986295\n",
      "train loss:0.9783917361319461\n",
      "train loss:1.024917161021738\n",
      "train loss:0.9692147037500781\n",
      "train loss:0.8802379302302544\n",
      "train loss:0.9617772797773777\n",
      "train loss:1.092788025617311\n",
      "train loss:1.172706521897608\n",
      "train loss:1.01217932329158\n",
      "train loss:0.8803088370955986\n",
      "train loss:1.0258272595175306\n",
      "train loss:0.9454131200784424\n",
      "train loss:0.9532445797007562\n",
      "train loss:0.9515075170095733\n",
      "train loss:1.1085291607499195\n",
      "train loss:0.8781355172060147\n",
      "train loss:1.0630515338238986\n",
      "train loss:1.2428225365365502\n",
      "train loss:0.905779599157147\n",
      "train loss:1.0657577236558942\n",
      "train loss:0.8322895724365984\n",
      "train loss:0.9261338332583865\n",
      "train loss:0.9981871387770489\n",
      "train loss:0.9838895119456823\n",
      "train loss:0.9216069848909194\n",
      "train loss:1.2366925390070953\n",
      "train loss:0.9887019722109549\n",
      "train loss:1.0990791788180756\n",
      "train loss:0.9970812904768828\n",
      "train loss:0.8574909299524708\n",
      "train loss:1.1114103519215615\n",
      "train loss:0.8127556100142272\n",
      "train loss:1.2276818058505696\n",
      "train loss:1.0794878936783603\n",
      "train loss:1.1909012063021784\n",
      "train loss:0.85617862793854\n",
      "train loss:0.9530213717377911\n",
      "train loss:1.0929033738573286\n",
      "train loss:0.9820172308564229\n",
      "train loss:1.0866789978004272\n",
      "train loss:0.9565758809239878\n",
      "train loss:1.0993872334829282\n",
      "train loss:0.9342436913066152\n",
      "train loss:0.9040265632437235\n",
      "train loss:1.1147348823309315\n",
      "train loss:1.086571819551967\n",
      "train loss:0.7896468428146534\n",
      "train loss:1.0051435962709858\n",
      "train loss:0.8856112014165762\n",
      "train loss:0.8873688500271253\n",
      "train loss:1.1387917046571432\n",
      "train loss:0.9337529545091021\n",
      "train loss:0.8835318842348598\n",
      "train loss:1.1408844332261425\n",
      "train loss:0.7975954667478636\n",
      "train loss:0.912116840697724\n",
      "train loss:1.1030169452289955\n",
      "train loss:0.9887339844151048\n",
      "train loss:1.083422774183883\n",
      "train loss:1.0925109374487112\n",
      "train loss:1.0976930869671788\n",
      "train loss:0.8272966315604197\n",
      "train loss:0.9788919356329139\n",
      "train loss:0.8550912516716795\n",
      "train loss:0.9515355609726912\n",
      "train loss:1.0825002401235069\n",
      "train loss:1.0359040357516194\n",
      "train loss:1.0792927320287575\n",
      "train loss:1.0717091610705016\n",
      "train loss:1.0614043675849876\n",
      "train loss:0.7474085980692695\n",
      "train loss:0.9002025411287992\n",
      "train loss:1.0457963995600044\n",
      "train loss:0.8613220190579667\n",
      "train loss:0.9128470641212502\n",
      "train loss:1.0534443526686794\n",
      "train loss:0.8778400232591909\n",
      "train loss:1.0650396253266041\n",
      "train loss:1.1048098805564124\n",
      "train loss:1.023189198348494\n",
      "train loss:1.055437259736335\n",
      "train loss:0.9586790452418604\n",
      "train loss:0.9685904659932342\n",
      "train loss:1.0416747437661518\n",
      "train loss:0.9460875623597452\n",
      "train loss:0.9356300640401314\n",
      "train loss:1.0360850993001562\n",
      "train loss:0.9757877299757706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.071030247980523\n",
      "train loss:0.9022209859868533\n",
      "train loss:1.0263788596462284\n",
      "train loss:0.9830719102843676\n",
      "train loss:0.933507296823784\n",
      "train loss:0.8193216698187408\n",
      "train loss:0.8615524625293045\n",
      "train loss:0.8735545565213124\n",
      "train loss:0.8837987208872456\n",
      "train loss:0.9968098589256132\n",
      "train loss:0.9339410310500346\n",
      "train loss:1.057025863331687\n",
      "train loss:1.1107978218219774\n",
      "train loss:0.9926792820372793\n",
      "train loss:1.0038681144516035\n",
      "train loss:1.093859880528934\n",
      "train loss:1.1336793990906586\n",
      "train loss:1.0497601738065725\n",
      "train loss:0.9873025976572347\n",
      "train loss:1.0401279520486377\n",
      "train loss:1.0331763537026568\n",
      "train loss:1.1690555163606031\n",
      "train loss:0.9034531360841652\n",
      "train loss:0.9493084686875496\n",
      "train loss:0.951218125664015\n",
      "train loss:0.9224181446021317\n",
      "train loss:0.9909787460707744\n",
      "train loss:0.9687033891536688\n",
      "train loss:1.0503674135669678\n",
      "train loss:0.9887904558063112\n",
      "train loss:1.046401288078619\n",
      "train loss:0.9385070114123198\n",
      "train loss:0.930708039256795\n",
      "train loss:1.0643865359208144\n",
      "train loss:0.8116750635962774\n",
      "train loss:1.0802033487410898\n",
      "train loss:1.0110733218230887\n",
      "train loss:1.050397184779262\n",
      "train loss:1.088420499702634\n",
      "train loss:0.8605071439433694\n",
      "train loss:1.2290846150247123\n",
      "train loss:0.8274423786304347\n",
      "train loss:1.0419492968107174\n",
      "train loss:0.9291416126328379\n",
      "train loss:0.8141347563527788\n",
      "train loss:1.0330582131088952\n",
      "train loss:0.859493319577211\n",
      "train loss:1.035314330450027\n",
      "train loss:0.8646068235460589\n",
      "train loss:0.9765011923566944\n",
      "train loss:0.9430559378272979\n",
      "train loss:1.1040673091942204\n",
      "train loss:0.832513913387521\n",
      "train loss:0.872145695701678\n",
      "train loss:1.1680083262130403\n",
      "train loss:0.8777805115831907\n",
      "train loss:1.052578565918917\n",
      "train loss:1.0322071330996554\n",
      "train loss:1.0365722806677138\n",
      "train loss:0.9888524449609517\n",
      "train loss:0.9742677720307605\n",
      "train loss:1.0729467980374472\n",
      "train loss:0.9562051846357089\n",
      "train loss:1.0660037443183266\n",
      "train loss:0.920450465374294\n",
      "train loss:1.2525064099591539\n",
      "train loss:1.0886442998902928\n",
      "train loss:0.9507067636958412\n",
      "train loss:1.0427123791687258\n",
      "train loss:0.8879150750860183\n",
      "train loss:0.9888982412712113\n",
      "train loss:0.9834291189711967\n",
      "train loss:1.0390944502596766\n",
      "train loss:1.0079636221312556\n",
      "train loss:1.0102753854637043\n",
      "train loss:1.088380837938402\n",
      "train loss:0.9333624643697778\n",
      "train loss:1.070809673774732\n",
      "train loss:0.972296394432948\n",
      "train loss:1.0794438949841962\n",
      "train loss:0.8281803427048903\n",
      "train loss:0.956683446521991\n",
      "train loss:1.058183958862375\n",
      "train loss:0.8745269736521085\n",
      "train loss:1.205778128113452\n",
      "train loss:0.9776707453273281\n",
      "train loss:1.0853031789134286\n",
      "train loss:0.8464123076307368\n",
      "train loss:1.0398379740451624\n",
      "train loss:1.078635533569967\n",
      "train loss:1.1259919644544971\n",
      "train loss:1.009790986194182\n",
      "train loss:0.9491531980184356\n",
      "train loss:1.116705590775915\n",
      "train loss:0.9207551885247114\n",
      "train loss:0.759143527169808\n",
      "train loss:0.9681782904996818\n",
      "train loss:0.9941771391655536\n",
      "train loss:0.8789012897686007\n",
      "train loss:0.9040367600379626\n",
      "train loss:0.9598236335018125\n",
      "train loss:0.9665990220908789\n",
      "train loss:1.012193577913048\n",
      "train loss:1.0380427684115736\n",
      "train loss:0.9628615912629206\n",
      "train loss:1.039985490544007\n",
      "train loss:0.9963902392322957\n",
      "train loss:1.0532920635988208\n",
      "train loss:1.1148140580903023\n",
      "train loss:1.0264156066419006\n",
      "train loss:1.0335041604157151\n",
      "train loss:1.139408560132895\n",
      "train loss:0.897382118187481\n",
      "train loss:1.0301471766052392\n",
      "train loss:0.9159758706851712\n",
      "train loss:0.9707758541404412\n",
      "train loss:1.0461641746593615\n",
      "train loss:0.8602386467559819\n",
      "train loss:0.9263268851964481\n",
      "train loss:0.9696539984803562\n",
      "train loss:1.1126693452936731\n",
      "train loss:0.9498839338399877\n",
      "train loss:1.0622496901698995\n",
      "train loss:1.0416647725807957\n",
      "train loss:0.9844419382111951\n",
      "train loss:1.0411729835698074\n",
      "train loss:1.0306321942803\n",
      "train loss:0.7460232205137949\n",
      "train loss:1.0213298802587898\n",
      "train loss:1.102348925942301\n",
      "train loss:0.9884448952064776\n",
      "train loss:0.9762343161542597\n",
      "train loss:0.9301840680728901\n",
      "train loss:1.0274585301003492\n",
      "train loss:0.9690825882364887\n",
      "train loss:1.022238859178921\n",
      "train loss:1.0205264255499644\n",
      "train loss:1.128876174108724\n",
      "train loss:0.8751151673045637\n",
      "train loss:0.9051682361971528\n",
      "train loss:0.9459707818665025\n",
      "train loss:0.9421445036238236\n",
      "train loss:1.1009662669683458\n",
      "train loss:1.0864636788371413\n",
      "train loss:0.9240811149508743\n",
      "train loss:1.0155921549339153\n",
      "train loss:1.026519834738263\n",
      "train loss:0.9128558578852537\n",
      "train loss:0.9528374882767795\n",
      "train loss:0.8981473651472902\n",
      "train loss:1.0634266697519301\n",
      "train loss:1.0794141341056924\n",
      "train loss:0.7869230926887524\n",
      "train loss:0.9963211591514248\n",
      "train loss:1.0778574136002939\n",
      "train loss:0.9842748345652389\n",
      "train loss:1.0176920962527085\n",
      "train loss:1.022681622396367\n",
      "train loss:0.9033555052545075\n",
      "train loss:1.137442897564845\n",
      "train loss:0.9207660451035947\n",
      "train loss:0.8274284058345089\n",
      "train loss:0.9468058651997197\n",
      "train loss:1.0687038348645783\n",
      "train loss:0.8935915952994811\n",
      "train loss:1.0386002708551125\n",
      "train loss:1.0272691535648752\n",
      "train loss:1.0198130819098805\n",
      "train loss:1.2577327401283747\n",
      "train loss:1.0313082172931307\n",
      "train loss:0.9170444301357402\n",
      "train loss:1.0260971820983595\n",
      "train loss:0.9494417782892792\n",
      "train loss:1.0424479523202974\n",
      "train loss:1.095538969193517\n",
      "train loss:1.01917218752143\n",
      "train loss:0.9944948910799668\n",
      "train loss:0.8942492767443649\n",
      "train loss:0.9723205625208813\n",
      "train loss:0.9757916344071398\n",
      "train loss:1.1464164445260012\n",
      "train loss:1.0755929380253806\n",
      "train loss:0.938792852199057\n",
      "train loss:0.9639589678250843\n",
      "train loss:0.9489895743001798\n",
      "train loss:1.0936855907330834\n",
      "train loss:0.8896048010402585\n",
      "train loss:0.8479486719716942\n",
      "train loss:1.12298517149624\n",
      "train loss:1.0174687318903641\n",
      "train loss:0.7724275288092673\n",
      "train loss:1.055660969786227\n",
      "train loss:1.0197498197893955\n",
      "train loss:1.0486427180565492\n",
      "train loss:0.8961692415768148\n",
      "train loss:1.030492036995281\n",
      "train loss:1.1364365394550995\n",
      "train loss:1.030492157091803\n",
      "train loss:1.0307609488519633\n",
      "train loss:1.0288080898706484\n",
      "train loss:0.9864490142552629\n",
      "train loss:1.040277753773452\n",
      "train loss:1.0228621891641665\n",
      "train loss:1.0192025356082997\n",
      "train loss:1.0095793327581029\n",
      "train loss:0.9821053349528248\n",
      "train loss:0.876997583532505\n",
      "train loss:0.9244311706270562\n",
      "train loss:0.9137991792664867\n",
      "train loss:1.1405888886333713\n",
      "train loss:0.9846036089406631\n",
      "train loss:0.8738649668610564\n",
      "train loss:1.0602093727975428\n",
      "train loss:0.9848646419563235\n",
      "train loss:0.9268270042523206\n",
      "train loss:0.9276953715662205\n",
      "train loss:1.0213820598242582\n",
      "train loss:0.8119813390291791\n",
      "train loss:0.9319978185152686\n",
      "train loss:0.9040069336401747\n",
      "train loss:1.0649934379306552\n",
      "train loss:0.9171815455276128\n",
      "train loss:0.9747158023591134\n",
      "train loss:0.9504502746182872\n",
      "train loss:0.9645374476384514\n",
      "train loss:0.9561845019538555\n",
      "train loss:0.8982294297175402\n",
      "train loss:0.9930157850361945\n",
      "train loss:1.0318930073237724\n",
      "train loss:1.1197569911338847\n",
      "train loss:0.8119023501116606\n",
      "train loss:0.8439282422210311\n",
      "train loss:1.0427956987525773\n",
      "train loss:0.9733680434044326\n",
      "train loss:0.9851490134301433\n",
      "train loss:0.9403590942568977\n",
      "train loss:0.9952454623595753\n",
      "train loss:0.9212735402981438\n",
      "train loss:1.0157729781348097\n",
      "train loss:0.9646141685499809\n",
      "train loss:1.109010935810787\n",
      "train loss:0.8428139102084721\n",
      "train loss:0.8991812339807609\n",
      "train loss:0.8294338786181862\n",
      "train loss:1.2269823224014917\n",
      "train loss:1.0770017963489376\n",
      "train loss:0.9115008590639079\n",
      "train loss:1.1866752492577306\n",
      "train loss:1.1085191979197353\n",
      "train loss:1.048421428826155\n",
      "train loss:0.9936362401386297\n",
      "train loss:1.023949163270849\n",
      "train loss:1.068821077939881\n",
      "train loss:0.8123040191939315\n",
      "train loss:0.8584040522271285\n",
      "train loss:0.9393892411142097\n",
      "train loss:0.9376074424645764\n",
      "train loss:1.1750508030375864\n",
      "train loss:0.9090767397183345\n",
      "train loss:1.2910931775879018\n",
      "train loss:1.2089988158675737\n",
      "train loss:1.0304109831575103\n",
      "train loss:0.9459415134705316\n",
      "train loss:1.0581210870241602\n",
      "train loss:1.1475073030112282\n",
      "train loss:0.9670982150073465\n",
      "train loss:0.9328192582811622\n",
      "train loss:0.9676158279080513\n",
      "train loss:0.9612797587176103\n",
      "train loss:0.8660518495646815\n",
      "train loss:0.921821380178779\n",
      "train loss:0.8704716307768756\n",
      "train loss:1.0968368779514248\n",
      "train loss:0.9965554744308655\n",
      "train loss:1.0150179539094575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9776750619388908\n",
      "train loss:1.0422291252650489\n",
      "train loss:0.8720474237460034\n",
      "train loss:0.7468591846759537\n",
      "train loss:1.078348588290894\n",
      "train loss:1.1099520764965463\n",
      "train loss:0.802045418158646\n",
      "train loss:1.055479803416282\n",
      "train loss:0.8816147216346348\n",
      "train loss:0.9467096109690325\n",
      "train loss:0.8831827807567401\n",
      "train loss:0.9161608311854789\n",
      "train loss:0.9880657408106032\n",
      "train loss:0.9615804240084216\n",
      "train loss:0.8012836699596404\n",
      "train loss:0.7762220360849074\n",
      "train loss:0.8626495914234826\n",
      "train loss:0.9768671775398592\n",
      "train loss:0.9417587077788424\n",
      "train loss:0.9600215582410911\n",
      "train loss:0.8831840056324238\n",
      "train loss:0.8742207365104682\n",
      "train loss:0.9149057018329294\n",
      "train loss:0.8668976307533569\n",
      "train loss:1.0539393815504232\n",
      "train loss:1.1786561068385986\n",
      "train loss:0.9492261195814043\n",
      "train loss:1.0730490124526613\n",
      "train loss:1.0094925026631545\n",
      "train loss:1.0663600414479446\n",
      "train loss:1.0631051640888245\n",
      "train loss:1.067781140618496\n",
      "train loss:1.057365721736756\n",
      "train loss:0.9349127976588547\n",
      "train loss:0.976045083684256\n",
      "train loss:1.022018635634633\n",
      "train loss:1.0090872901890613\n",
      "train loss:1.3490585790582303\n",
      "train loss:1.1061276848063806\n",
      "train loss:1.0644580965305739\n",
      "train loss:1.0997327758009887\n",
      "train loss:0.9334883895812108\n",
      "train loss:1.1476605874183212\n",
      "train loss:0.8419232546037304\n",
      "train loss:0.7994672426062469\n",
      "train loss:1.1765711987119427\n",
      "train loss:0.6684363784238626\n",
      "train loss:0.9102553189520635\n",
      "train loss:1.0683012997774695\n",
      "train loss:1.0915295174886974\n",
      "train loss:1.1075812768042912\n",
      "train loss:0.9208736087535105\n",
      "train loss:0.9625465706876732\n",
      "train loss:1.0304217412072798\n",
      "train loss:1.0613083766099494\n",
      "train loss:0.9379363934370423\n",
      "train loss:1.0575911596414578\n",
      "train loss:0.9442123550789231\n",
      "train loss:0.9740358917647272\n",
      "train loss:0.9554460545101364\n",
      "train loss:0.8617743122059273\n",
      "train loss:0.7602829566287771\n",
      "train loss:1.0166477794067281\n",
      "train loss:1.0215440847978263\n",
      "train loss:0.9364591689027221\n",
      "train loss:0.9846093069653437\n",
      "train loss:1.0969946443248766\n",
      "train loss:1.15687945141043\n",
      "train loss:0.9869511343641357\n",
      "train loss:1.02802463595651\n",
      "train loss:0.9230889413416575\n",
      "train loss:0.95169008990176\n",
      "train loss:0.9548840952269819\n",
      "train loss:0.8137141933612653\n",
      "train loss:0.8686308059062484\n",
      "train loss:0.9653857330646178\n",
      "=== epoch:8, train acc:0.984, test acc:0.979 ===\n",
      "train loss:1.0008279650098004\n",
      "train loss:1.054717150741886\n",
      "train loss:1.0801666975734487\n",
      "train loss:1.1265848404544014\n",
      "train loss:0.9069322960255773\n",
      "train loss:1.0952374790588544\n",
      "train loss:0.9196933736731957\n",
      "train loss:1.0526278639344697\n",
      "train loss:0.9130609153174851\n",
      "train loss:0.9792913537057142\n",
      "train loss:1.1454420141726995\n",
      "train loss:1.038534305789822\n",
      "train loss:1.0234516199016854\n",
      "train loss:1.054710902445899\n",
      "train loss:0.9823555118899915\n",
      "train loss:0.9646975938965858\n",
      "train loss:1.0066004529669426\n",
      "train loss:0.894809187306766\n",
      "train loss:0.9094765609612786\n",
      "train loss:0.9758567071961219\n",
      "train loss:1.0502133771055355\n",
      "train loss:0.9289725230679785\n",
      "train loss:1.0935501329590196\n",
      "train loss:0.9510161971069191\n",
      "train loss:1.1254117746888617\n",
      "train loss:1.004649086615953\n",
      "train loss:0.9160629221671782\n",
      "train loss:1.0045756987698986\n",
      "train loss:0.8515844722704561\n",
      "train loss:1.0433304174355178\n",
      "train loss:1.0380794157792064\n",
      "train loss:1.0469789253820154\n",
      "train loss:0.9603118578273747\n",
      "train loss:1.2497502978587491\n",
      "train loss:1.0449164959987371\n",
      "train loss:0.8809054157938668\n",
      "train loss:0.9703068858459312\n",
      "train loss:1.0089194552529264\n",
      "train loss:1.057496745444478\n",
      "train loss:1.1923539519422135\n",
      "train loss:1.0617405902844934\n",
      "train loss:0.9132716634323944\n",
      "train loss:0.8160878713095133\n",
      "train loss:0.9360961847748519\n",
      "train loss:0.9055514740071763\n",
      "train loss:0.8263864264719141\n",
      "train loss:0.9058229483699661\n",
      "train loss:0.9842893512808643\n",
      "train loss:1.0361719885129157\n",
      "train loss:0.9046402684505915\n",
      "train loss:1.1495911485453576\n",
      "train loss:1.0865915035410305\n",
      "train loss:1.1817067084332042\n",
      "train loss:1.0218779707997907\n",
      "train loss:1.051106148004491\n",
      "train loss:0.9811311808531751\n",
      "train loss:1.0286642655893794\n",
      "train loss:0.8818390010149715\n",
      "train loss:1.1694452133110018\n",
      "train loss:1.2639915422027268\n",
      "train loss:1.1380181548793153\n",
      "train loss:0.8639724937727671\n",
      "train loss:1.031159000769257\n",
      "train loss:0.9850380395008037\n",
      "train loss:1.018301882758731\n",
      "train loss:1.0511452997267208\n",
      "train loss:0.879030494408489\n",
      "train loss:1.0294663923139034\n",
      "train loss:0.8936329582278479\n",
      "train loss:1.048208130530523\n",
      "train loss:0.9999438141731121\n",
      "train loss:0.8877678197956675\n",
      "train loss:1.0164382048785037\n",
      "train loss:1.011176006622299\n",
      "train loss:0.9279461329074442\n",
      "train loss:0.9685283405979537\n",
      "train loss:0.929437503945004\n",
      "train loss:0.9785345346293526\n",
      "train loss:1.161132858825659\n",
      "train loss:0.7344404276380817\n",
      "train loss:0.9117980033558887\n",
      "train loss:0.8968868972140561\n",
      "train loss:0.9719638852064881\n",
      "train loss:0.9109474231141637\n",
      "train loss:1.0792333811730692\n",
      "train loss:1.1848401218753493\n",
      "train loss:0.9911270051785714\n",
      "train loss:0.8611465496008358\n",
      "train loss:0.8922047375622532\n",
      "train loss:0.7971065501898602\n",
      "train loss:0.8363800886411588\n",
      "train loss:0.9910548899867392\n",
      "train loss:0.8870913520590692\n",
      "train loss:1.0905158083055255\n",
      "train loss:0.9866456422799608\n",
      "train loss:1.1858906495556862\n",
      "train loss:0.9728066894011076\n",
      "train loss:1.012097561291983\n",
      "train loss:0.8941624636969269\n",
      "train loss:1.1198032208533437\n",
      "train loss:1.001295950789444\n",
      "train loss:0.9535921189295826\n",
      "train loss:1.0982466122343915\n",
      "train loss:1.1443976688597712\n",
      "train loss:1.121439572189875\n",
      "train loss:1.2100085503157976\n",
      "train loss:1.0317636928205989\n",
      "train loss:0.9426525964916601\n",
      "train loss:0.9163329774521851\n",
      "train loss:0.9768717252452184\n",
      "train loss:0.9638546135484617\n",
      "train loss:1.0390758278782988\n",
      "train loss:0.9540726372227383\n",
      "train loss:0.9876153221791095\n",
      "train loss:0.9799805245996869\n",
      "train loss:0.8192108730944595\n",
      "train loss:1.083703843409518\n",
      "train loss:1.0036425747372046\n",
      "train loss:0.9485867930259428\n",
      "train loss:1.1042484726259334\n",
      "train loss:0.8733016270817884\n",
      "train loss:1.0286577326275843\n",
      "train loss:0.7720130809502463\n",
      "train loss:0.9868341413963251\n",
      "train loss:0.8950253582387113\n",
      "train loss:1.207007222812799\n",
      "train loss:1.1163010579434678\n",
      "train loss:0.8950321084556512\n",
      "train loss:1.002692785076596\n",
      "train loss:0.8677510707119838\n",
      "train loss:0.996728711318704\n",
      "train loss:0.766294734331624\n",
      "train loss:0.9118784279544581\n",
      "train loss:0.8455814933450866\n",
      "train loss:1.1082454877226149\n",
      "train loss:0.9572979730359706\n",
      "train loss:1.0347916050020214\n",
      "train loss:1.008276326694804\n",
      "train loss:0.927307013431744\n",
      "train loss:0.8412056827521137\n",
      "train loss:1.0447132663883318\n",
      "train loss:0.890696649477287\n",
      "train loss:1.130087617351932\n",
      "train loss:0.993296123120692\n",
      "train loss:1.0671684330671833\n",
      "train loss:1.0714957364938176\n",
      "train loss:1.1419585665089322\n",
      "train loss:1.1102179649207784\n",
      "train loss:1.0358566799303068\n",
      "train loss:1.0425218779859615\n",
      "train loss:0.8076182420541472\n",
      "train loss:0.9915492078912262\n",
      "train loss:0.968946391032164\n",
      "train loss:1.0263212481318662\n",
      "train loss:1.0555553747471487\n",
      "train loss:1.1064122469217654\n",
      "train loss:1.0300853724910282\n",
      "train loss:0.8108564140874748\n",
      "train loss:1.1385433898961832\n",
      "train loss:1.1022939945515895\n",
      "train loss:0.8312927773267763\n",
      "train loss:1.0870053263001884\n",
      "train loss:0.9381774473192244\n",
      "train loss:1.1072867709960332\n",
      "train loss:0.8682520631110313\n",
      "train loss:0.9143451261940417\n",
      "train loss:1.0000324671270393\n",
      "train loss:0.9314365018197718\n",
      "train loss:0.9877596045689573\n",
      "train loss:0.8500684009137807\n",
      "train loss:0.9159261248114777\n",
      "train loss:0.9390809118895471\n",
      "train loss:1.0116945690354848\n",
      "train loss:0.9260998024521626\n",
      "train loss:0.8402460799872817\n",
      "train loss:1.1463860590985067\n",
      "train loss:1.1288067371121047\n",
      "train loss:1.019052835810115\n",
      "train loss:1.0690617396598447\n",
      "train loss:0.874046189696284\n",
      "train loss:0.8888604498024962\n",
      "train loss:0.8959353164432422\n",
      "train loss:0.900008348257994\n",
      "train loss:0.7589388595614197\n",
      "train loss:0.9780856875109843\n",
      "train loss:1.0148690102448126\n",
      "train loss:0.856603063297326\n",
      "train loss:0.9910058222933514\n",
      "train loss:0.9731408196751063\n",
      "train loss:1.0704986686719045\n",
      "train loss:0.9058042534504778\n",
      "train loss:0.9332905779541479\n",
      "train loss:0.7764046206708433\n",
      "train loss:1.0920443769696888\n",
      "train loss:0.9690461274260558\n",
      "train loss:1.0715958877718121\n",
      "train loss:1.190064515563553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9725812214394081\n",
      "train loss:1.0714511459934812\n",
      "train loss:1.1459454615455495\n",
      "train loss:0.9774536432246655\n",
      "train loss:0.8473734848997303\n",
      "train loss:0.9463872337834808\n",
      "train loss:0.8701792123490466\n",
      "train loss:0.9841057566972655\n",
      "train loss:0.9400612735228816\n",
      "train loss:1.061878160280483\n",
      "train loss:0.9571719937508101\n",
      "train loss:0.8879892454518241\n",
      "train loss:0.9368796498211034\n",
      "train loss:1.0766445088618932\n",
      "train loss:1.0586597586902666\n",
      "train loss:0.7307001145821594\n",
      "train loss:0.9444473935107918\n",
      "train loss:0.9269055209810105\n",
      "train loss:1.0121924561148892\n",
      "train loss:1.029536803610943\n",
      "train loss:1.0157596440616217\n",
      "train loss:0.9124678257180336\n",
      "train loss:1.0396777389358922\n",
      "train loss:0.84995361245534\n",
      "train loss:1.0257668303209326\n",
      "train loss:0.9689676195640037\n",
      "train loss:0.7947230917130742\n",
      "train loss:1.1430280986045842\n",
      "train loss:0.9444741531403565\n",
      "train loss:1.0987551000368276\n",
      "train loss:1.06229489362066\n",
      "train loss:0.9575807098922445\n",
      "train loss:1.0067617941539233\n",
      "train loss:1.0308751701007592\n",
      "train loss:0.958565418559275\n",
      "train loss:1.192471439830887\n",
      "train loss:1.0881811890860984\n",
      "train loss:0.9444451613586935\n",
      "train loss:1.0228575246737028\n",
      "train loss:1.1206286638149345\n",
      "train loss:0.8960521035069011\n",
      "train loss:0.8283120941163209\n",
      "train loss:0.861415914274504\n",
      "train loss:0.9682026271832798\n",
      "train loss:0.8326366174651634\n",
      "train loss:1.0521628032284698\n",
      "train loss:1.1699084803899737\n",
      "train loss:0.8512564860290489\n",
      "train loss:0.8894492342946317\n",
      "train loss:0.9008808130550446\n",
      "train loss:0.994994813962786\n",
      "train loss:0.9319055888178656\n",
      "train loss:0.9861137107240253\n",
      "train loss:0.9532375927888094\n",
      "train loss:0.9672142553001233\n",
      "train loss:1.075854947642611\n",
      "train loss:1.100423420711577\n",
      "train loss:0.9756947209639472\n",
      "train loss:0.7875595475831454\n",
      "train loss:0.94103620219405\n",
      "train loss:0.9405181897428448\n",
      "train loss:0.9693415571907736\n",
      "train loss:1.0524840563685078\n",
      "train loss:1.14249677872968\n",
      "train loss:1.0141309256864324\n",
      "train loss:1.1143018377367764\n",
      "train loss:0.9225999000696913\n",
      "train loss:1.0361570628919448\n",
      "train loss:0.9365780770755425\n",
      "train loss:0.8851451556028365\n",
      "train loss:1.0173197522527082\n",
      "train loss:1.0927013791953408\n",
      "train loss:1.121442324668215\n",
      "train loss:1.056528254731005\n",
      "train loss:0.8008380022887447\n",
      "train loss:0.9659921976708518\n",
      "train loss:0.9254041406832583\n",
      "train loss:0.9162415892808454\n",
      "train loss:1.0064224223401737\n",
      "train loss:0.8576632171451773\n",
      "train loss:1.0759664905404336\n",
      "train loss:0.9731187111820244\n",
      "train loss:1.0309115369772321\n",
      "train loss:0.8564019483598666\n",
      "train loss:0.899398975370414\n",
      "train loss:1.0720496534092083\n",
      "train loss:0.9328586900552296\n",
      "train loss:0.9653217812840391\n",
      "train loss:1.0852075310580436\n",
      "train loss:1.1944337601166073\n",
      "train loss:1.099110140484464\n",
      "train loss:0.9425257442610675\n",
      "train loss:0.9655678467614298\n",
      "train loss:1.0355616551996618\n",
      "train loss:1.0039446557227214\n",
      "train loss:1.1281747453525626\n",
      "train loss:0.8528331325067242\n",
      "train loss:1.1453990208860028\n",
      "train loss:0.9735357723072172\n",
      "train loss:0.8707605407414504\n",
      "train loss:0.9193692356684889\n",
      "train loss:0.9376704315839245\n",
      "train loss:0.9389278396180155\n",
      "train loss:0.9569062374952826\n",
      "train loss:0.887400932852796\n",
      "train loss:1.234559362430549\n",
      "train loss:0.9871646108322207\n",
      "train loss:0.8352629925921177\n",
      "train loss:1.0338424180153254\n",
      "train loss:0.8343136526177172\n",
      "train loss:0.9982721245818916\n",
      "train loss:0.9180061203939167\n",
      "train loss:0.8908732690048267\n",
      "train loss:1.1041495211125685\n",
      "train loss:1.0486525143915444\n",
      "train loss:0.8726838956003325\n",
      "train loss:0.8354031555221105\n",
      "train loss:1.083281126832539\n",
      "train loss:1.0855109386332296\n",
      "train loss:0.9533198976758136\n",
      "train loss:1.0535774253122192\n",
      "train loss:1.0248616202161953\n",
      "train loss:0.9932021096297359\n",
      "train loss:1.0159624656751187\n",
      "train loss:0.9691797821507222\n",
      "train loss:0.8885418346194222\n",
      "train loss:1.0037701274288324\n",
      "train loss:1.0522680836492413\n",
      "train loss:1.0753354413364706\n",
      "train loss:0.9352696997366301\n",
      "train loss:1.006010019945145\n",
      "train loss:0.8430301570108882\n",
      "train loss:0.9449913472555365\n",
      "train loss:1.0455825342604201\n",
      "train loss:0.8004742738513899\n",
      "train loss:1.0348080654152436\n",
      "train loss:1.0570430045219366\n",
      "train loss:0.9641487299531885\n",
      "train loss:1.0357024218493829\n",
      "train loss:0.9471360551209248\n",
      "train loss:0.9682719745128899\n",
      "train loss:0.9288319270348704\n",
      "train loss:1.0173649259333017\n",
      "train loss:0.9601214934740007\n",
      "train loss:0.9713978431585959\n",
      "train loss:1.0709981663109518\n",
      "train loss:0.8547323715234627\n",
      "train loss:1.0131231549977293\n",
      "train loss:0.8253813519910566\n",
      "train loss:1.1918313589678307\n",
      "train loss:0.9155514721296271\n",
      "train loss:0.9182233849266583\n",
      "train loss:1.067345186276269\n",
      "train loss:1.0552164693017116\n",
      "train loss:0.9073320852892971\n",
      "train loss:0.843068962496262\n",
      "train loss:1.0868728397892586\n",
      "train loss:0.9571627946189131\n",
      "train loss:0.8749120473951895\n",
      "train loss:0.8759949272071101\n",
      "train loss:0.8524230935462026\n",
      "train loss:1.0695735055636408\n",
      "train loss:1.0111221392384968\n",
      "train loss:0.899599524332109\n",
      "train loss:0.9187558085188797\n",
      "train loss:0.9671888666327797\n",
      "train loss:1.0630979788256179\n",
      "train loss:0.9212490424781347\n",
      "train loss:0.9780864182397206\n",
      "train loss:0.9665715718024724\n",
      "train loss:1.1019644173565541\n",
      "train loss:0.9503701583982604\n",
      "train loss:0.9375684421102369\n",
      "train loss:0.9069121057527869\n",
      "train loss:1.0621029678053646\n",
      "train loss:1.102390115145578\n",
      "train loss:1.1343255335987972\n",
      "train loss:0.9183258012193342\n",
      "train loss:0.9760050741102763\n",
      "train loss:0.8708358646178729\n",
      "train loss:0.9454221763494634\n",
      "train loss:0.9454671478294813\n",
      "train loss:1.0210020976381724\n",
      "train loss:0.8762571091529243\n",
      "train loss:0.9316041084089295\n",
      "train loss:0.8870991529657809\n",
      "train loss:0.8963518240856644\n",
      "train loss:1.0468821683792644\n",
      "train loss:0.9914736863947171\n",
      "train loss:0.9644844985610816\n",
      "train loss:1.0385824936595462\n",
      "train loss:1.0812899841739432\n",
      "train loss:0.9686869332328558\n",
      "train loss:0.9345978080609733\n",
      "train loss:1.1146827862048325\n",
      "train loss:1.1901499858377933\n",
      "train loss:0.9314049017326043\n",
      "train loss:0.8689473209007126\n",
      "train loss:1.086504662118547\n",
      "train loss:0.857263106352231\n",
      "train loss:0.9742073014782524\n",
      "train loss:1.0561369559433396\n",
      "train loss:0.9879769618489\n",
      "train loss:0.9919094409197023\n",
      "train loss:0.9076453904258479\n",
      "train loss:1.0260710693803974\n",
      "train loss:1.1479727773324466\n",
      "train loss:1.0739716680663742\n",
      "train loss:1.0825155352269558\n",
      "train loss:1.1601525791050245\n",
      "train loss:1.0153856949409197\n",
      "train loss:1.0737141097404743\n",
      "train loss:1.0138397972178879\n",
      "train loss:0.987698328891388\n",
      "train loss:1.1209277548460572\n",
      "train loss:0.9975034902982292\n",
      "train loss:1.1259137988760468\n",
      "train loss:0.9077312517225137\n",
      "train loss:1.2119582764526076\n",
      "train loss:0.8098534246775287\n",
      "train loss:0.8681939229027749\n",
      "train loss:1.215222900837582\n",
      "train loss:1.0638406097898652\n",
      "train loss:0.6718142069119835\n",
      "train loss:1.002916480714904\n",
      "train loss:0.7951371015598819\n",
      "train loss:1.0455340057198452\n",
      "train loss:0.9746270092878977\n",
      "train loss:0.9895192313527025\n",
      "train loss:0.7043662851044898\n",
      "train loss:0.9884768273616161\n",
      "train loss:0.9392530302101717\n",
      "train loss:0.9029760615826603\n",
      "train loss:1.0444920794890447\n",
      "train loss:1.0080925200971147\n",
      "train loss:0.9862340542397348\n",
      "train loss:1.1243778766335308\n",
      "train loss:1.0457024920064633\n",
      "train loss:0.9712006312649487\n",
      "train loss:1.1194810695678274\n",
      "train loss:1.0542143769735037\n",
      "train loss:1.0451938462197747\n",
      "train loss:1.0485500695875367\n",
      "train loss:0.927743124791236\n",
      "train loss:0.9617423688598301\n",
      "train loss:0.8262614394418258\n",
      "train loss:0.9363309993113035\n",
      "train loss:1.0181763378850226\n",
      "train loss:1.0234480956121152\n",
      "train loss:0.9370128256911282\n",
      "train loss:1.014038886312762\n",
      "train loss:1.0905514967629195\n",
      "train loss:0.9649747454341449\n",
      "train loss:1.0370801544641741\n",
      "train loss:0.9724532009070573\n",
      "train loss:1.1481876573093523\n",
      "train loss:0.9633737894390575\n",
      "train loss:0.814028366695691\n",
      "train loss:0.9129706043083552\n",
      "train loss:0.9281380293909686\n",
      "train loss:1.1331576314824519\n",
      "train loss:0.945717574561193\n",
      "train loss:1.066253898999984\n",
      "train loss:1.184845952502138\n",
      "train loss:0.95479789099385\n",
      "train loss:0.8474103060900119\n",
      "train loss:0.8015283460430297\n",
      "train loss:0.7680299490829735\n",
      "train loss:0.989134022794811\n",
      "train loss:1.1609148318523768\n",
      "train loss:0.7784977634198998\n",
      "train loss:1.0465101000638446\n",
      "train loss:0.7875508237240707\n",
      "train loss:0.855157136787888\n",
      "train loss:1.1238849535770257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9685109553312808\n",
      "train loss:0.9502580373275962\n",
      "train loss:1.061973201063294\n",
      "train loss:1.0592249464750878\n",
      "train loss:1.052422847156029\n",
      "train loss:1.049645647505336\n",
      "train loss:0.9783953860151152\n",
      "train loss:0.8940283822385713\n",
      "train loss:1.0290492103333848\n",
      "train loss:0.8939711808038558\n",
      "train loss:0.9318498832102086\n",
      "train loss:0.9697407908487361\n",
      "train loss:1.1523003271149634\n",
      "train loss:0.9160841816778196\n",
      "train loss:0.921012843604385\n",
      "train loss:1.0232811496881742\n",
      "train loss:1.0104538482283905\n",
      "train loss:0.8724867192884848\n",
      "train loss:0.9659769704375095\n",
      "train loss:0.9696321000410352\n",
      "train loss:0.9510877527161651\n",
      "train loss:1.0415012548521405\n",
      "train loss:0.6730889744008419\n",
      "train loss:0.9686070940019741\n",
      "train loss:1.0534104186068867\n",
      "train loss:0.8755308686436731\n",
      "train loss:0.7952743903482146\n",
      "train loss:1.291613602026309\n",
      "train loss:0.9914319086112142\n",
      "train loss:0.9262123743536803\n",
      "train loss:0.9230169168848623\n",
      "train loss:0.8682496110931701\n",
      "train loss:0.8438853076111049\n",
      "train loss:0.9402132172677636\n",
      "train loss:1.0055651410882878\n",
      "train loss:0.7995338151229525\n",
      "train loss:0.869044854227459\n",
      "train loss:1.041680565452856\n",
      "train loss:0.8546777990599879\n",
      "train loss:0.880701237174509\n",
      "train loss:1.0532686936911009\n",
      "train loss:0.8634897530359262\n",
      "train loss:1.0110771838157262\n",
      "train loss:0.856906072886868\n",
      "train loss:0.8359272479529067\n",
      "train loss:1.1407666084099257\n",
      "train loss:1.036588717992185\n",
      "train loss:1.1139856992225101\n",
      "train loss:0.8103734866049441\n",
      "train loss:0.7444813436245576\n",
      "train loss:0.9924996263680884\n",
      "train loss:0.9154911081254575\n",
      "train loss:1.042534747159146\n",
      "train loss:0.8499854520615228\n",
      "train loss:0.8295296227845482\n",
      "train loss:1.075279086111821\n",
      "train loss:0.8941311380244292\n",
      "train loss:0.7355757937514262\n",
      "train loss:0.922312843294815\n",
      "train loss:0.7887985969797481\n",
      "train loss:1.1243648661075896\n",
      "train loss:0.8998345496886992\n",
      "train loss:0.8795843585718298\n",
      "train loss:1.0168588543857016\n",
      "train loss:0.901711604642188\n",
      "train loss:0.9909648676358208\n",
      "train loss:0.9969258340640218\n",
      "train loss:1.0674222910110194\n",
      "train loss:0.8912219964572633\n",
      "train loss:0.9692619983061995\n",
      "train loss:0.7735585234327302\n",
      "train loss:1.0225889290864552\n",
      "train loss:0.9728989397680543\n",
      "train loss:1.0188348704529495\n",
      "train loss:0.8678142928577834\n",
      "train loss:1.0372399734481434\n",
      "train loss:0.9923666793854136\n",
      "train loss:0.805110199830936\n",
      "train loss:1.0544987278677629\n",
      "train loss:1.189289134231189\n",
      "train loss:0.7059273785124638\n",
      "train loss:0.8252436433735927\n",
      "train loss:1.0892458973173815\n",
      "train loss:0.8997215245128133\n",
      "train loss:0.9416413925018899\n",
      "train loss:0.9131463763761658\n",
      "train loss:0.9563429153229442\n",
      "train loss:1.0858590345069163\n",
      "train loss:0.9738272412270983\n",
      "train loss:0.9346584513585131\n",
      "train loss:0.7904535075736975\n",
      "train loss:1.0153143077969404\n",
      "train loss:1.029793762131098\n",
      "train loss:1.0130021448076256\n",
      "train loss:1.05695452167108\n",
      "train loss:1.0722407474407765\n",
      "train loss:0.9508645049666101\n",
      "train loss:1.0620030411756003\n",
      "train loss:0.8311860455679111\n",
      "train loss:0.9457731086540396\n",
      "train loss:0.7516722220228744\n",
      "train loss:0.9521719912767908\n",
      "train loss:1.084007848185401\n",
      "train loss:0.9464848596180583\n",
      "train loss:1.035736552100158\n",
      "train loss:0.9780782561363204\n",
      "train loss:1.0626196628317102\n",
      "train loss:0.8635107436166153\n",
      "train loss:0.7919586711611666\n",
      "train loss:0.9767747525787637\n",
      "train loss:1.1631912869325933\n",
      "train loss:0.7400378689694962\n",
      "train loss:1.0258646683292134\n",
      "train loss:1.0429239277926983\n",
      "train loss:1.1467838268317891\n",
      "train loss:0.9310191333911985\n",
      "train loss:1.1499047036672456\n",
      "train loss:0.8778465365478594\n",
      "train loss:1.0913480368445942\n",
      "train loss:1.1309775813539042\n",
      "train loss:1.0105725367012324\n",
      "train loss:1.036092235121051\n",
      "train loss:1.0450655315062793\n",
      "train loss:0.9450405216712199\n",
      "train loss:0.9448250269573495\n",
      "train loss:1.1650659062457196\n",
      "train loss:0.8984062038231169\n",
      "train loss:0.8838426086056791\n",
      "=== epoch:9, train acc:0.979, test acc:0.984 ===\n",
      "train loss:1.1132494464470108\n",
      "train loss:1.0349063990716834\n",
      "train loss:0.8797729328327486\n",
      "train loss:0.8270254934495713\n",
      "train loss:0.9416461074331459\n",
      "train loss:1.0042139449862832\n",
      "train loss:0.9072803119120124\n",
      "train loss:0.9728829734666468\n",
      "train loss:0.9267876594670222\n",
      "train loss:0.9107812229417723\n",
      "train loss:1.2083455058088555\n",
      "train loss:0.8778499817813823\n",
      "train loss:1.1479596803948748\n",
      "train loss:1.1105904353259575\n",
      "train loss:1.1404760989131395\n",
      "train loss:0.8802400284088263\n",
      "train loss:0.8943338884210513\n",
      "train loss:0.8719885194598276\n",
      "train loss:0.9591225274342621\n",
      "train loss:1.1285185281898749\n",
      "train loss:0.830326819326659\n",
      "train loss:1.157165165356056\n",
      "train loss:0.9526783556615195\n",
      "train loss:1.0030227596830819\n",
      "train loss:0.9004393910014215\n",
      "train loss:0.8116256988426972\n",
      "train loss:1.0284184695492855\n",
      "train loss:1.1084664059411415\n",
      "train loss:1.11628711003737\n",
      "train loss:1.04535018984229\n",
      "train loss:1.083840304726745\n",
      "train loss:0.9401831275210293\n",
      "train loss:1.011562510780262\n",
      "train loss:1.100612244294739\n",
      "train loss:0.8768475125892934\n",
      "train loss:0.9000978450124438\n",
      "train loss:1.049793325754529\n",
      "train loss:0.9970401110832526\n",
      "train loss:0.8417012877736479\n",
      "train loss:0.9591673302339544\n",
      "train loss:1.1470794805182045\n",
      "train loss:1.000818848332346\n",
      "train loss:1.024428133761701\n",
      "train loss:0.9059100362914638\n",
      "train loss:0.9412752552707374\n",
      "train loss:0.8845376156013708\n",
      "train loss:0.9131988063496398\n",
      "train loss:0.9536793765920041\n",
      "train loss:1.070935464227604\n",
      "train loss:0.9899863848749019\n",
      "train loss:0.9169471733084954\n",
      "train loss:0.9801643456840491\n",
      "train loss:0.8405828923424933\n",
      "train loss:1.0325391000723072\n",
      "train loss:1.0692123823539563\n",
      "train loss:0.9071215445259658\n",
      "train loss:0.8727094081624585\n",
      "train loss:0.8250292567893338\n",
      "train loss:1.0051244354908333\n",
      "train loss:1.0645864427100016\n",
      "train loss:0.9833750641024332\n",
      "train loss:0.9586070426292782\n",
      "train loss:0.7898406629447566\n",
      "train loss:0.8897528722201602\n",
      "train loss:0.9602279731622505\n",
      "train loss:0.9150289784960041\n",
      "train loss:0.892072416037014\n",
      "train loss:1.0807465973598849\n",
      "train loss:0.9485042225747445\n",
      "train loss:0.9676897640353873\n",
      "train loss:1.0327839554819327\n",
      "train loss:1.0095879832646866\n",
      "train loss:1.0576597561464853\n",
      "train loss:0.9848831205857868\n",
      "train loss:0.9931311127560963\n",
      "train loss:0.806696267527505\n",
      "train loss:0.8333465745285394\n",
      "train loss:1.0392310900238209\n",
      "train loss:0.8258006958810055\n",
      "train loss:0.96294766754243\n",
      "train loss:1.0862255759594148\n",
      "train loss:1.0293751363739894\n",
      "train loss:1.0406971002397538\n",
      "train loss:0.9200556674578289\n",
      "train loss:1.1230698137906883\n",
      "train loss:1.0479199952106557\n",
      "train loss:1.0715755963245217\n",
      "train loss:0.9543433488520431\n",
      "train loss:0.9584834186287623\n",
      "train loss:1.0468127149309638\n",
      "train loss:0.9494642939640734\n",
      "train loss:0.9478782380795746\n",
      "train loss:0.9773977550912245\n",
      "train loss:0.9903165472845097\n",
      "train loss:1.126873872896763\n",
      "train loss:1.1136960872360984\n",
      "train loss:1.0398286975296378\n",
      "train loss:1.0522200034177847\n",
      "train loss:1.1735885226956284\n",
      "train loss:1.0346691279531617\n",
      "train loss:1.0152514605657021\n",
      "train loss:0.9560628391164776\n",
      "train loss:1.0732790322685386\n",
      "train loss:0.7719527939094641\n",
      "train loss:0.9757328471690886\n",
      "train loss:1.0321429501565271\n",
      "train loss:1.0288453474194532\n",
      "train loss:0.8902770933690792\n",
      "train loss:0.7303590413845332\n",
      "train loss:1.1029670560472347\n",
      "train loss:0.9256402726997883\n",
      "train loss:0.976522870388742\n",
      "train loss:0.9547103208421747\n",
      "train loss:0.9858308672109086\n",
      "train loss:0.9250740044134225\n",
      "train loss:0.9293938205892123\n",
      "train loss:1.1377908515855735\n",
      "train loss:0.965800508077765\n",
      "train loss:0.9192709602947257\n",
      "train loss:1.0027296598005195\n",
      "train loss:0.884961461343075\n",
      "train loss:0.9699660310568331\n",
      "train loss:1.1289354088975374\n",
      "train loss:0.9637814820370284\n",
      "train loss:0.7384824654486006\n",
      "train loss:1.1116565979995727\n",
      "train loss:0.9875956023193413\n",
      "train loss:0.9399521266430645\n",
      "train loss:0.8052519633122209\n",
      "train loss:1.1025665124776467\n",
      "train loss:0.756875589441553\n",
      "train loss:1.0815543075524474\n",
      "train loss:1.0273241849676058\n",
      "train loss:1.1272338730115221\n",
      "train loss:0.80546788063324\n",
      "train loss:0.7571018684623493\n",
      "train loss:1.2504747930250242\n",
      "train loss:0.8536444748068972\n",
      "train loss:0.8403903407195866\n",
      "train loss:1.0069090028422627\n",
      "train loss:0.727275934707098\n",
      "train loss:0.8113864366134517\n",
      "train loss:1.0609853843207326\n",
      "train loss:1.0670852001068825\n",
      "train loss:1.0034817691112143\n",
      "train loss:0.9292967134887071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8947551397938156\n",
      "train loss:0.8996192107709777\n",
      "train loss:0.9582231552826785\n",
      "train loss:0.9130058658308432\n",
      "train loss:0.8434281983909068\n",
      "train loss:1.0064105289937135\n",
      "train loss:1.0097461344251455\n",
      "train loss:0.9103035317104157\n",
      "train loss:0.891990260283515\n",
      "train loss:1.0195526584980243\n",
      "train loss:0.860452567457557\n",
      "train loss:0.9320191802493362\n",
      "train loss:0.97524407267286\n",
      "train loss:0.9213046918754613\n",
      "train loss:0.8435155374403669\n",
      "train loss:1.0196393817301517\n",
      "train loss:0.8898590998516603\n",
      "train loss:0.9494717137792125\n",
      "train loss:0.9526562009921904\n",
      "train loss:0.9229424083659319\n",
      "train loss:1.0141206862039582\n",
      "train loss:1.043130223099669\n",
      "train loss:1.0161624032257237\n",
      "train loss:0.9297182867128876\n",
      "train loss:1.0827759903778422\n",
      "train loss:0.9560756083403605\n",
      "train loss:1.08159836034594\n",
      "train loss:1.030525983192079\n",
      "train loss:0.9796084459921072\n",
      "train loss:0.9117522672744403\n",
      "train loss:1.0758089812551355\n",
      "train loss:0.8276442495236448\n",
      "train loss:0.939201805903598\n",
      "train loss:0.937004063107236\n",
      "train loss:1.1487431265422263\n",
      "train loss:0.9908562192229228\n",
      "train loss:0.8606199358077735\n",
      "train loss:1.0433253865287693\n",
      "train loss:0.9948681499792095\n",
      "train loss:0.9495164547226977\n",
      "train loss:1.2347311180435994\n",
      "train loss:0.9975070867832716\n",
      "train loss:1.014888321983889\n",
      "train loss:0.7931449177928448\n",
      "train loss:0.8146426299481564\n",
      "train loss:1.0489625823830993\n",
      "train loss:1.086013496818772\n",
      "train loss:0.9737340175126589\n",
      "train loss:0.9655807063878664\n",
      "train loss:0.9574171426290421\n",
      "train loss:0.9695659704345009\n",
      "train loss:0.9028026110690022\n",
      "train loss:1.0805425533132398\n",
      "train loss:1.0354450531865766\n",
      "train loss:0.9894125015403509\n",
      "train loss:0.8730149592039118\n",
      "train loss:0.9397187418592101\n",
      "train loss:0.9866658736407109\n",
      "train loss:0.9015324203245825\n",
      "train loss:0.8967285288949995\n",
      "train loss:0.9664952488991619\n",
      "train loss:0.9084075789132853\n",
      "train loss:1.0325564687127273\n",
      "train loss:0.8817209217692111\n",
      "train loss:1.0101779991199382\n",
      "train loss:0.8864654285622957\n",
      "train loss:1.0110697875395613\n",
      "train loss:0.7730590024122859\n",
      "train loss:1.0172534913585844\n",
      "train loss:1.0667228693571706\n",
      "train loss:0.9608187718579819\n",
      "train loss:0.8840154047106122\n",
      "train loss:1.1405919850259771\n",
      "train loss:1.03388140138292\n",
      "train loss:0.8056892272303225\n",
      "train loss:0.9366089566324188\n",
      "train loss:1.0130165161871383\n",
      "train loss:1.0605490886715723\n",
      "train loss:0.886791115130827\n",
      "train loss:0.8888499056624153\n",
      "train loss:1.1831124432454219\n",
      "train loss:1.0053689705430187\n",
      "train loss:0.9872143506358074\n",
      "train loss:0.898822125008742\n",
      "train loss:0.8373177441592868\n",
      "train loss:1.033416719023268\n",
      "train loss:0.916806841743091\n",
      "train loss:0.9466272714262333\n",
      "train loss:0.8937612341007951\n",
      "train loss:0.9851296828104446\n",
      "train loss:0.8258874846154945\n",
      "train loss:0.9396696501303603\n",
      "train loss:0.8504091156361165\n",
      "train loss:0.823525561153285\n",
      "train loss:0.9263796559150117\n",
      "train loss:1.0157561287382066\n",
      "train loss:1.032154438443487\n",
      "train loss:0.6083130345138784\n",
      "train loss:0.9737723319530538\n",
      "train loss:0.957561207216274\n",
      "train loss:0.9419799647608332\n",
      "train loss:0.8962522640376115\n",
      "train loss:1.052824741285794\n",
      "train loss:0.9281176816635552\n",
      "train loss:0.9994174469531351\n",
      "train loss:0.9945087647807505\n",
      "train loss:0.962004058713888\n",
      "train loss:1.0014015775210212\n",
      "train loss:0.845998079365976\n",
      "train loss:0.9819393365177137\n",
      "train loss:0.990735648457951\n",
      "train loss:1.1243284193467447\n",
      "train loss:1.1227148091933368\n",
      "train loss:1.0281143989816348\n",
      "train loss:1.027151119206208\n",
      "train loss:0.9499766509711833\n",
      "train loss:0.9852352647737763\n",
      "train loss:0.9242963026322398\n",
      "train loss:0.9897434847311938\n",
      "train loss:0.9206814382327154\n",
      "train loss:0.7834777873946887\n",
      "train loss:0.9210931500541412\n",
      "train loss:0.8659663688164553\n",
      "train loss:0.9095495958990801\n",
      "train loss:0.9561395643917731\n",
      "train loss:1.0264171341836548\n",
      "train loss:1.0013687949544576\n",
      "train loss:0.9927492832739339\n",
      "train loss:0.8914204631388725\n",
      "train loss:0.9747527760089794\n",
      "train loss:1.0172134515931108\n",
      "train loss:0.9224037677293695\n",
      "train loss:0.8931193558725745\n",
      "train loss:0.8466601012636965\n",
      "train loss:0.9517888590598023\n",
      "train loss:0.9959177142042113\n",
      "train loss:0.9536770636654179\n",
      "train loss:0.9008787659565242\n",
      "train loss:0.9828899502990676\n",
      "train loss:1.0509841100071755\n",
      "train loss:0.9045761531327803\n",
      "train loss:0.9577477379585221\n",
      "train loss:0.7657936208744383\n",
      "train loss:0.8826510590858603\n",
      "train loss:1.007415513157246\n",
      "train loss:0.7959575926291451\n",
      "train loss:1.1586061096868379\n",
      "train loss:0.9689808151045117\n",
      "train loss:0.8983558207809991\n",
      "train loss:0.8453586628397809\n",
      "train loss:0.9862191331569389\n",
      "train loss:1.1058104085275378\n",
      "train loss:0.7364669581001826\n",
      "train loss:0.920420388989074\n",
      "train loss:0.8484996421660779\n",
      "train loss:1.0039409960133114\n",
      "train loss:1.0065461126759423\n",
      "train loss:1.0444949609535168\n",
      "train loss:0.9740825358263383\n",
      "train loss:0.795337152449397\n",
      "train loss:0.9965394297164377\n",
      "train loss:0.8301528432151017\n",
      "train loss:0.9074123944732022\n",
      "train loss:1.0644093157915868\n",
      "train loss:0.9310679661943554\n",
      "train loss:0.8733533669424659\n",
      "train loss:0.7538202285404939\n",
      "train loss:0.9012592795595497\n",
      "train loss:0.9597386262002113\n",
      "train loss:0.9209638424023795\n",
      "train loss:0.9120036327573874\n",
      "train loss:0.9802089013196472\n",
      "train loss:0.9791992223428622\n",
      "train loss:1.1450878811035963\n",
      "train loss:1.0541038418700879\n",
      "train loss:1.0123012250823848\n",
      "train loss:1.0291256125422357\n",
      "train loss:0.8944959857270711\n",
      "train loss:0.9386066537025479\n",
      "train loss:0.8319522590072311\n",
      "train loss:0.8585041955949302\n",
      "train loss:1.081915931049756\n",
      "train loss:0.9059540416853424\n",
      "train loss:0.864313005743821\n",
      "train loss:0.9246227932309964\n",
      "train loss:0.9596623548985365\n",
      "train loss:0.9560156203462666\n",
      "train loss:1.0513190298901638\n",
      "train loss:0.8181680604258316\n",
      "train loss:1.050905513184977\n",
      "train loss:0.9658906037137417\n",
      "train loss:1.0226629715879911\n",
      "train loss:0.9291322332926866\n",
      "train loss:0.9350699755453528\n",
      "train loss:0.9938584417622519\n",
      "train loss:0.8003300230982698\n",
      "train loss:0.7959885470426328\n",
      "train loss:0.8917207032590229\n",
      "train loss:0.9318316492447001\n",
      "train loss:0.9583616472319716\n",
      "train loss:0.9366337598612023\n",
      "train loss:0.9456068054092017\n",
      "train loss:0.9548111752126913\n",
      "train loss:0.8348738893147586\n",
      "train loss:1.0087140290648728\n",
      "train loss:0.9733955415065774\n",
      "train loss:1.0470102617099069\n",
      "train loss:1.001694664640891\n",
      "train loss:1.064285168405657\n",
      "train loss:0.8269051654787581\n",
      "train loss:0.8635880990994856\n",
      "train loss:1.02489042306747\n",
      "train loss:0.916238817919774\n",
      "train loss:1.004595239152481\n",
      "train loss:0.8747878705318264\n",
      "train loss:1.0762714456788276\n",
      "train loss:1.0202734278142322\n",
      "train loss:1.127594494023287\n",
      "train loss:0.9738092815033891\n",
      "train loss:1.064406002087985\n",
      "train loss:1.0315567083595798\n",
      "train loss:1.052984250300093\n",
      "train loss:0.9585560517180614\n",
      "train loss:1.073733584667375\n",
      "train loss:0.9833965920350376\n",
      "train loss:0.9116561119155064\n",
      "train loss:0.6294102610373361\n",
      "train loss:0.8951596992074242\n",
      "train loss:1.0534959602712695\n",
      "train loss:1.0674382367090418\n",
      "train loss:1.0211683770976727\n",
      "train loss:0.8632354711031408\n",
      "train loss:0.9601312789548043\n",
      "train loss:0.997967124679575\n",
      "train loss:0.9551223671221517\n",
      "train loss:0.8283968122516047\n",
      "train loss:1.0415669052609589\n",
      "train loss:1.1911623758323064\n",
      "train loss:1.0029489679636505\n",
      "train loss:0.9709534338589674\n",
      "train loss:1.1504732347703062\n",
      "train loss:0.9972051651884954\n",
      "train loss:0.8461720624555134\n",
      "train loss:0.899312275591146\n",
      "train loss:0.9900139071717988\n",
      "train loss:0.97357875624727\n",
      "train loss:0.7633556684486293\n",
      "train loss:0.9164332313261572\n",
      "train loss:1.0700772991465177\n",
      "train loss:1.0969422655218224\n",
      "train loss:0.9041724734650752\n",
      "train loss:0.8793495186528439\n",
      "train loss:0.8022818822672027\n",
      "train loss:0.9526100116782577\n",
      "train loss:0.7293799239178592\n",
      "train loss:0.8792829630460123\n",
      "train loss:0.9643672098209342\n",
      "train loss:1.0180729132741875\n",
      "train loss:1.0771406734613749\n",
      "train loss:0.9250610937318114\n",
      "train loss:1.1884279305652787\n",
      "train loss:0.9495296627583418\n",
      "train loss:0.9308474300052515\n",
      "train loss:0.9697810690174115\n",
      "train loss:0.9264491125224051\n",
      "train loss:0.8182391163455442\n",
      "train loss:0.9268519413672057\n",
      "train loss:1.121247928070141\n",
      "train loss:1.046070702998437\n",
      "train loss:0.984709608642899\n",
      "train loss:1.1066214273512898\n",
      "train loss:0.9716421590824331\n",
      "train loss:1.0691209295484658\n",
      "train loss:1.1032057094126595\n",
      "train loss:0.9551049959987787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.945068968808996\n",
      "train loss:0.9773496364598896\n",
      "train loss:0.7938205199836014\n",
      "train loss:1.023788616025527\n",
      "train loss:0.9258526393310396\n",
      "train loss:0.9092404328016095\n",
      "train loss:0.9311610945150318\n",
      "train loss:0.9120373515583844\n",
      "train loss:0.9011123743061402\n",
      "train loss:1.0614871273464268\n",
      "train loss:1.0415679692747404\n",
      "train loss:1.0416052315719833\n",
      "train loss:1.0735786691710008\n",
      "train loss:1.101400077494328\n",
      "train loss:1.1143432680887233\n",
      "train loss:0.9606822620327226\n",
      "train loss:0.9835638643169301\n",
      "train loss:0.9054068502541104\n",
      "train loss:0.9805690030182944\n",
      "train loss:0.9613121245535542\n",
      "train loss:0.9934872421403034\n",
      "train loss:0.9075876720681131\n",
      "train loss:1.0694550917626773\n",
      "train loss:1.0146522308283774\n",
      "train loss:0.8809626324488995\n",
      "train loss:0.7940648531277248\n",
      "train loss:0.9362453027291668\n",
      "train loss:1.0092193640000182\n",
      "train loss:0.9276934159622203\n",
      "train loss:1.0443923112557976\n",
      "train loss:0.9907303208110111\n",
      "train loss:0.8635598003736635\n",
      "train loss:0.8344377804897789\n",
      "train loss:0.8575378989988294\n",
      "train loss:1.0394745326450134\n",
      "train loss:0.982843114026753\n",
      "train loss:0.8428267417729016\n",
      "train loss:0.9527650399543732\n",
      "train loss:0.884784958319688\n",
      "train loss:0.922226202303396\n",
      "train loss:0.9470487739475186\n",
      "train loss:0.7984233317430797\n",
      "train loss:1.047724255060625\n",
      "train loss:0.9147995689101436\n",
      "train loss:0.9689710219629651\n",
      "train loss:0.7846592278316582\n",
      "train loss:0.9068709315435055\n",
      "train loss:0.954099795903598\n",
      "train loss:1.009787366407097\n",
      "train loss:0.9167318705672117\n",
      "train loss:0.8814474521131512\n",
      "train loss:1.0689075528661895\n",
      "train loss:0.9466168173826969\n",
      "train loss:0.9970009304054003\n",
      "train loss:0.8668426636899934\n",
      "train loss:0.9607333162498161\n",
      "train loss:0.9037861176273695\n",
      "train loss:0.9435062671999652\n",
      "train loss:0.9293069861607577\n",
      "train loss:1.0864161646220254\n",
      "train loss:0.9498855082503787\n",
      "train loss:0.9896994936545401\n",
      "train loss:0.9366798624292507\n",
      "train loss:0.9205261715016162\n",
      "train loss:0.865925549944227\n",
      "train loss:1.0003505611397763\n",
      "train loss:1.092068046252005\n",
      "train loss:0.8579292537330829\n",
      "train loss:1.0193315215589258\n",
      "train loss:0.9865754123255183\n",
      "train loss:0.9795624610047511\n",
      "train loss:1.069650983614691\n",
      "train loss:0.8295211299014646\n",
      "train loss:0.9305587222637657\n",
      "train loss:0.9227021655974919\n",
      "train loss:0.8009734297712394\n",
      "train loss:0.996105994231499\n",
      "train loss:1.0446709852629406\n",
      "train loss:1.009272786799985\n",
      "train loss:0.8853051072087365\n",
      "train loss:0.9550384772843863\n",
      "train loss:1.0065969929456866\n",
      "train loss:1.0626144677282523\n",
      "train loss:0.9617365916938261\n",
      "train loss:1.0110694408823389\n",
      "train loss:0.942453177173347\n",
      "train loss:0.809823487876852\n",
      "train loss:0.9741524408340667\n",
      "train loss:0.8886654835778903\n",
      "train loss:1.0457909973297503\n",
      "train loss:1.0209124328442238\n",
      "train loss:0.9955025083387068\n",
      "train loss:0.9994661532623438\n",
      "train loss:0.9533185775728361\n",
      "train loss:1.0167924735700498\n",
      "train loss:0.9505958583046408\n",
      "train loss:0.9190464686139808\n",
      "train loss:0.7738898750122276\n",
      "train loss:1.0445927263507935\n",
      "train loss:1.0729664769125489\n",
      "train loss:0.9383046027267578\n",
      "train loss:0.9704222250032647\n",
      "train loss:0.999062372640922\n",
      "train loss:0.8494505369561745\n",
      "train loss:0.8843664898678091\n",
      "train loss:1.0149868926965584\n",
      "train loss:0.7436232630472426\n",
      "train loss:1.1106079999257341\n",
      "train loss:0.9175782031717624\n",
      "train loss:0.951405369106231\n",
      "train loss:1.0393955426375987\n",
      "train loss:1.0223204826380816\n",
      "train loss:0.9729830294680655\n",
      "train loss:0.9720327690512666\n",
      "train loss:0.944602180830561\n",
      "train loss:0.8966448655018899\n",
      "train loss:1.0100451813666114\n",
      "train loss:0.921538681528872\n",
      "train loss:0.9413792121150977\n",
      "train loss:1.0289548857749151\n",
      "train loss:1.047685346916986\n",
      "train loss:0.9499840195430904\n",
      "train loss:1.0668792485378171\n",
      "train loss:0.9429566816927707\n",
      "train loss:1.0459756702811858\n",
      "train loss:1.1070478546920046\n",
      "train loss:1.0352445657884557\n",
      "train loss:0.869623418362777\n",
      "train loss:1.0010521746106915\n",
      "train loss:1.076191094470004\n",
      "train loss:1.0249278267151092\n",
      "train loss:0.9704572375977579\n",
      "train loss:0.9914933517938028\n",
      "train loss:1.0831345274552195\n",
      "train loss:0.7982345389790534\n",
      "train loss:0.8875912287793528\n",
      "train loss:0.9888963924865447\n",
      "train loss:0.9558525320616124\n",
      "train loss:1.106602838303865\n",
      "train loss:1.0939794110988925\n",
      "train loss:0.801593692746994\n",
      "train loss:0.9100816101877005\n",
      "train loss:0.88782162561726\n",
      "train loss:0.9059924397587957\n",
      "train loss:0.8960244868257802\n",
      "train loss:0.9393742216914857\n",
      "train loss:1.0067884567532195\n",
      "train loss:0.9970989060808911\n",
      "train loss:0.972484128280536\n",
      "train loss:0.9463599047491696\n",
      "train loss:1.0480106596851155\n",
      "train loss:0.8374561686306182\n",
      "train loss:1.0428116488991195\n",
      "train loss:1.0493662984143506\n",
      "train loss:1.0282280004285425\n",
      "train loss:0.8445904116675473\n",
      "train loss:0.985203641965124\n",
      "train loss:1.0174115928964673\n",
      "train loss:1.1007524295806597\n",
      "train loss:1.123244182554957\n",
      "train loss:0.9641288692244272\n",
      "train loss:0.84592961227975\n",
      "train loss:1.123630422453528\n",
      "train loss:0.851562402151124\n",
      "train loss:0.9356025610502544\n",
      "train loss:0.8885312018785421\n",
      "train loss:0.8504466435788445\n",
      "train loss:0.9490150613079226\n",
      "train loss:0.9798054426501858\n",
      "train loss:0.8457461692671557\n",
      "train loss:0.9280831570319826\n",
      "train loss:1.0726836733422755\n",
      "train loss:0.9849353464793699\n",
      "train loss:1.0047703271371402\n",
      "train loss:0.8916017661853266\n",
      "train loss:0.9207262293558399\n",
      "train loss:1.047240020364848\n",
      "train loss:0.8785129676585538\n",
      "train loss:1.0239711787706587\n",
      "=== epoch:10, train acc:0.986, test acc:0.987 ===\n",
      "train loss:0.8842990876227569\n",
      "train loss:0.925843289245334\n",
      "train loss:1.0241450117385071\n",
      "train loss:0.8837230321601389\n",
      "train loss:0.895905292525055\n",
      "train loss:0.7721022687221183\n",
      "train loss:0.8317587875216508\n",
      "train loss:0.9088857933636258\n",
      "train loss:0.9408173176278599\n",
      "train loss:0.9505249192107124\n",
      "train loss:1.1200266549318196\n",
      "train loss:0.7920089171366126\n",
      "train loss:1.1087407105586176\n",
      "train loss:0.9213829612522063\n",
      "train loss:0.8307748276291506\n",
      "train loss:1.0201134386969204\n",
      "train loss:1.368178954630288\n",
      "train loss:1.088683736794472\n",
      "train loss:0.856188936598123\n",
      "train loss:0.9403982884368195\n",
      "train loss:0.9439396987497973\n",
      "train loss:0.8679492999465606\n",
      "train loss:1.1112321123785203\n",
      "train loss:0.8933873657480906\n",
      "train loss:0.8909690029570991\n",
      "train loss:1.033487448017619\n",
      "train loss:0.9593709915548244\n",
      "train loss:0.9289164797449969\n",
      "train loss:1.010213956361524\n",
      "train loss:0.9382149684109617\n",
      "train loss:1.0094099533369327\n",
      "train loss:0.9878896198652701\n",
      "train loss:0.9849721294309987\n",
      "train loss:0.9258666345780208\n",
      "train loss:1.0807191597604136\n",
      "train loss:1.1231457339694169\n",
      "train loss:1.2550387838598243\n",
      "train loss:1.1045159421132023\n",
      "train loss:0.8928026773510231\n",
      "train loss:0.9379869841908325\n",
      "train loss:0.9888438307787604\n",
      "train loss:0.8345302770390265\n",
      "train loss:0.9737763849378537\n",
      "train loss:1.0278763936230042\n",
      "train loss:0.9543316841574534\n",
      "train loss:0.8334981328602317\n",
      "train loss:0.828077782524716\n",
      "train loss:0.8712560415130095\n",
      "train loss:0.7803764940013181\n",
      "train loss:1.0478080143764006\n",
      "train loss:0.9146674972117543\n",
      "train loss:0.8603994731691909\n",
      "train loss:1.0929308936418871\n",
      "train loss:1.0232844694805638\n",
      "train loss:1.0488768160400672\n",
      "train loss:0.9186076356626818\n",
      "train loss:1.0152140904528075\n",
      "train loss:1.1651669222548886\n",
      "train loss:0.9139541320719096\n",
      "train loss:0.9985102453421288\n",
      "train loss:0.8450404409409602\n",
      "train loss:0.9046134696573147\n",
      "train loss:1.2009298036766385\n",
      "train loss:0.8478434812025096\n",
      "train loss:0.9103411651904244\n",
      "train loss:0.8930770792644457\n",
      "train loss:0.9893911319144055\n",
      "train loss:0.887504835225484\n",
      "train loss:0.8993979311162225\n",
      "train loss:0.9907498231748945\n",
      "train loss:0.8519084772331166\n",
      "train loss:0.934379858987628\n",
      "train loss:0.9242733200789154\n",
      "train loss:1.0435704005415625\n",
      "train loss:0.9330970001049935\n",
      "train loss:0.9554803894359776\n",
      "train loss:1.0019619207758779\n",
      "train loss:0.9595943140525133\n",
      "train loss:1.0812900803534915\n",
      "train loss:0.9494319696382872\n",
      "train loss:0.8958557336031577\n",
      "train loss:0.8955700260220616\n",
      "train loss:1.0347129082965374\n",
      "train loss:1.0051282406011894\n",
      "train loss:0.9947202038140064\n",
      "train loss:1.0289349508338028\n",
      "train loss:1.0093889502150437\n",
      "train loss:0.9541174951693364\n",
      "train loss:0.9580673356681879\n",
      "train loss:1.0764963175384266\n",
      "train loss:0.8883844104966532\n",
      "train loss:0.7787177242842693\n",
      "train loss:1.022288362106417\n",
      "train loss:0.9595307644807416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.0011436906265045\n",
      "train loss:1.0727980216068058\n",
      "train loss:0.9270237482687921\n",
      "train loss:0.9583493734683829\n",
      "train loss:0.8848785493049607\n",
      "train loss:0.8989742620132448\n",
      "train loss:0.7484782736807729\n",
      "train loss:1.0084243376408268\n",
      "train loss:1.0273799698567987\n",
      "train loss:1.0406093607998907\n",
      "train loss:1.0766099287902002\n",
      "train loss:0.8820466870117474\n",
      "train loss:0.9674805235072285\n",
      "train loss:0.8937445045305016\n",
      "train loss:0.9831690052270843\n",
      "train loss:1.0379425468661787\n",
      "train loss:0.8789784908414415\n",
      "train loss:1.0592220824487555\n",
      "train loss:1.1029660712072558\n",
      "train loss:0.8484806220819753\n",
      "train loss:0.8214946398254392\n",
      "train loss:0.9640880303493019\n",
      "train loss:1.0399389281162736\n",
      "train loss:0.8177191144768828\n",
      "train loss:0.8819825402889095\n",
      "train loss:0.9317663162166819\n",
      "train loss:1.0844123992540262\n",
      "train loss:0.8281218763038695\n",
      "train loss:0.8536459673250306\n",
      "train loss:1.050588953725508\n",
      "train loss:0.8542634005943216\n",
      "train loss:0.7735796896824574\n",
      "train loss:0.9448221665580232\n",
      "train loss:0.8483133098263171\n",
      "train loss:1.073015046025331\n",
      "train loss:0.8462294683733776\n",
      "train loss:1.2363790491498454\n",
      "train loss:0.9752560263891782\n",
      "train loss:0.9177325467518972\n",
      "train loss:0.9942517487532606\n",
      "train loss:0.9649193330466533\n",
      "train loss:0.8817883085411051\n",
      "train loss:0.9858142040496557\n",
      "train loss:1.0425402247295035\n",
      "train loss:1.0503892982929295\n",
      "train loss:0.9545661986540422\n",
      "train loss:0.9037155519813631\n",
      "train loss:1.0902870071778994\n",
      "train loss:0.8363199522635028\n",
      "train loss:0.7592081919046002\n",
      "train loss:0.9704808835600102\n",
      "train loss:0.7587269517696963\n",
      "train loss:0.9453505288629205\n",
      "train loss:0.8718914117316746\n",
      "train loss:0.9117899726976387\n",
      "train loss:0.9759294857772214\n",
      "train loss:1.0162168632541635\n",
      "train loss:1.116155341681344\n",
      "train loss:1.016385417444417\n",
      "train loss:0.8677954883114042\n",
      "train loss:0.7678916161947491\n",
      "train loss:0.986746506196914\n",
      "train loss:0.9513062297363861\n",
      "train loss:0.8688699864381298\n",
      "train loss:1.0899644757246258\n",
      "train loss:0.6736862534174002\n",
      "train loss:1.0984344012281957\n",
      "train loss:1.0952653338078233\n",
      "train loss:0.8888020531070692\n",
      "train loss:0.9573682757839188\n",
      "train loss:0.9150473820524424\n",
      "train loss:1.1826316884431547\n",
      "train loss:0.9461325866593726\n",
      "train loss:0.9579865537583246\n",
      "train loss:1.040689326606153\n",
      "train loss:1.0013243804606085\n",
      "train loss:0.9523301171126755\n",
      "train loss:0.8536397734433665\n",
      "train loss:0.9846742558471437\n",
      "train loss:1.0639421233734156\n",
      "train loss:1.1177654069390222\n",
      "train loss:0.888118774027453\n",
      "train loss:0.9447446740609806\n",
      "train loss:1.094067451660981\n",
      "train loss:0.9246328529020359\n",
      "train loss:1.0759149374028254\n",
      "train loss:0.8308108936764033\n",
      "train loss:0.684487377084922\n",
      "train loss:0.9055343016613685\n",
      "train loss:1.0339431416352012\n",
      "train loss:0.9132874603794715\n",
      "train loss:0.8277623183871277\n",
      "train loss:0.9529704517489292\n",
      "train loss:0.939118726550246\n",
      "train loss:0.8703796246544109\n",
      "train loss:0.9496940127979647\n",
      "train loss:0.9706625781373274\n",
      "train loss:1.191089460370393\n",
      "train loss:0.8643979305951826\n",
      "train loss:0.9871611685305741\n",
      "train loss:0.8326668248821733\n",
      "train loss:0.7817708124843488\n",
      "train loss:0.8115018232927085\n",
      "train loss:1.088218443503289\n",
      "train loss:1.1219790818752178\n",
      "train loss:0.8469712464448886\n",
      "train loss:0.9408682854254157\n",
      "train loss:0.8844638484012717\n",
      "train loss:0.8188878146661729\n",
      "train loss:1.0017654711594448\n",
      "train loss:1.0334059333862844\n",
      "train loss:1.1235355312918438\n",
      "train loss:0.929299679871125\n",
      "train loss:1.00872426806157\n",
      "train loss:0.9311637324671821\n",
      "train loss:1.028994849324995\n",
      "train loss:0.8412829835842408\n",
      "train loss:0.9438309075239326\n",
      "train loss:0.8576772683987564\n",
      "train loss:0.9535731608224612\n",
      "train loss:0.9748001511443696\n",
      "train loss:0.7620006509928718\n",
      "train loss:0.8889010353083556\n",
      "train loss:1.0500447503781525\n",
      "train loss:0.8644668684399729\n",
      "train loss:0.9188847576370333\n",
      "train loss:1.0339351294147612\n",
      "train loss:0.9774573001655967\n",
      "train loss:0.8979834040950143\n",
      "train loss:0.8607854808534207\n",
      "train loss:1.0428188151884878\n",
      "train loss:1.0295586288747522\n",
      "train loss:0.9269103876261725\n",
      "train loss:0.8212627861898825\n",
      "train loss:0.970317099380554\n",
      "train loss:0.9718330840097685\n",
      "train loss:1.1677543928648428\n",
      "train loss:0.9917488535203438\n",
      "train loss:0.9611443548382304\n",
      "train loss:0.9271255828261833\n",
      "train loss:0.8349461742156131\n",
      "train loss:1.0105747533695466\n",
      "train loss:1.0150165876328636\n",
      "train loss:0.9065079285527895\n",
      "train loss:0.8190489053507545\n",
      "train loss:0.9186298201813743\n",
      "train loss:0.982496172432619\n",
      "train loss:1.0488211431645296\n",
      "train loss:1.0044906050588842\n",
      "train loss:0.7967861888564353\n",
      "train loss:0.7473019407518987\n",
      "train loss:1.0094318907178108\n",
      "train loss:0.8725392774148052\n",
      "train loss:0.9581034999308607\n",
      "train loss:0.8839599408965465\n",
      "train loss:1.0056205315081501\n",
      "train loss:0.9183270579683038\n",
      "train loss:0.8523676856693696\n",
      "train loss:0.8870210186648225\n",
      "train loss:0.8416024533277481\n",
      "train loss:0.7296753629417176\n",
      "train loss:0.9053782938401536\n",
      "train loss:0.8131208855069783\n",
      "train loss:1.0554917126869159\n",
      "train loss:0.9920957011385378\n",
      "train loss:0.9892798947683152\n",
      "train loss:0.9742903014763642\n",
      "train loss:1.012044659370286\n",
      "train loss:0.9754404959937578\n",
      "train loss:0.9043325454435487\n",
      "train loss:1.032767148063519\n",
      "train loss:0.9619139799208911\n",
      "train loss:0.9131612059915524\n",
      "train loss:0.8173571012436176\n",
      "train loss:0.7719418666522097\n",
      "train loss:1.2027956738995729\n",
      "train loss:0.8688889617032938\n",
      "train loss:0.89783977782292\n",
      "train loss:0.9901012229631431\n",
      "train loss:1.0461511536606969\n",
      "train loss:0.9618902447673153\n",
      "train loss:1.0149964842761252\n",
      "train loss:0.940259220790616\n",
      "train loss:0.8868872538596133\n",
      "train loss:1.0524851257926224\n",
      "train loss:0.9779292594056593\n",
      "train loss:1.0182461949127875\n",
      "train loss:1.0185928760095622\n",
      "train loss:0.8954395233107535\n",
      "train loss:1.029505216880589\n",
      "train loss:0.9616203792271679\n",
      "train loss:1.0562727104913696\n",
      "train loss:0.9095503151151391\n",
      "train loss:0.8890190473220305\n",
      "train loss:1.0450799209031323\n",
      "train loss:0.8236512943415529\n",
      "train loss:0.9434629279547748\n",
      "train loss:1.1741845312807209\n",
      "train loss:0.7071947174257022\n",
      "train loss:1.1302882918303296\n",
      "train loss:1.1727891489583484\n",
      "train loss:0.9459364709318361\n",
      "train loss:0.6796573885506407\n",
      "train loss:0.9374025789100271\n",
      "train loss:1.161539073291289\n",
      "train loss:0.7441966538064577\n",
      "train loss:0.9507276262494454\n",
      "train loss:1.0829896837832071\n",
      "train loss:0.9467506170997844\n",
      "train loss:0.9363448960337102\n",
      "train loss:0.910114359932449\n",
      "train loss:1.2799253798888446\n",
      "train loss:0.7574989093130701\n",
      "train loss:1.1721125834800121\n",
      "train loss:1.030491815700889\n",
      "train loss:1.0348324958144755\n",
      "train loss:0.9247970355802184\n",
      "train loss:0.9925263411254922\n",
      "train loss:0.8636766815852949\n",
      "train loss:0.9211054940205108\n",
      "train loss:0.9645395854683837\n",
      "train loss:0.9668976711634546\n",
      "train loss:0.9024382948919062\n",
      "train loss:0.8867076070475778\n",
      "train loss:0.8339322409573184\n",
      "train loss:1.0444691798931125\n",
      "train loss:0.9025279579779852\n",
      "train loss:0.8963558339100627\n",
      "train loss:0.9262968812044279\n",
      "train loss:0.8174971672443132\n",
      "train loss:1.010904076633728\n",
      "train loss:0.9157719200631963\n",
      "train loss:0.8414815262646885\n",
      "train loss:0.959837626911683\n",
      "train loss:0.9484994480842626\n",
      "train loss:1.1319560199976708\n",
      "train loss:1.023934376308832\n",
      "train loss:0.9004456097088948\n",
      "train loss:0.9075680708614692\n",
      "train loss:0.9521238033239493\n",
      "train loss:0.7781257642576427\n",
      "train loss:1.0478236619905632\n",
      "train loss:0.9118724123426977\n",
      "train loss:0.9901203017883385\n",
      "train loss:1.1085354494415909\n",
      "train loss:0.9418604699574818\n",
      "train loss:1.1486073402069403\n",
      "train loss:1.0416720296059854\n",
      "train loss:1.0444572352958075\n",
      "train loss:1.0624482961026327\n",
      "train loss:0.8106750577522233\n",
      "train loss:0.9979262119278602\n",
      "train loss:0.6808796723529569\n",
      "train loss:1.187505931879327\n",
      "train loss:1.0138578405621042\n",
      "train loss:1.049016547161805\n",
      "train loss:0.7876762203827191\n",
      "train loss:1.118753599396717\n",
      "train loss:0.9018234610865825\n",
      "train loss:0.7850381602152663\n",
      "train loss:1.047108731847552\n",
      "train loss:1.1261593488447426\n",
      "train loss:0.9354868596592943\n",
      "train loss:0.8816363906008516\n",
      "train loss:0.7938780284645465\n",
      "train loss:1.1231556912713376\n",
      "train loss:0.884632976742664\n",
      "train loss:0.9700431255177823\n",
      "train loss:0.9189571002412537\n",
      "train loss:0.8973978045171951\n",
      "train loss:0.778460766232042\n",
      "train loss:0.8598251206849116\n",
      "train loss:0.7687635442578472\n",
      "train loss:0.8689106266034046\n",
      "train loss:0.9433894083122131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9518714500715098\n",
      "train loss:0.9382799298128284\n",
      "train loss:0.8671014289352814\n",
      "train loss:0.9420031299120598\n",
      "train loss:0.8538612957031151\n",
      "train loss:1.0160230471787528\n",
      "train loss:0.9507881129800435\n",
      "train loss:1.053986495228618\n",
      "train loss:0.9636236115342293\n",
      "train loss:0.8612136808793386\n",
      "train loss:1.0832655241104738\n",
      "train loss:0.8975374427167594\n",
      "train loss:0.9904745859310818\n",
      "train loss:0.7586583509051931\n",
      "train loss:1.0190586741037593\n",
      "train loss:1.1323138270487796\n",
      "train loss:1.0287018179944605\n",
      "train loss:0.7995232033728266\n",
      "train loss:1.0018887634298037\n",
      "train loss:1.0749718328323785\n",
      "train loss:1.0862859581649915\n",
      "train loss:0.927203953041759\n",
      "train loss:1.0319705817462248\n",
      "train loss:0.8030353050317841\n",
      "train loss:0.920604399270551\n",
      "train loss:0.8566650558019113\n",
      "train loss:0.8868702991555627\n",
      "train loss:0.9061902496495032\n",
      "train loss:1.0003678980670532\n",
      "train loss:0.9092577588530004\n",
      "train loss:0.9722707283152475\n",
      "train loss:0.8190618482491604\n",
      "train loss:0.8315412109538879\n",
      "train loss:0.9713964778643606\n",
      "train loss:1.2932388103865962\n",
      "train loss:0.960913236204072\n",
      "train loss:0.8860167156371115\n",
      "train loss:0.8463149404296084\n",
      "train loss:1.0162691436126874\n",
      "train loss:1.0133478537407685\n",
      "train loss:0.9952287286635656\n",
      "train loss:1.0618022158982467\n",
      "train loss:0.9149394094650166\n",
      "train loss:0.7921565927369342\n",
      "train loss:0.8521286285360142\n",
      "train loss:0.9423340869861216\n",
      "train loss:0.7470649741542559\n",
      "train loss:1.03072623489542\n",
      "train loss:0.8956870058897999\n",
      "train loss:0.8859395351170689\n",
      "train loss:1.0672350912553457\n",
      "train loss:0.7421821543452293\n",
      "train loss:0.8327706634348696\n",
      "train loss:0.8572151140907774\n",
      "train loss:0.8829289560955129\n",
      "train loss:1.1318788188955942\n",
      "train loss:0.9817927221439224\n",
      "train loss:1.0581563250699968\n",
      "train loss:0.7246477641505793\n",
      "train loss:0.8084914934324761\n",
      "train loss:1.01149367232399\n",
      "train loss:1.0269744626917057\n",
      "train loss:0.9297935077698655\n",
      "train loss:0.9067991314094708\n",
      "train loss:1.124563937682885\n",
      "train loss:0.9761378797849217\n",
      "train loss:0.8561560449426981\n",
      "train loss:0.9822329746641526\n",
      "train loss:0.9547648863281925\n",
      "train loss:1.0500361603482287\n",
      "train loss:0.9189127254584186\n",
      "train loss:1.037163967716352\n",
      "train loss:1.04685224150095\n",
      "train loss:0.9512639604234622\n",
      "train loss:0.9508965000942776\n",
      "train loss:0.9521203247355453\n",
      "train loss:0.8353304388924586\n",
      "train loss:1.1049775850432515\n",
      "train loss:0.7807564128366338\n",
      "train loss:0.9436824736308662\n",
      "train loss:0.8696285384040905\n",
      "train loss:1.1697982598086334\n",
      "train loss:1.084339954838632\n",
      "train loss:0.9313754124919444\n",
      "train loss:1.0158389273908535\n",
      "train loss:0.7634899193013176\n",
      "train loss:0.8423366963691297\n",
      "train loss:0.8907774006812074\n",
      "train loss:0.9331573036606877\n",
      "train loss:0.9990291653277885\n",
      "train loss:0.8233386167444648\n",
      "train loss:0.9528705705221242\n",
      "train loss:0.9549539353984682\n",
      "train loss:0.9995260552067201\n",
      "train loss:1.1066216262199244\n",
      "train loss:0.940646830961298\n",
      "train loss:0.8976905046341913\n",
      "train loss:1.0587591947821329\n",
      "train loss:1.119931529804089\n",
      "train loss:0.8836696966295814\n",
      "train loss:0.8919706283924405\n",
      "train loss:1.0162844809224412\n",
      "train loss:1.1657221729289429\n",
      "train loss:1.1489623676365452\n",
      "train loss:0.8559498596928456\n",
      "train loss:1.0167545313899682\n",
      "train loss:1.0150698162165264\n",
      "train loss:0.9256010468415937\n",
      "train loss:0.83479132347723\n",
      "train loss:1.047692173502422\n",
      "train loss:1.0218287045740204\n",
      "train loss:0.8636257122508888\n",
      "train loss:1.0507153782212344\n",
      "train loss:0.8685926896336674\n",
      "train loss:0.8842327475435313\n",
      "train loss:0.951579277547906\n",
      "train loss:0.9047161602713765\n",
      "train loss:1.007280487535216\n",
      "train loss:0.9101767125547829\n",
      "train loss:0.9077152458782384\n",
      "train loss:0.7307830650676129\n",
      "train loss:1.032363563040851\n",
      "train loss:0.8141393800603716\n",
      "train loss:0.8561066578513957\n",
      "train loss:1.2255023401114846\n",
      "train loss:0.9632996912960107\n",
      "train loss:1.0086646701956963\n",
      "train loss:0.9158124930076228\n",
      "train loss:0.9976703342724317\n",
      "train loss:0.9891134510214812\n",
      "train loss:1.0086886861635314\n",
      "train loss:0.9736361346163342\n",
      "train loss:1.0592371524332518\n",
      "train loss:1.029138720104705\n",
      "train loss:0.8643076076087692\n",
      "train loss:0.9863568235728459\n",
      "train loss:0.8766874987356614\n",
      "train loss:1.0136290106386527\n",
      "train loss:0.8863785350576923\n",
      "train loss:1.0847675113212967\n",
      "train loss:0.9923346969024169\n",
      "train loss:0.7500508513201575\n",
      "train loss:1.0248660013379196\n",
      "train loss:0.9978167942277103\n",
      "train loss:0.9693953187691907\n",
      "train loss:0.9253609201439583\n",
      "train loss:1.0112098400951566\n",
      "train loss:0.7946083321998932\n",
      "train loss:0.9932581729457749\n",
      "train loss:0.8929316152306315\n",
      "train loss:0.9438563898387201\n",
      "train loss:1.003669307267856\n",
      "train loss:0.9130404210185319\n",
      "train loss:0.7540846725955384\n",
      "train loss:0.9346343679345404\n",
      "train loss:1.0002514601656252\n",
      "train loss:0.9072646562252931\n",
      "train loss:0.9598262145133154\n",
      "train loss:1.0478364287431912\n",
      "train loss:1.0466369872558838\n",
      "train loss:1.0310682741556547\n",
      "train loss:0.8976030182888058\n",
      "train loss:0.9499559683746318\n",
      "train loss:0.9392073767512764\n",
      "train loss:1.0129195146558214\n",
      "train loss:0.9058692806840226\n",
      "train loss:0.9070622665086228\n",
      "train loss:0.9530115145450061\n",
      "train loss:0.8729719820225529\n",
      "train loss:0.8432926138842867\n",
      "train loss:0.8751896281321794\n",
      "train loss:0.9608220569156609\n",
      "train loss:0.9885952674400397\n",
      "train loss:0.9934774285005251\n",
      "train loss:0.906318853971232\n",
      "train loss:0.8735169277537962\n",
      "train loss:0.9046230597453837\n",
      "train loss:1.0265088335586752\n",
      "train loss:0.9099697323171896\n",
      "train loss:0.9868020784153451\n",
      "train loss:0.8539323969774942\n",
      "train loss:0.7723441108934481\n",
      "train loss:1.204977331282603\n",
      "train loss:0.8107765536100076\n",
      "train loss:1.0213879625308198\n",
      "train loss:0.8377071235414865\n",
      "train loss:0.8995843493880044\n",
      "train loss:0.9828917247749532\n",
      "train loss:0.8973625836622768\n",
      "train loss:1.1199363119571064\n",
      "train loss:0.894572078595178\n",
      "train loss:0.9091468172633168\n",
      "train loss:0.8710397602800432\n",
      "train loss:1.0490969359974456\n",
      "train loss:0.8695475408712074\n",
      "train loss:0.9143164237724392\n",
      "train loss:0.9500814128601509\n",
      "train loss:0.8587726891161429\n",
      "train loss:1.0632303758985207\n",
      "train loss:0.8606817647082164\n",
      "train loss:0.9930025496550844\n",
      "train loss:0.8708694207090224\n",
      "train loss:1.124656914835624\n",
      "train loss:0.784366960964792\n",
      "train loss:1.020048203728592\n",
      "train loss:1.0364133000335432\n",
      "train loss:0.8563372437246063\n",
      "train loss:0.8439965098722465\n",
      "train loss:0.8586167918978181\n",
      "train loss:0.7871814920440973\n",
      "train loss:0.9922814612804143\n",
      "train loss:0.8778638514311713\n",
      "train loss:1.1063717368025807\n",
      "train loss:0.8530120934695304\n",
      "train loss:0.9750615958345259\n",
      "train loss:0.9009469809744362\n",
      "train loss:1.1132216326050215\n",
      "train loss:1.0645724936379517\n",
      "train loss:1.0235061285435827\n",
      "train loss:1.111277812553132\n",
      "train loss:0.8253030724573209\n",
      "train loss:1.0435209152124243\n",
      "train loss:0.9568839073655782\n",
      "train loss:0.9625542152179704\n",
      "train loss:1.0132668644327802\n",
      "train loss:0.9602221602054003\n",
      "train loss:0.8780975996314492\n",
      "train loss:0.8512684809315084\n",
      "train loss:1.0778619121903974\n",
      "train loss:0.8267324344510246\n",
      "train loss:0.8915785779146499\n",
      "=== epoch:11, train acc:0.986, test acc:0.988 ===\n",
      "train loss:0.9311545539562336\n",
      "train loss:1.0040275194201516\n",
      "train loss:1.0115289985174944\n",
      "train loss:0.9556135454037269\n",
      "train loss:0.8974827841825995\n",
      "train loss:0.9256418722832807\n",
      "train loss:0.7735834358363608\n",
      "train loss:1.0476354998044033\n",
      "train loss:0.8513231072333464\n",
      "train loss:1.0742105398688842\n",
      "train loss:0.9438427314975371\n",
      "train loss:0.9245983903612823\n",
      "train loss:0.9843128052239867\n",
      "train loss:0.8533268002513479\n",
      "train loss:0.9887322667191601\n",
      "train loss:0.8648348934536725\n",
      "train loss:0.9992348511665324\n",
      "train loss:1.0471988422433294\n",
      "train loss:0.9919715689968465\n",
      "train loss:0.9332498778901528\n",
      "train loss:0.9339259790553777\n",
      "train loss:0.9687468951723643\n",
      "train loss:0.8867381204307526\n",
      "train loss:1.046454609108706\n",
      "train loss:1.0274696616881807\n",
      "train loss:0.8223439893317651\n",
      "train loss:1.0349206402210578\n",
      "train loss:0.9698447296749917\n",
      "train loss:1.006819310335517\n",
      "train loss:1.0534986828137614\n",
      "train loss:0.9254435198038599\n",
      "train loss:0.9563109598022449\n",
      "train loss:1.0088201658375755\n",
      "train loss:1.0966091357062953\n",
      "train loss:1.0172806348159813\n",
      "train loss:1.0153023541902728\n",
      "train loss:1.143795826899181\n",
      "train loss:0.8977016225743575\n",
      "train loss:0.8765839850013244\n",
      "train loss:0.9016616017952545\n",
      "train loss:0.849982692970394\n",
      "train loss:1.1396952044465336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.0049959269542699\n",
      "train loss:0.9616850872763688\n",
      "train loss:1.056944336747328\n",
      "train loss:0.9096310549622452\n",
      "train loss:1.1044745505898301\n",
      "train loss:0.9843257170806491\n",
      "train loss:1.00872411740441\n",
      "train loss:0.9368634575400842\n",
      "train loss:1.0751924982347507\n",
      "train loss:1.04772414272292\n",
      "train loss:1.0129644828250648\n",
      "train loss:0.7619981220694036\n",
      "train loss:0.9093873066702584\n",
      "train loss:1.220615817962457\n",
      "train loss:1.0500048665505757\n",
      "train loss:1.0473122927617302\n",
      "train loss:1.0420158512681228\n",
      "train loss:0.9340393018343671\n",
      "train loss:0.9718742273063598\n",
      "train loss:0.8788635550361067\n",
      "train loss:0.9630307989511222\n",
      "train loss:0.9224623621121266\n",
      "train loss:0.8544423331156022\n",
      "train loss:0.9238317308278329\n",
      "train loss:0.9970927759527366\n",
      "train loss:1.0481213298844674\n",
      "train loss:0.8940436224280809\n",
      "train loss:0.9379715952151373\n",
      "train loss:0.9477360341303677\n",
      "train loss:0.9431596967099959\n",
      "train loss:0.9608408590885347\n",
      "train loss:0.8219067075982871\n",
      "train loss:1.0365415659028567\n",
      "train loss:0.9614226842463169\n",
      "train loss:0.8752993516413357\n",
      "train loss:0.7830198357972208\n",
      "train loss:0.9752521850132841\n",
      "train loss:0.9902182112141227\n",
      "train loss:1.0871050012639842\n",
      "train loss:0.8445821323862165\n",
      "train loss:0.9363891050595516\n",
      "train loss:0.8907984165695862\n",
      "train loss:0.9479074816660973\n",
      "train loss:0.9492204840418396\n",
      "train loss:0.9009775450963313\n",
      "train loss:1.0741954361344295\n",
      "train loss:0.9625716024139167\n",
      "train loss:0.9558459783741252\n",
      "train loss:0.8574377784559966\n",
      "train loss:1.0930373320723479\n",
      "train loss:0.9739277995322294\n",
      "train loss:0.8884220393040421\n",
      "train loss:0.7726336097963401\n",
      "train loss:0.8920301146812629\n",
      "train loss:0.8953903126140723\n",
      "train loss:0.8091749680173835\n",
      "train loss:1.020978265352241\n",
      "train loss:0.8798489183328253\n",
      "train loss:1.0191518009031038\n",
      "train loss:0.9784759280015395\n",
      "train loss:1.0109616801692527\n",
      "train loss:0.9079220427641919\n",
      "train loss:0.8749626974685778\n",
      "train loss:0.8314618731393132\n",
      "train loss:0.837676989374351\n",
      "train loss:0.9990768289841604\n",
      "train loss:0.9679659847964847\n",
      "train loss:0.9976107476270093\n",
      "train loss:0.8913864734304684\n",
      "train loss:1.0244829143902545\n",
      "train loss:1.0472999367936826\n",
      "train loss:0.8885594027732135\n",
      "train loss:0.8153071537806446\n",
      "train loss:0.9536040122044692\n",
      "train loss:0.9466525509908874\n",
      "train loss:1.0702293910103648\n",
      "train loss:0.8712665614662821\n",
      "train loss:0.9715437239426676\n",
      "train loss:0.9691278884642022\n",
      "train loss:0.9338244675610909\n",
      "train loss:1.0504786016977812\n",
      "train loss:0.8080680743683456\n",
      "train loss:1.0247025989040055\n",
      "train loss:1.0588495070369717\n",
      "train loss:1.0615255186065395\n",
      "train loss:1.0206471368513572\n",
      "train loss:0.9541264808220395\n",
      "train loss:1.0427666953474024\n",
      "train loss:1.0388363380913441\n",
      "train loss:0.9432015290284194\n",
      "train loss:0.9247667236620515\n",
      "train loss:1.004014072199995\n",
      "train loss:0.8856466289710737\n",
      "train loss:0.8973442774114123\n",
      "train loss:1.0683746368491271\n",
      "train loss:1.0757512568388983\n",
      "train loss:0.9218130945088334\n",
      "train loss:0.8998659416379575\n",
      "train loss:0.8308214286030704\n",
      "train loss:0.7292917183758262\n",
      "train loss:0.9456047090871067\n",
      "train loss:1.1005480900481992\n",
      "train loss:0.906355598418435\n",
      "train loss:0.9499716408994737\n",
      "train loss:0.9477506240475649\n",
      "train loss:0.9357019620933178\n",
      "train loss:1.1002640304627755\n",
      "train loss:0.8646751734821762\n",
      "train loss:0.8060400322942263\n",
      "train loss:0.8398725977451704\n",
      "train loss:1.010816640759337\n",
      "train loss:0.9950686490361655\n",
      "train loss:0.8491207578118317\n",
      "train loss:1.0282493056013815\n",
      "train loss:0.9497971528142056\n",
      "train loss:0.9406343693781851\n",
      "train loss:0.8942230217440583\n",
      "train loss:0.8743262681159532\n",
      "train loss:0.8996572581825116\n",
      "train loss:0.8496133028016747\n",
      "train loss:1.0350861508672606\n",
      "train loss:0.8862608923332599\n",
      "train loss:0.9508756068598048\n",
      "train loss:0.8221111880818376\n",
      "train loss:0.9519879126754651\n",
      "train loss:0.8223499324472434\n",
      "train loss:0.7683392573463835\n",
      "train loss:0.922401712820541\n",
      "train loss:0.8384054733096388\n",
      "train loss:1.1814034655658638\n",
      "train loss:1.0190321556787234\n",
      "train loss:0.9070280285961178\n",
      "train loss:0.9329333654301161\n",
      "train loss:1.0303947812997536\n",
      "train loss:0.8117386631164902\n",
      "train loss:1.194447267053132\n",
      "train loss:0.8975584740534285\n",
      "train loss:0.7636109221597607\n",
      "train loss:0.9546835229161078\n",
      "train loss:0.9732611810754231\n",
      "train loss:0.8287222058338852\n",
      "train loss:1.011995714429705\n",
      "train loss:0.9225432827218473\n",
      "train loss:1.14570072603167\n",
      "train loss:1.0458293995497774\n",
      "train loss:0.9884697855966936\n",
      "train loss:0.9356826962602388\n",
      "train loss:0.838162943496711\n",
      "train loss:0.8327263617236951\n",
      "train loss:0.8555859777189534\n",
      "train loss:1.0530410911471775\n",
      "train loss:0.8741425795910829\n",
      "train loss:0.8625628306331069\n",
      "train loss:0.991128457676076\n",
      "train loss:0.9082243035676619\n",
      "train loss:0.9632264582425307\n",
      "train loss:0.8474573386178004\n",
      "train loss:0.7654191138456818\n",
      "train loss:0.8921972962997949\n",
      "train loss:1.0050373574002938\n",
      "train loss:0.9884545476535311\n",
      "train loss:1.0248324032403946\n",
      "train loss:1.0778668713462836\n",
      "train loss:0.9953974708656355\n",
      "train loss:0.7729871165418888\n",
      "train loss:0.865034765344104\n",
      "train loss:1.0838229332289626\n",
      "train loss:0.9549161470912313\n",
      "train loss:0.8597515238655289\n",
      "train loss:0.9767600895940847\n",
      "train loss:1.0769725836653485\n",
      "train loss:0.8467966925501806\n",
      "train loss:0.9615430357942212\n",
      "train loss:0.8899760888872632\n",
      "train loss:1.1509833662468147\n",
      "train loss:0.9925177040668518\n",
      "train loss:0.9513612745401203\n",
      "train loss:0.861446864896066\n",
      "train loss:1.087678194457757\n",
      "train loss:0.818257269848419\n",
      "train loss:0.8864231959564997\n",
      "train loss:1.0092493382408845\n",
      "train loss:1.0273189265058311\n",
      "train loss:0.979673577302367\n",
      "train loss:0.98883697624223\n",
      "train loss:0.9876057890639216\n",
      "train loss:1.0236357409656955\n",
      "train loss:0.9689004629903388\n",
      "train loss:1.04533671111265\n",
      "train loss:1.0534701364091532\n",
      "train loss:0.8898538664069414\n",
      "train loss:0.9969010617318701\n",
      "train loss:0.8373065212472433\n",
      "train loss:0.958410883811487\n",
      "train loss:0.875263515833109\n",
      "train loss:0.9236356222752606\n",
      "train loss:1.0900561298052778\n",
      "train loss:0.8959566418380873\n",
      "train loss:0.9837110196453058\n",
      "train loss:0.9361228502664818\n",
      "train loss:0.8331310289413006\n",
      "train loss:0.894290707072603\n",
      "train loss:1.0888966953274806\n",
      "train loss:1.0609003315807082\n",
      "train loss:0.7982441625704207\n",
      "train loss:1.1454932379259823\n",
      "train loss:0.9818757903839045\n",
      "train loss:1.252675847145679\n",
      "train loss:1.0597756464436143\n",
      "train loss:1.0105918381495598\n",
      "train loss:0.9473924423689397\n",
      "train loss:0.9773122449471221\n",
      "train loss:1.1843505329866266\n",
      "train loss:0.8692312305511359\n",
      "train loss:0.8557264284988487\n",
      "train loss:1.0114004715124194\n",
      "train loss:0.8398123303772325\n",
      "train loss:0.9119148025941487\n",
      "train loss:0.8612694461700617\n",
      "train loss:0.8255106104911737\n",
      "train loss:0.7707404520429985\n",
      "train loss:0.9667295998888952\n",
      "train loss:0.8896111884859905\n",
      "train loss:0.9611286077317035\n",
      "train loss:0.8662903563978672\n",
      "train loss:0.8238810433017306\n",
      "train loss:0.9458213763377846\n",
      "train loss:1.1190919063882863\n",
      "train loss:1.047904389132794\n",
      "train loss:1.0534583882241126\n",
      "train loss:0.8439927285596015\n",
      "train loss:0.9398150839566272\n",
      "train loss:0.9290027576898546\n",
      "train loss:1.0009016446524304\n",
      "train loss:0.9870076261370133\n",
      "train loss:1.0975934115852468\n",
      "train loss:0.6617827374339162\n",
      "train loss:1.0280565089617775\n",
      "train loss:0.971422874733673\n",
      "train loss:0.9709338426051437\n",
      "train loss:0.8109734219894829\n",
      "train loss:0.9456811071748861\n",
      "train loss:0.9156581016640556\n",
      "train loss:1.0014639567384749\n",
      "train loss:1.0205907409021604\n",
      "train loss:0.8631044471464923\n",
      "train loss:0.9406482678664009\n",
      "train loss:1.028665331787096\n",
      "train loss:0.9596901764508149\n",
      "train loss:0.8171598175861405\n",
      "train loss:1.008156760622885\n",
      "train loss:1.1457804163624505\n",
      "train loss:1.026229725482799\n",
      "train loss:0.9237115226037568\n",
      "train loss:0.9170431304475366\n",
      "train loss:0.871721517752387\n",
      "train loss:1.0995650988972696\n",
      "train loss:1.001830881479642\n",
      "train loss:0.8724376836087573\n",
      "train loss:0.9918399017992563\n",
      "train loss:0.9209528017027582\n",
      "train loss:0.8745414782235743\n",
      "train loss:0.9218102702757569\n",
      "train loss:1.0829461962354905\n",
      "train loss:0.8959188350927637\n",
      "train loss:0.980131306381406\n",
      "train loss:0.9974739970485286\n",
      "train loss:1.0418725295079698\n",
      "train loss:1.0504783779578384\n",
      "train loss:1.055658649488396\n",
      "train loss:1.0463407526525526\n",
      "train loss:1.1877796113683432\n",
      "train loss:0.948600351890433\n",
      "train loss:0.9700682806493677\n",
      "train loss:0.9037511087025245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8551891633650596\n",
      "train loss:0.842618137094165\n",
      "train loss:0.8087692331753417\n",
      "train loss:1.0556141122321991\n",
      "train loss:0.8702351551626889\n",
      "train loss:1.012056505328542\n",
      "train loss:0.8732288740108762\n",
      "train loss:0.9630087828015398\n",
      "train loss:1.0705510999916792\n",
      "train loss:1.0260350651462753\n",
      "train loss:0.9330256928512565\n",
      "train loss:0.8511756234344893\n",
      "train loss:0.9986274823496173\n",
      "train loss:0.7741449882464561\n",
      "train loss:1.0473091017555916\n",
      "train loss:1.0065639038024898\n",
      "train loss:1.0999550129864495\n",
      "train loss:0.979851798250314\n",
      "train loss:0.9802396194004129\n",
      "train loss:0.8049472096291468\n",
      "train loss:0.8784153282697557\n",
      "train loss:0.9101907840466461\n",
      "train loss:0.7915387922231223\n",
      "train loss:1.1074366420050463\n",
      "train loss:1.1058086079871239\n",
      "train loss:1.0355801906417776\n",
      "train loss:0.8917878762772851\n",
      "train loss:0.9129052565554834\n",
      "train loss:0.8463598297866697\n",
      "train loss:1.0941492280816882\n",
      "train loss:0.9138495252180928\n",
      "train loss:1.0526298593700674\n",
      "train loss:1.0192774521612162\n",
      "train loss:0.9205994295135714\n",
      "train loss:1.089526017870162\n",
      "train loss:1.0308100605892434\n",
      "train loss:1.033745426687881\n",
      "train loss:0.9465222315903016\n",
      "train loss:0.9266563965476072\n",
      "train loss:0.9209660735222868\n",
      "train loss:0.897907791203034\n",
      "train loss:0.8290183960946785\n",
      "train loss:0.9033102652973372\n",
      "train loss:0.8633461013046858\n",
      "train loss:1.0349349299466268\n",
      "train loss:0.8857757698843968\n",
      "train loss:0.9604802524820119\n",
      "train loss:0.9774715914008617\n",
      "train loss:0.9145403573777905\n",
      "train loss:0.9632888930264769\n",
      "train loss:0.8923998589054879\n",
      "train loss:0.9487559071028641\n",
      "train loss:0.8235991114666593\n",
      "train loss:0.8091494546825295\n",
      "train loss:0.9753991833162455\n",
      "train loss:1.0059281753376965\n",
      "train loss:0.9174656311735434\n",
      "train loss:0.8126701977818235\n",
      "train loss:0.970489301427531\n",
      "train loss:1.2464744459366814\n",
      "train loss:0.881476213266707\n",
      "train loss:0.9791092655250584\n",
      "train loss:1.0834229739514643\n",
      "train loss:0.8597184376408598\n",
      "train loss:0.8506121165872661\n",
      "train loss:1.0046553972279784\n",
      "train loss:0.9687804705146137\n",
      "train loss:0.9585285506598475\n",
      "train loss:0.9324139099722007\n",
      "train loss:0.8516937318516766\n",
      "train loss:1.0563980538569315\n",
      "train loss:1.129673900085723\n",
      "train loss:0.908602275958837\n",
      "train loss:0.9011471094186788\n",
      "train loss:1.1731862509297957\n",
      "train loss:1.0286272048868124\n",
      "train loss:1.0276217231150917\n",
      "train loss:1.1382958651817743\n",
      "train loss:0.9952360063056409\n",
      "train loss:0.7369989337279031\n",
      "train loss:0.8538732291404132\n",
      "train loss:1.0218941243406932\n",
      "train loss:0.9395543841586196\n",
      "train loss:0.9464905692105599\n",
      "train loss:0.8877692994953444\n",
      "train loss:1.1342860658720537\n",
      "train loss:0.9328944404291017\n",
      "train loss:0.950471672613245\n",
      "train loss:0.9950754540102735\n",
      "train loss:0.9440996050013326\n",
      "train loss:0.8458917044719334\n",
      "train loss:0.9538776988207784\n",
      "train loss:0.9126550851230728\n",
      "train loss:1.0549192976689605\n",
      "train loss:0.9490947966638644\n",
      "train loss:0.9698313011968458\n",
      "train loss:1.0176202648299553\n",
      "train loss:0.8492698908198837\n",
      "train loss:0.9269644986210993\n",
      "train loss:0.9524316594018651\n",
      "train loss:0.9345744475032025\n",
      "train loss:1.099466959120567\n",
      "train loss:0.9617603919539718\n",
      "train loss:1.0050366491764622\n",
      "train loss:0.8785851861758629\n",
      "train loss:0.8904608849796334\n",
      "train loss:1.0580222344905417\n",
      "train loss:1.1137236937235186\n",
      "train loss:0.9062957462290325\n",
      "train loss:0.9460687028097141\n",
      "train loss:1.0183349588498642\n",
      "train loss:0.9391337253922849\n",
      "train loss:0.9981501259798126\n",
      "train loss:1.0036240845934046\n",
      "train loss:1.0678309453506962\n",
      "train loss:1.0210842898773516\n",
      "train loss:0.8373075503878598\n",
      "train loss:0.9043698595879244\n",
      "train loss:0.8996958988488107\n",
      "train loss:0.7183674496225865\n",
      "train loss:1.1045742719231697\n",
      "train loss:0.9305587751444793\n",
      "train loss:1.0142873585498196\n",
      "train loss:0.8658263737155114\n",
      "train loss:0.9865727587443601\n",
      "train loss:1.105948589193781\n",
      "train loss:0.8317977843723295\n",
      "train loss:1.122363093546771\n",
      "train loss:0.9403870895510346\n",
      "train loss:0.8439609281790287\n",
      "train loss:0.8439334249480405\n",
      "train loss:0.8204154016933992\n",
      "train loss:0.9688728652464197\n",
      "train loss:1.0326318515092168\n",
      "train loss:0.8726852810242909\n",
      "train loss:1.091683509166907\n",
      "train loss:0.9329678301725888\n",
      "train loss:0.8284532816762181\n",
      "train loss:0.889535235242712\n",
      "train loss:0.970494523478542\n",
      "train loss:1.0174978253067408\n",
      "train loss:0.8500561353703108\n",
      "train loss:1.0634827373961537\n",
      "train loss:1.0776377880651085\n",
      "train loss:0.7332420522739865\n",
      "train loss:1.0005908005198154\n",
      "train loss:0.9788109039246591\n",
      "train loss:1.0917011786907331\n",
      "train loss:1.028122662163549\n",
      "train loss:0.8973244872374502\n",
      "train loss:1.0899758414603817\n",
      "train loss:1.1220760444185027\n",
      "train loss:0.9834769856986927\n",
      "train loss:0.8633630299225418\n",
      "train loss:1.0360235789769512\n",
      "train loss:0.8072723924888621\n",
      "train loss:0.9334634887748529\n",
      "train loss:0.9741564518367518\n",
      "train loss:1.1045758899144669\n",
      "train loss:1.0166175626057168\n",
      "train loss:0.8892628730864489\n",
      "train loss:1.0625850937350718\n",
      "train loss:0.8624475974006774\n",
      "train loss:0.8651315164400403\n",
      "train loss:0.8359989622153877\n",
      "train loss:0.9307017121397522\n",
      "train loss:1.0005940576918668\n",
      "train loss:0.9690523725501881\n",
      "train loss:1.0796124869751766\n",
      "train loss:0.8464803494163036\n",
      "train loss:1.0314469125824501\n",
      "train loss:0.921886939770401\n",
      "train loss:0.9356496888034423\n",
      "train loss:1.0496654045185858\n",
      "train loss:0.9612337833735053\n",
      "train loss:0.8518551313892722\n",
      "train loss:0.9500395509979339\n",
      "train loss:0.8078533075982597\n",
      "train loss:0.9424386484000208\n",
      "train loss:0.9315675384819196\n",
      "train loss:0.8686260860342279\n",
      "train loss:1.0266334893550257\n",
      "train loss:1.0276421494195387\n",
      "train loss:0.8738846339271461\n",
      "train loss:0.9108083683865815\n",
      "train loss:1.1035856999277802\n",
      "train loss:0.8975918399100121\n",
      "train loss:0.8841458488278058\n",
      "train loss:0.8441362069943031\n",
      "train loss:1.0355306569926652\n",
      "train loss:1.03334734740605\n",
      "train loss:0.8683047653553781\n",
      "train loss:1.0574637214115947\n",
      "train loss:0.8978935484953542\n",
      "train loss:0.7980071371589449\n",
      "train loss:0.8446715238350521\n",
      "train loss:0.8909173901487403\n",
      "train loss:1.0538680729853598\n",
      "train loss:0.9782834771666488\n",
      "train loss:1.114667808217882\n",
      "train loss:1.0647206726651595\n",
      "train loss:1.0675997343229446\n",
      "train loss:0.9166810593192793\n",
      "train loss:1.0481972108555855\n",
      "train loss:0.9929403048436042\n",
      "train loss:0.9066386689327901\n",
      "train loss:0.9400736193711462\n",
      "train loss:0.9301847275959403\n",
      "train loss:1.000191768259286\n",
      "train loss:1.0277516214117666\n",
      "train loss:0.8696011176725551\n",
      "train loss:0.8221374160556547\n",
      "train loss:1.067945898038321\n",
      "train loss:0.8838254009164942\n",
      "train loss:1.010358709061915\n",
      "train loss:0.8532210723903177\n",
      "train loss:1.0504038976522274\n",
      "train loss:0.9809328892924034\n",
      "train loss:0.9594136983854518\n",
      "train loss:0.9331607923904098\n",
      "train loss:0.9138919589085738\n",
      "train loss:0.8156465085683695\n",
      "train loss:0.8591556832851568\n",
      "train loss:1.0467095243770717\n",
      "train loss:1.064426242326638\n",
      "train loss:0.94954783750513\n",
      "train loss:0.98302508881538\n",
      "train loss:0.9223966357193383\n",
      "train loss:0.9186679900585746\n",
      "train loss:0.891083138207206\n",
      "train loss:0.8159597940392267\n",
      "train loss:0.8541295900716075\n",
      "train loss:0.9974872941202974\n",
      "train loss:1.0204743468861845\n",
      "train loss:0.8964376628896712\n",
      "train loss:0.9127815778239383\n",
      "train loss:0.84773351347932\n",
      "train loss:0.8540253853102634\n",
      "train loss:0.9177020468221891\n",
      "train loss:0.8449873710472207\n",
      "train loss:0.9815304653810276\n",
      "train loss:0.9113122676599933\n",
      "train loss:0.8866040246282274\n",
      "train loss:0.8867510732057124\n",
      "train loss:0.9662374263268183\n",
      "train loss:0.9196202442167764\n",
      "train loss:0.8791163344081174\n",
      "train loss:0.962066757959939\n",
      "train loss:1.0585507417211322\n",
      "train loss:0.9234550577861637\n",
      "train loss:0.9889304040473965\n",
      "train loss:0.9948772402270225\n",
      "train loss:0.8929047453404698\n",
      "train loss:1.0080672976677074\n",
      "train loss:1.1152038286424453\n",
      "train loss:1.010086696918264\n",
      "train loss:0.8046243349781506\n",
      "train loss:1.0677537146603986\n",
      "train loss:0.8954256443461703\n",
      "train loss:0.8347995442099664\n",
      "train loss:0.9946137479232406\n",
      "train loss:1.0429016945722003\n",
      "train loss:0.9740192606198105\n",
      "train loss:1.073612859525234\n",
      "train loss:0.8959380548738136\n",
      "train loss:1.0157588756649654\n",
      "train loss:0.7865669922545971\n",
      "train loss:0.8636111377709326\n",
      "train loss:1.1926123866639957\n",
      "train loss:0.9185994850991793\n",
      "train loss:0.9199613419041982\n",
      "train loss:0.9662331529435337\n",
      "train loss:0.9496962237057989\n",
      "train loss:1.0409095537722446\n",
      "train loss:1.077288761135615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9157125002674124\n",
      "train loss:1.181299935916169\n",
      "train loss:1.0687367171498439\n",
      "train loss:1.014458205339585\n",
      "train loss:0.7941587534454092\n",
      "train loss:1.1007028024833976\n",
      "train loss:0.8493501518395666\n",
      "train loss:1.0210318982663475\n",
      "=== epoch:12, train acc:0.988, test acc:0.991 ===\n",
      "train loss:0.8942084090950796\n",
      "train loss:0.9034766089111368\n",
      "train loss:1.0037589371476934\n",
      "train loss:1.0173249521294847\n",
      "train loss:0.9346532121929725\n",
      "train loss:0.9821086496975993\n",
      "train loss:0.7376695888301519\n",
      "train loss:0.8408956577710104\n",
      "train loss:1.0104748791941223\n",
      "train loss:1.058152198082853\n",
      "train loss:0.821593121469387\n",
      "train loss:0.9331590407450113\n",
      "train loss:0.9779237859298396\n",
      "train loss:0.9262700822729522\n",
      "train loss:0.9265128544818251\n",
      "train loss:1.0215185554176733\n",
      "train loss:0.715890729848403\n",
      "train loss:0.9586073548157182\n",
      "train loss:0.9582126812051734\n",
      "train loss:1.1260280454773821\n",
      "train loss:0.9397999908527177\n",
      "train loss:1.1013621886313332\n",
      "train loss:0.7435574189004478\n",
      "train loss:0.7564034339920012\n",
      "train loss:0.9974580661461606\n",
      "train loss:0.8563215975962941\n",
      "train loss:0.9105116250433645\n",
      "train loss:0.8644624408964954\n",
      "train loss:0.8916443600475307\n",
      "train loss:0.8770659179274675\n",
      "train loss:0.8990661179708116\n",
      "train loss:0.7517266840053779\n",
      "train loss:0.8341201709789303\n",
      "train loss:0.9090068716447314\n",
      "train loss:0.8402604867964386\n",
      "train loss:0.9873931947875155\n",
      "train loss:1.233107177788152\n",
      "train loss:1.036733091538648\n",
      "train loss:0.8976243141938106\n",
      "train loss:0.8510076935535744\n",
      "train loss:0.968390793009544\n",
      "train loss:0.7665841367059143\n",
      "train loss:0.8478555043392985\n",
      "train loss:0.8842825682932525\n",
      "train loss:1.052940342460832\n",
      "train loss:0.92456667184264\n",
      "train loss:0.8061531056311309\n",
      "train loss:0.918356775519879\n",
      "train loss:0.9601619326336949\n",
      "train loss:1.0122157537834924\n",
      "train loss:0.8388212802969832\n",
      "train loss:0.8951034968744395\n",
      "train loss:0.9273860303708744\n",
      "train loss:0.861222931442904\n",
      "train loss:0.9891671920978589\n",
      "train loss:0.96812047560752\n",
      "train loss:0.832229175289735\n",
      "train loss:0.9741510951491071\n",
      "train loss:0.8068275425761331\n",
      "train loss:0.986241487314147\n",
      "train loss:0.8430754089254094\n",
      "train loss:0.9360379711886142\n",
      "train loss:0.8527414646608846\n",
      "train loss:0.9816104838110365\n",
      "train loss:0.731975636486873\n",
      "train loss:0.8866873299558392\n",
      "train loss:0.9540491487399438\n",
      "train loss:1.0079897486346523\n",
      "train loss:0.9590007216282241\n",
      "train loss:1.0675904097900524\n",
      "train loss:0.8352058587849345\n",
      "train loss:0.8433794329285554\n",
      "train loss:0.9498218616015831\n",
      "train loss:0.9331088646533233\n",
      "train loss:0.9187578819968191\n",
      "train loss:1.062666064633927\n",
      "train loss:0.9919016864030304\n",
      "train loss:0.8318164668829993\n",
      "train loss:0.9976026758905837\n",
      "train loss:0.9584791752417702\n",
      "train loss:0.8133591532417563\n",
      "train loss:0.8803412005194037\n",
      "train loss:0.8574903357383721\n",
      "train loss:1.023749614317335\n",
      "train loss:0.9222356875651017\n",
      "train loss:0.8871856661011657\n",
      "train loss:0.9114294525682225\n",
      "train loss:0.8833763239899519\n",
      "train loss:0.9236706266026927\n",
      "train loss:1.1644407702607595\n",
      "train loss:0.9647146311804632\n",
      "train loss:1.088405369851018\n",
      "train loss:0.9563347688674106\n",
      "train loss:0.9096172282837311\n",
      "train loss:0.9938490909944417\n",
      "train loss:0.9285104307769704\n",
      "train loss:0.7887486836528008\n",
      "train loss:0.7747683758267059\n",
      "train loss:0.9159776091933294\n",
      "train loss:0.9095793488887254\n",
      "train loss:0.8647523173309015\n",
      "train loss:0.829995595954648\n",
      "train loss:0.9146894082840668\n",
      "train loss:1.0430831750578595\n",
      "train loss:1.0280926474775731\n",
      "train loss:0.9553650224156687\n",
      "train loss:1.0382340821238065\n",
      "train loss:0.9732665927614548\n",
      "train loss:0.7971984909784762\n",
      "train loss:1.0150550306422619\n",
      "train loss:0.9202458209734341\n",
      "train loss:0.9682065947489565\n",
      "train loss:0.9229853609151012\n",
      "train loss:1.039205055159627\n",
      "train loss:1.0051030041252376\n",
      "train loss:1.0045208818379256\n",
      "train loss:1.0898682993785065\n",
      "train loss:1.042712265060328\n",
      "train loss:0.9237945020851533\n",
      "train loss:0.934449473867166\n",
      "train loss:1.0278444442623846\n",
      "train loss:1.0912452499792642\n",
      "train loss:0.9756420807024394\n",
      "train loss:0.9966448514962054\n",
      "train loss:0.8295302930387237\n",
      "train loss:0.9128216326504268\n",
      "train loss:0.9376512801097785\n",
      "train loss:0.9025769448117649\n",
      "train loss:1.1666548826359324\n",
      "train loss:0.9648375525687668\n",
      "train loss:0.8628109757240295\n",
      "train loss:0.8941327352348396\n",
      "train loss:0.959394860280012\n",
      "train loss:0.8416710977383107\n",
      "train loss:0.915019300300288\n",
      "train loss:1.1149487136916252\n",
      "train loss:1.0145666179714063\n",
      "train loss:0.8582065076769959\n",
      "train loss:0.8996752928043652\n",
      "train loss:0.9490121427753366\n",
      "train loss:1.0823525562943184\n",
      "train loss:0.7721288031747752\n",
      "train loss:0.8789605966583082\n",
      "train loss:1.0843972636834411\n",
      "train loss:0.9552049544551585\n",
      "train loss:0.8163542923982366\n",
      "train loss:1.026184589312775\n",
      "train loss:0.8812825886131143\n",
      "train loss:1.0003095785934197\n",
      "train loss:0.8550546221938314\n",
      "train loss:0.7718610293118888\n",
      "train loss:1.0448287776539296\n",
      "train loss:0.931070239981411\n",
      "train loss:0.9306879069931118\n",
      "train loss:0.9834027585708895\n",
      "train loss:0.9349751406289418\n",
      "train loss:1.0169625591539369\n",
      "train loss:0.7612738387490232\n",
      "train loss:0.9294015846687373\n",
      "train loss:0.9755225080647437\n",
      "train loss:1.091837636517304\n",
      "train loss:0.8955215780334109\n",
      "train loss:1.0372834294414977\n",
      "train loss:1.0342640197405828\n",
      "train loss:0.9464617864319728\n",
      "train loss:0.8776014852678538\n",
      "train loss:0.713966816732245\n",
      "train loss:0.8506450817337494\n",
      "train loss:1.085028255078881\n",
      "train loss:0.883711077896202\n",
      "train loss:1.002766339715749\n",
      "train loss:0.8819799828991021\n",
      "train loss:1.1694206327711023\n",
      "train loss:1.1173321243644738\n",
      "train loss:0.9117033298701913\n",
      "train loss:0.8313154947282446\n",
      "train loss:0.7683525569489201\n",
      "train loss:0.8783102435581301\n",
      "train loss:0.9179645491307015\n",
      "train loss:1.0416837871787725\n",
      "train loss:0.8844905264453776\n",
      "train loss:0.9138797830666673\n",
      "train loss:0.9582227543701487\n",
      "train loss:0.9343691529474241\n",
      "train loss:0.8307432113624722\n",
      "train loss:0.9208886166908069\n",
      "train loss:0.9138303569538171\n",
      "train loss:0.9329267154476412\n",
      "train loss:0.8911181797649235\n",
      "train loss:1.12535414108898\n",
      "train loss:0.894795272876508\n",
      "train loss:0.9257215054911572\n",
      "train loss:0.9150141025249907\n",
      "train loss:0.9853983322397484\n",
      "train loss:0.8573181147587544\n",
      "train loss:1.0646808638762613\n",
      "train loss:0.865539187854761\n",
      "train loss:0.9929159044782027\n",
      "train loss:0.837267582943038\n",
      "train loss:0.9477284041990858\n",
      "train loss:0.9836871043715186\n",
      "train loss:0.8943985893260867\n",
      "train loss:0.8958432357934843\n",
      "train loss:0.9206174806360208\n",
      "train loss:0.8684996329387373\n",
      "train loss:1.0464175553690303\n",
      "train loss:1.024685612162888\n",
      "train loss:0.8607229477256664\n",
      "train loss:0.8872416824710512\n",
      "train loss:1.081550199365389\n",
      "train loss:0.8672361961860231\n",
      "train loss:0.9484440937269918\n",
      "train loss:0.8190230493084429\n",
      "train loss:1.0194226782556266\n",
      "train loss:1.00122964378931\n",
      "train loss:0.7573686406355528\n",
      "train loss:0.9816399074026896\n",
      "train loss:1.1178074361752888\n",
      "train loss:1.0758780612627326\n",
      "train loss:1.0086576587478686\n",
      "train loss:0.8652572045731111\n",
      "train loss:1.027022651301759\n",
      "train loss:0.9073941372603914\n",
      "train loss:0.9016100306134771\n",
      "train loss:1.047646738555971\n",
      "train loss:1.0796419012971719\n",
      "train loss:0.8973247541126831\n",
      "train loss:0.7906415965480963\n",
      "train loss:0.8569068516374663\n",
      "train loss:0.9467477349827671\n",
      "train loss:1.0017952786393138\n",
      "train loss:0.9017470050816914\n",
      "train loss:0.9457718596781807\n",
      "train loss:0.913558895643237\n",
      "train loss:0.8167153413041555\n",
      "train loss:1.1095608095109177\n",
      "train loss:0.8598017179846977\n",
      "train loss:1.0107323946669073\n",
      "train loss:0.9884862114818306\n",
      "train loss:0.9611105657635661\n",
      "train loss:1.0853112946298151\n",
      "train loss:0.8587198880447757\n",
      "train loss:1.0186685068590449\n",
      "train loss:0.8740411141864958\n",
      "train loss:0.9462627321890607\n",
      "train loss:1.0773618754937\n",
      "train loss:0.905549329443751\n",
      "train loss:1.0661957518168714\n",
      "train loss:0.9613962379921684\n",
      "train loss:0.9823021414215474\n",
      "train loss:1.0369966622355395\n",
      "train loss:0.8969755698268813\n",
      "train loss:0.9806854158848433\n",
      "train loss:0.9496045424963249\n",
      "train loss:0.9068229537269429\n",
      "train loss:0.9937948612846\n",
      "train loss:0.8781054216540611\n",
      "train loss:1.1730332150557232\n",
      "train loss:0.8559688040094212\n",
      "train loss:0.8938927546820709\n",
      "train loss:0.8648120727861603\n",
      "train loss:0.9757013742239877\n",
      "train loss:1.0167826829416533\n",
      "train loss:0.86160680536761\n",
      "train loss:0.8552394061346752\n",
      "train loss:0.8956547207418503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9536404189292225\n",
      "train loss:0.9286781756990146\n",
      "train loss:0.8751411773785956\n",
      "train loss:0.8934492576854758\n",
      "train loss:0.9669513488980616\n",
      "train loss:0.882738504693842\n",
      "train loss:0.96883155196694\n",
      "train loss:0.885416519858049\n",
      "train loss:0.9496380734382484\n",
      "train loss:0.8640482186837527\n",
      "train loss:0.848416854409566\n",
      "train loss:0.9911597518710322\n",
      "train loss:0.9906127355723849\n",
      "train loss:0.7954220980216753\n",
      "train loss:0.8857887542541042\n",
      "train loss:1.0991992137373194\n",
      "train loss:0.8733975056224489\n",
      "train loss:0.8010975839401546\n",
      "train loss:0.8251025782910442\n",
      "train loss:0.9633567482621279\n",
      "train loss:0.8885655302672336\n",
      "train loss:1.0037758520727416\n",
      "train loss:1.0034982010001297\n",
      "train loss:1.0040165186868684\n",
      "train loss:0.9132829816150178\n",
      "train loss:0.9452575778581824\n",
      "train loss:0.8791871406942537\n",
      "train loss:1.0391687652179564\n",
      "train loss:1.076344037888916\n",
      "train loss:1.0026602321216895\n",
      "train loss:0.9383484205731613\n",
      "train loss:1.0483023331582835\n",
      "train loss:0.820811508163557\n",
      "train loss:0.8204050658252564\n",
      "train loss:0.8798702233152587\n",
      "train loss:0.918243853687118\n",
      "train loss:0.9738633443460849\n",
      "train loss:0.9017375496019288\n",
      "train loss:1.0452278083140323\n",
      "train loss:0.8871131670006364\n",
      "train loss:0.7360738137005485\n",
      "train loss:0.8848361994704121\n",
      "train loss:1.039631707018405\n",
      "train loss:0.8925651283656406\n",
      "train loss:0.7633062135258811\n",
      "train loss:1.0046113651396913\n",
      "train loss:1.0413297332446847\n",
      "train loss:0.920125760381676\n",
      "train loss:1.027004106328393\n",
      "train loss:1.028057781822235\n",
      "train loss:1.0608093808424937\n",
      "train loss:0.7576132812571623\n",
      "train loss:1.1851494217092948\n",
      "train loss:1.1031149510292912\n",
      "train loss:0.9497033437389456\n",
      "train loss:1.0163189538932327\n",
      "train loss:1.1302788643899282\n",
      "train loss:1.031579540039135\n",
      "train loss:1.1519952873295167\n",
      "train loss:0.6931132271278956\n",
      "train loss:0.8173428738099741\n",
      "train loss:0.8997688192253854\n",
      "train loss:0.9091876679796402\n",
      "train loss:0.9043866337975427\n",
      "train loss:0.8117505553191584\n",
      "train loss:0.9516329185639205\n",
      "train loss:0.9507621613608462\n",
      "train loss:0.8588760063106023\n",
      "train loss:0.9698829024464505\n",
      "train loss:1.0017043625669344\n",
      "train loss:1.143162164434826\n",
      "train loss:0.9530205751502437\n",
      "train loss:0.8065234394118029\n",
      "train loss:0.8129375158763377\n",
      "train loss:1.02660617827843\n",
      "train loss:0.9839010637720594\n",
      "train loss:0.7905729177188499\n",
      "train loss:1.0738463797407898\n",
      "train loss:0.9097252742411619\n",
      "train loss:0.909634122854175\n",
      "train loss:0.8279259934285866\n",
      "train loss:0.7111303209024987\n",
      "train loss:0.9252012180800853\n",
      "train loss:0.9707739734479125\n",
      "train loss:0.7667663271765646\n",
      "train loss:1.0725670632639102\n",
      "train loss:0.9007133457935526\n",
      "train loss:0.982196448441034\n",
      "train loss:0.8600297012064934\n",
      "train loss:1.116589176890079\n",
      "train loss:0.9374288769232203\n",
      "train loss:0.9539640872889771\n",
      "train loss:1.0184800025852538\n",
      "train loss:0.9880961357087413\n",
      "train loss:0.8480579801493733\n",
      "train loss:0.746228125608397\n",
      "train loss:1.00885920269273\n",
      "train loss:0.8335671525035298\n",
      "train loss:1.0405968925909121\n",
      "train loss:0.847095898954583\n",
      "train loss:0.8384618693747208\n",
      "train loss:0.972152533499193\n",
      "train loss:0.9145411041146301\n",
      "train loss:0.9804842149048182\n",
      "train loss:0.999221997220736\n",
      "train loss:0.7856847838406312\n",
      "train loss:0.9842092220644765\n",
      "train loss:0.9976435437633795\n",
      "train loss:0.7745334310007473\n",
      "train loss:0.9708943256747494\n",
      "train loss:0.9927832318239527\n",
      "train loss:0.9396425432079437\n",
      "train loss:1.0910937391639501\n",
      "train loss:0.9154142264764148\n",
      "train loss:0.8940412558418528\n",
      "train loss:1.0026784090973515\n",
      "train loss:1.0117090754879328\n",
      "train loss:0.7601536518930762\n",
      "train loss:1.021205956252294\n",
      "train loss:0.9094509498382033\n",
      "train loss:0.9559416027596574\n",
      "train loss:0.8901629251398654\n",
      "train loss:0.8937147645270064\n",
      "train loss:0.956519703695806\n",
      "train loss:1.064408663074907\n",
      "train loss:0.9168169210688292\n",
      "train loss:0.968119383875764\n",
      "train loss:0.9259812953030659\n",
      "train loss:0.7830545359476422\n",
      "train loss:0.9599509005253382\n",
      "train loss:1.0638363500454817\n",
      "train loss:1.1829013650184919\n",
      "train loss:1.050884709979126\n",
      "train loss:0.8083095365240736\n",
      "train loss:0.8479861341049699\n",
      "train loss:1.0401996365551194\n",
      "train loss:0.9030770374344566\n",
      "train loss:0.8257033745954935\n",
      "train loss:1.089845131795443\n",
      "train loss:1.0346492428389065\n",
      "train loss:0.9061602513397651\n",
      "train loss:0.9730240499801087\n",
      "train loss:1.060312129987069\n",
      "train loss:1.0137961088123029\n",
      "train loss:1.0033594994782218\n",
      "train loss:0.8906682928601686\n",
      "train loss:0.9603716560861755\n",
      "train loss:0.8621064553248972\n",
      "train loss:0.9441190522105665\n",
      "train loss:0.851114130814098\n",
      "train loss:0.8859511169017079\n",
      "train loss:0.8481611520220959\n",
      "train loss:0.8958938599225453\n",
      "train loss:1.0280647035757597\n",
      "train loss:0.9731151263993459\n",
      "train loss:1.0893825340794827\n",
      "train loss:0.9388111302895957\n",
      "train loss:0.9097600829484425\n",
      "train loss:0.966287211041632\n",
      "train loss:1.1652780635142153\n",
      "train loss:0.8003586537848303\n",
      "train loss:0.8506804651879155\n",
      "train loss:0.9083347677391571\n",
      "train loss:1.0022980265529968\n",
      "train loss:1.0732951704998805\n",
      "train loss:0.8938864129564379\n",
      "train loss:0.8838707219380914\n",
      "train loss:0.9297154329081343\n",
      "train loss:1.027466850590581\n",
      "train loss:0.8822482588502575\n",
      "train loss:1.0564979322103523\n",
      "train loss:0.9304382876139167\n",
      "train loss:0.9485930550799472\n",
      "train loss:1.0142458711116662\n",
      "train loss:0.872779991666154\n",
      "train loss:0.9619988180575971\n",
      "train loss:0.917253897866834\n",
      "train loss:1.0035751372571529\n",
      "train loss:0.8862245053667164\n",
      "train loss:0.9830838792556332\n",
      "train loss:1.077774507695924\n",
      "train loss:1.0744296789355354\n",
      "train loss:1.1379042690799852\n",
      "train loss:0.9494933790293528\n",
      "train loss:1.1075535080595775\n",
      "train loss:0.9710592642551639\n",
      "train loss:0.9705191893499471\n",
      "train loss:0.7888515010873398\n",
      "train loss:1.1124634079941178\n",
      "train loss:0.8474882720296603\n",
      "train loss:0.9768786598013066\n",
      "train loss:1.0233423954720515\n",
      "train loss:0.8916254490610757\n",
      "train loss:0.993637666806135\n",
      "train loss:1.0164028437781973\n",
      "train loss:0.9869021370096346\n",
      "train loss:0.893847066939816\n",
      "train loss:1.0580217552150089\n",
      "train loss:0.872031787566247\n",
      "train loss:1.0479130646888053\n",
      "train loss:0.8947457817891684\n",
      "train loss:0.7729020843281406\n",
      "train loss:0.9446402124232657\n",
      "train loss:0.8933940203313026\n",
      "train loss:1.0774628685269187\n",
      "train loss:0.9713620665874241\n",
      "train loss:0.9471661120194205\n",
      "train loss:0.960924533045583\n",
      "train loss:0.9022943699058598\n",
      "train loss:1.0575023519237778\n",
      "train loss:0.9416222659987856\n",
      "train loss:1.0889743952834443\n",
      "train loss:0.8692811586252137\n",
      "train loss:0.8736583781098065\n",
      "train loss:0.9539692098567829\n",
      "train loss:0.9200151528523195\n",
      "train loss:0.8272589241892916\n",
      "train loss:1.0223459986444872\n",
      "train loss:0.9357282824019844\n",
      "train loss:1.0527740367357896\n",
      "train loss:0.9108369915493425\n",
      "train loss:1.0552741739986724\n",
      "train loss:1.05285158420504\n",
      "train loss:0.9352501971128667\n",
      "train loss:0.9804555203067379\n",
      "train loss:0.7150564902415881\n",
      "train loss:1.1472777382527444\n",
      "train loss:0.9033622182062188\n",
      "train loss:0.8973072911190221\n",
      "train loss:0.9134964740887668\n",
      "train loss:0.912221391785994\n",
      "train loss:1.0161736741453398\n",
      "train loss:0.9655074572570908\n",
      "train loss:1.0383012644113447\n",
      "train loss:0.9337645669892397\n",
      "train loss:0.9130107941985116\n",
      "train loss:0.9999608227756512\n",
      "train loss:0.9463515196323199\n",
      "train loss:0.7840766921405369\n",
      "train loss:0.9809407300957669\n",
      "train loss:1.0064973514257958\n",
      "train loss:0.8317381840190581\n",
      "train loss:0.9634573418761687\n",
      "train loss:0.9066445565159289\n",
      "train loss:0.955664362046297\n",
      "train loss:0.8013866446540417\n",
      "train loss:0.8814741236867983\n",
      "train loss:1.0073802216229122\n",
      "train loss:0.829756532004298\n",
      "train loss:0.7666708613353247\n",
      "train loss:1.0306833931391404\n",
      "train loss:1.0179427483239112\n",
      "train loss:1.023055505608937\n",
      "train loss:0.9899523075278434\n",
      "train loss:0.8639039423697507\n",
      "train loss:0.7969083981065552\n",
      "train loss:0.8725450170066924\n",
      "train loss:0.9275316772131836\n",
      "train loss:0.9691302464423437\n",
      "train loss:1.0513172483808355\n",
      "train loss:0.927321029239627\n",
      "train loss:0.9710417730797611\n",
      "train loss:0.8892968446046207\n",
      "train loss:0.9114318031512778\n",
      "train loss:1.0434835352655383\n",
      "train loss:0.9087546912926256\n",
      "train loss:0.9678717404436018\n",
      "train loss:1.032495775215157\n",
      "train loss:0.8707447473238736\n",
      "train loss:0.8670718369634204\n",
      "train loss:1.009652541164802\n",
      "train loss:0.9644551565740729\n",
      "train loss:0.9183063964155675\n",
      "train loss:1.0244886125612802\n",
      "train loss:0.8145755749683613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7793916160406218\n",
      "train loss:1.061378655768766\n",
      "train loss:1.0003902799621025\n",
      "train loss:0.9253569455589303\n",
      "train loss:0.968236485579866\n",
      "train loss:0.8737007777766883\n",
      "train loss:0.9455873202085389\n",
      "train loss:0.9308507236318221\n",
      "train loss:0.9459264949738804\n",
      "train loss:1.0045620076835555\n",
      "train loss:0.911071249802662\n",
      "train loss:1.134984880382368\n",
      "train loss:0.9623399864182016\n",
      "train loss:0.8406661210915884\n",
      "train loss:0.9663000202734163\n",
      "train loss:1.045869827440701\n",
      "train loss:0.9186043549918107\n",
      "train loss:0.8935086431429631\n",
      "train loss:1.0004804800616953\n",
      "train loss:1.0309617185495366\n",
      "train loss:1.069374003825891\n",
      "train loss:1.0978321530731463\n",
      "train loss:1.1111076023690567\n",
      "train loss:1.0681298389316927\n",
      "train loss:1.01416896673409\n",
      "train loss:1.2424407539102051\n",
      "train loss:0.8208042266530272\n",
      "train loss:0.9501959460185033\n",
      "train loss:0.9357405651507444\n",
      "train loss:0.9638938560878607\n",
      "train loss:0.9882182639209992\n",
      "train loss:1.1289479510809763\n",
      "train loss:0.8917656137959784\n",
      "train loss:0.8382209515868861\n",
      "train loss:0.9075872318191998\n",
      "train loss:0.9179497100614351\n",
      "train loss:0.877149125702666\n",
      "train loss:0.8391443315148007\n",
      "train loss:0.8883769443630721\n",
      "train loss:0.7967336628981729\n",
      "train loss:0.9693663963154787\n",
      "train loss:0.8625238876652352\n",
      "train loss:0.8984812168766868\n",
      "train loss:1.049991418025388\n",
      "train loss:1.0733671084739032\n",
      "train loss:1.1368350521402688\n",
      "train loss:0.957894043662156\n",
      "train loss:1.0163413214040284\n",
      "train loss:0.9075785488607212\n",
      "train loss:0.9818230830145518\n",
      "train loss:0.9566639484247679\n",
      "train loss:0.8152868395542603\n",
      "train loss:0.9401976432042928\n",
      "train loss:0.7682176612323474\n",
      "train loss:0.8249764464910306\n",
      "train loss:0.9881474566162655\n",
      "train loss:0.8927409065846362\n",
      "train loss:0.886853651088655\n",
      "train loss:0.9282511081265892\n",
      "=== epoch:13, train acc:0.986, test acc:0.99 ===\n",
      "train loss:0.9019186334498192\n",
      "train loss:1.0678244250429276\n",
      "train loss:0.872451257396309\n",
      "train loss:0.8542958947500041\n",
      "train loss:0.9351542721101557\n",
      "train loss:0.8397338878073148\n",
      "train loss:0.9103680011085925\n",
      "train loss:0.8155704794798032\n",
      "train loss:0.9530935392579422\n",
      "train loss:0.9299866498433815\n",
      "train loss:0.8812439929910245\n",
      "train loss:1.0993588022353478\n",
      "train loss:1.1780189036662665\n",
      "train loss:0.7278918157430272\n",
      "train loss:1.047559026944761\n",
      "train loss:0.9820966112198991\n",
      "train loss:0.7806674757787436\n",
      "train loss:0.9246602526238068\n",
      "train loss:0.7919066856012985\n",
      "train loss:0.813065371925873\n",
      "train loss:0.9688137569681016\n",
      "train loss:0.8462312430661459\n",
      "train loss:0.98514238796418\n",
      "train loss:1.064993779163866\n",
      "train loss:0.9566856545896296\n",
      "train loss:0.8658290814900426\n",
      "train loss:0.929245517802915\n",
      "train loss:0.9083105527671546\n",
      "train loss:0.9049676640303086\n",
      "train loss:0.7670703191199388\n",
      "train loss:0.999691885124644\n",
      "train loss:0.9197658797653011\n",
      "train loss:0.9300831285651066\n",
      "train loss:0.8682463092334863\n",
      "train loss:0.9954539647400111\n",
      "train loss:1.068547048218381\n",
      "train loss:0.9061751742916185\n",
      "train loss:0.9371572513083186\n",
      "train loss:0.9030531613959444\n",
      "train loss:0.9614090128900749\n",
      "train loss:0.9512964434440354\n",
      "train loss:1.0914087409522657\n",
      "train loss:1.0982633876798216\n",
      "train loss:0.7972941744066838\n",
      "train loss:1.0697550098444655\n",
      "train loss:1.0352467995294312\n",
      "train loss:0.9563797966864377\n",
      "train loss:0.8814304409127526\n",
      "train loss:0.9914745364100593\n",
      "train loss:1.0413221533366799\n",
      "train loss:0.9860668206589714\n",
      "train loss:0.9557857645530823\n",
      "train loss:0.9160299147471759\n",
      "train loss:1.0537991142755685\n",
      "train loss:1.0006295930985656\n",
      "train loss:1.0574126169429923\n",
      "train loss:0.9714931374967829\n",
      "train loss:0.8630220067980906\n",
      "train loss:0.9649632843286331\n",
      "train loss:0.9519210306323387\n",
      "train loss:1.0559361269333276\n",
      "train loss:0.9324214092453142\n",
      "train loss:0.8691400163032824\n",
      "train loss:0.9144558754543084\n",
      "train loss:0.8285082624679057\n",
      "train loss:0.9540343881330449\n",
      "train loss:1.0378477140381457\n",
      "train loss:0.9692049173407981\n",
      "train loss:0.9261687995975726\n",
      "train loss:0.8504547862739044\n",
      "train loss:0.9780032161713814\n",
      "train loss:0.9165653630322569\n",
      "train loss:0.9883797574946978\n",
      "train loss:0.8722424647354906\n",
      "train loss:0.9465522077710886\n",
      "train loss:1.074511685386685\n",
      "train loss:1.040823515312105\n",
      "train loss:0.8629293069852164\n",
      "train loss:0.9172275335955766\n",
      "train loss:0.8620020904431029\n",
      "train loss:0.9557644377306755\n",
      "train loss:0.9588162729423728\n",
      "train loss:1.0718922985842922\n",
      "train loss:0.8742054187516187\n",
      "train loss:1.0330591708968893\n",
      "train loss:1.0426950524831025\n",
      "train loss:0.9589965401709261\n",
      "train loss:0.958802701561877\n",
      "train loss:0.9682093904156643\n",
      "train loss:1.0193028401994553\n",
      "train loss:0.8695407255830616\n",
      "train loss:0.7687607773227705\n",
      "train loss:0.8757745355088515\n",
      "train loss:1.0162423105514\n",
      "train loss:0.9517106054286117\n",
      "train loss:0.753966396470312\n",
      "train loss:0.8996423698796892\n",
      "train loss:0.999469197932672\n",
      "train loss:0.9008364441807848\n",
      "train loss:0.8785001907098677\n",
      "train loss:0.9584481874019484\n",
      "train loss:0.898473314663744\n",
      "train loss:1.0158161602037656\n",
      "train loss:0.844558887461607\n",
      "train loss:1.1495266268434496\n",
      "train loss:0.786848552988703\n",
      "train loss:0.7788110483428328\n",
      "train loss:0.9460569355782638\n",
      "train loss:0.8001433692536557\n",
      "train loss:1.0140797952272862\n",
      "train loss:1.021423615398055\n",
      "train loss:0.7077875663967117\n",
      "train loss:1.1270612474980006\n",
      "train loss:1.0060322026695583\n",
      "train loss:1.0081270448686042\n",
      "train loss:0.9635488522674253\n",
      "train loss:0.9145062808782746\n",
      "train loss:0.8343559683881862\n",
      "train loss:0.739621265480374\n",
      "train loss:0.9405337072484349\n",
      "train loss:0.9003372422438793\n",
      "train loss:1.0470153076018391\n",
      "train loss:0.709969433946764\n",
      "train loss:0.8494926863155043\n",
      "train loss:0.742017988092888\n",
      "train loss:0.9940998637339213\n",
      "train loss:0.8251286721936302\n",
      "train loss:0.9058303687105412\n",
      "train loss:0.9147325352644926\n",
      "train loss:0.996817996148136\n",
      "train loss:1.044915714973884\n",
      "train loss:0.9195103561641992\n",
      "train loss:0.9859754032954439\n",
      "train loss:0.8758409184018842\n",
      "train loss:0.9877851278313511\n",
      "train loss:0.8359148829911828\n",
      "train loss:0.8473686233072351\n",
      "train loss:0.9333517861924414\n",
      "train loss:0.7737032856677659\n",
      "train loss:0.9292718239957601\n",
      "train loss:1.0507212307154403\n",
      "train loss:1.0249165672327873\n",
      "train loss:0.9405555095855942\n",
      "train loss:0.8919661451900969\n",
      "train loss:0.9899640720385859\n",
      "train loss:0.8465550841789495\n",
      "train loss:0.8043753873101442\n",
      "train loss:0.9112477357357764\n",
      "train loss:0.9675529788939774\n",
      "train loss:1.0195830530050736\n",
      "train loss:0.8670737428078655\n",
      "train loss:1.028505061920858\n",
      "train loss:0.950704480712968\n",
      "train loss:0.8719685333975181\n",
      "train loss:0.9316949006724045\n",
      "train loss:1.0597613695102073\n",
      "train loss:0.9973096201398737\n",
      "train loss:0.9649231239915256\n",
      "train loss:0.9242560403837345\n",
      "train loss:0.9241635363223116\n",
      "train loss:1.019540157815777\n",
      "train loss:0.8526931515386497\n",
      "train loss:0.891077005141343\n",
      "train loss:0.8969866627424691\n",
      "train loss:1.0267073099707589\n",
      "train loss:0.9154039079011572\n",
      "train loss:1.0745725193225164\n",
      "train loss:0.9688533142269918\n",
      "train loss:1.0923547939466578\n",
      "train loss:0.8020406628615706\n",
      "train loss:0.8859598574977635\n",
      "train loss:1.0585788271762824\n",
      "train loss:1.0387410823223113\n",
      "train loss:0.8588042030615038\n",
      "train loss:0.921790383507123\n",
      "train loss:1.0297170490292396\n",
      "train loss:1.033063736597628\n",
      "train loss:0.9507908834106331\n",
      "train loss:1.0282878972763414\n",
      "train loss:0.8385785040000274\n",
      "train loss:0.9851520846659451\n",
      "train loss:0.9736313207312104\n",
      "train loss:1.042356110566339\n",
      "train loss:0.9170870121326853\n",
      "train loss:1.0263778595094624\n",
      "train loss:1.0466017065526518\n",
      "train loss:0.8831354326834722\n",
      "train loss:1.1590210671983983\n",
      "train loss:1.027338663985464\n",
      "train loss:0.8638948368681421\n",
      "train loss:0.7902981177935817\n",
      "train loss:0.8539346074610893\n",
      "train loss:1.1954186663553368\n",
      "train loss:0.9725477226988839\n",
      "train loss:0.8213937766357562\n",
      "train loss:0.9951914204972487\n",
      "train loss:1.0868182889730884\n",
      "train loss:0.9596307404568879\n",
      "train loss:1.0721347838085904\n",
      "train loss:0.9935034441892862\n",
      "train loss:0.9260417365693553\n",
      "train loss:0.8135822955832385\n",
      "train loss:1.025018148910725\n",
      "train loss:0.9573312896894828\n",
      "train loss:1.0013881628630825\n",
      "train loss:0.9451758893866345\n",
      "train loss:0.9443937328569754\n",
      "train loss:1.0614389203133545\n",
      "train loss:0.9876696709841055\n",
      "train loss:0.9680661550639766\n",
      "train loss:0.936110016851334\n",
      "train loss:0.7819797394148255\n",
      "train loss:1.0207928825860915\n",
      "train loss:0.9384148876854286\n",
      "train loss:1.1029243028134992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8266472169839051\n",
      "train loss:0.8893880905586202\n",
      "train loss:0.9235173079301036\n",
      "train loss:0.9278575918598811\n",
      "train loss:0.8461112566214216\n",
      "train loss:1.0005524516076085\n",
      "train loss:1.001274829404091\n",
      "train loss:0.9758273312641356\n",
      "train loss:0.8698816344319629\n",
      "train loss:1.1115364171205382\n",
      "train loss:0.9082378051285798\n",
      "train loss:1.0814704190576299\n",
      "train loss:0.8652242911474688\n",
      "train loss:1.0932758210555549\n",
      "train loss:1.0221198186502922\n",
      "train loss:0.9377571074732205\n",
      "train loss:0.9257160887089101\n",
      "train loss:0.79383874529723\n",
      "train loss:0.8597116411455259\n",
      "train loss:0.9900778139093752\n",
      "train loss:0.8977180172921829\n",
      "train loss:0.9961460482200102\n",
      "train loss:0.9778949940240306\n",
      "train loss:0.9143835746418287\n",
      "train loss:0.9419411876548922\n",
      "train loss:0.9323239840448081\n",
      "train loss:0.9451327905393101\n",
      "train loss:0.8653025387488887\n",
      "train loss:0.9248195140723816\n",
      "train loss:0.9858150219699788\n",
      "train loss:0.9539342540599463\n",
      "train loss:0.8609862751753582\n",
      "train loss:0.8252808015696199\n",
      "train loss:0.7320183626002575\n",
      "train loss:1.0168261770504798\n",
      "train loss:0.7064329393154098\n",
      "train loss:0.7569519977171977\n",
      "train loss:0.8656616849567562\n",
      "train loss:1.0036781757673163\n",
      "train loss:0.9080984920393784\n",
      "train loss:0.9197303252562122\n",
      "train loss:0.8589750129537547\n",
      "train loss:1.0630229999678995\n",
      "train loss:1.0066929618411102\n",
      "train loss:0.9094455304497151\n",
      "train loss:0.9479937922540769\n",
      "train loss:0.9919329752698934\n",
      "train loss:0.9885045923859511\n",
      "train loss:0.8106862747347522\n",
      "train loss:0.8982998506366574\n",
      "train loss:0.8680173795913682\n",
      "train loss:1.0953890702537767\n",
      "train loss:0.9275304060405599\n",
      "train loss:0.9382178953608528\n",
      "train loss:0.8367534764223911\n",
      "train loss:0.9462106778345583\n",
      "train loss:0.9326004518934228\n",
      "train loss:1.0331168134853543\n",
      "train loss:1.1728174766300048\n",
      "train loss:1.2176762738855613\n",
      "train loss:1.0830056370575714\n",
      "train loss:0.9962872599435353\n",
      "train loss:0.8524130038834753\n",
      "train loss:0.9799626994541552\n",
      "train loss:0.9142905106372936\n",
      "train loss:0.914518961458175\n",
      "train loss:0.9825236367547124\n",
      "train loss:0.8271220635524914\n",
      "train loss:0.9453669460887036\n",
      "train loss:0.8532763575085337\n",
      "train loss:1.0016007426470295\n",
      "train loss:1.0592267718297774\n",
      "train loss:0.873667118537913\n",
      "train loss:0.9211926399525051\n",
      "train loss:0.9342543422351831\n",
      "train loss:0.9263596707059211\n",
      "train loss:0.871994737547665\n",
      "train loss:0.7909181771199166\n",
      "train loss:0.9028193386100801\n",
      "train loss:1.0084309638780473\n",
      "train loss:1.0553404278770209\n",
      "train loss:0.8643680176854751\n",
      "train loss:0.9491567382479762\n",
      "train loss:0.8980012676865754\n",
      "train loss:0.8648244929283035\n",
      "train loss:0.929134413414296\n",
      "train loss:0.8471061484538123\n",
      "train loss:0.8105839390706021\n",
      "train loss:0.9017910547070194\n",
      "train loss:0.913166395767326\n",
      "train loss:0.9761521416961362\n",
      "train loss:1.0489322095144433\n",
      "train loss:0.9840456550370692\n",
      "train loss:1.0593449871516147\n",
      "train loss:0.9527290687218446\n",
      "train loss:1.2038804535712158\n",
      "train loss:0.7576683194555838\n",
      "train loss:0.7598593485716701\n",
      "train loss:0.9171918798385493\n",
      "train loss:0.735863234581492\n",
      "train loss:0.8151605900027913\n",
      "train loss:1.002377425338133\n",
      "train loss:0.9518191211273813\n",
      "train loss:0.8907829932567073\n",
      "train loss:0.9079726762889494\n",
      "train loss:0.9269208861461599\n",
      "train loss:1.217162144905582\n",
      "train loss:0.8616796513896658\n",
      "train loss:0.8545915463290175\n",
      "train loss:1.1106514074251626\n",
      "train loss:0.6806850497585109\n",
      "train loss:1.152680976015188\n",
      "train loss:0.8719466151039886\n",
      "train loss:0.9896230540782\n",
      "train loss:1.0402808670925163\n",
      "train loss:1.0102711814419332\n",
      "train loss:1.0543440220110307\n",
      "train loss:1.0688006212295291\n",
      "train loss:0.9974897776861528\n",
      "train loss:0.9042027931298946\n",
      "train loss:1.2325269363406084\n",
      "train loss:0.891454934763716\n",
      "train loss:0.8912369965496684\n",
      "train loss:0.799913129944309\n",
      "train loss:0.9770797221786672\n",
      "train loss:0.804194030966366\n",
      "train loss:0.963025412114266\n",
      "train loss:0.855207697774774\n",
      "train loss:0.795815447973132\n",
      "train loss:1.0352289626234494\n",
      "train loss:0.9338471880475677\n",
      "train loss:0.7586423219975632\n",
      "train loss:0.8567525071071054\n",
      "train loss:0.895165130761348\n",
      "train loss:0.9679220895894051\n",
      "train loss:1.0084955091337615\n",
      "train loss:1.2712402922599373\n",
      "train loss:0.9322277610961857\n",
      "train loss:0.8696587641366574\n",
      "train loss:1.0806232472101214\n",
      "train loss:0.8785839233113145\n",
      "train loss:0.743542396450996\n",
      "train loss:0.954950843861568\n",
      "train loss:1.0151437603172044\n",
      "train loss:0.8022374499209319\n",
      "train loss:0.8577387152124996\n",
      "train loss:0.8537943985172768\n",
      "train loss:0.9694835172449023\n",
      "train loss:0.9053597903081713\n",
      "train loss:1.025378469671081\n",
      "train loss:0.9602952609431102\n",
      "train loss:0.9087666501018267\n",
      "train loss:1.01337693433739\n",
      "train loss:0.7404437451977408\n",
      "train loss:1.0133316377095591\n",
      "train loss:1.09022550534776\n",
      "train loss:0.9694198268035938\n",
      "train loss:1.0276275256932519\n",
      "train loss:0.8547131443091289\n",
      "train loss:0.8135183073829885\n",
      "train loss:0.9319084000676626\n",
      "train loss:0.8806056915392019\n",
      "train loss:0.8828425937375397\n",
      "train loss:0.8353555997734224\n",
      "train loss:1.0056876033929643\n",
      "train loss:0.8331312754357905\n",
      "train loss:0.8960322186805025\n",
      "train loss:0.7116615898432683\n",
      "train loss:1.0367580988973046\n",
      "train loss:1.0391898565190776\n",
      "train loss:1.1125798704993066\n",
      "train loss:0.9951133575343301\n",
      "train loss:0.9542838459305316\n",
      "train loss:0.888810225947869\n",
      "train loss:1.036857587587003\n",
      "train loss:0.8892519110122257\n",
      "train loss:0.96834047886823\n",
      "train loss:0.6657286626388358\n",
      "train loss:0.8795629654151474\n",
      "train loss:0.9526650051121359\n",
      "train loss:0.9654774445798053\n",
      "train loss:0.9100021656847204\n",
      "train loss:1.0482583369350573\n",
      "train loss:1.019214169174967\n",
      "train loss:0.9453268418813263\n",
      "train loss:0.9875319793739838\n",
      "train loss:1.0337139234896617\n",
      "train loss:0.8915125152178603\n",
      "train loss:0.8467690290102163\n",
      "train loss:1.0249239474479712\n",
      "train loss:1.0398446224167688\n",
      "train loss:0.8417453129834621\n",
      "train loss:0.9516640085959751\n",
      "train loss:0.8602318924249811\n",
      "train loss:0.8610393122987563\n",
      "train loss:0.982274518924521\n",
      "train loss:0.9133569674603242\n",
      "train loss:0.8651282116418244\n",
      "train loss:0.7980772755940645\n",
      "train loss:0.9982100811824804\n",
      "train loss:1.0938997851399395\n",
      "train loss:0.8796104204614362\n",
      "train loss:0.9641134829222453\n",
      "train loss:1.0621491777808687\n",
      "train loss:0.898960964549242\n",
      "train loss:1.0021752522057792\n",
      "train loss:0.952111914197708\n",
      "train loss:0.906987795670353\n",
      "train loss:0.8702155872812906\n",
      "train loss:0.8755777433850623\n",
      "train loss:0.9546383125994609\n",
      "train loss:0.8378966164577244\n",
      "train loss:1.0953869204979205\n",
      "train loss:0.9687132489569624\n",
      "train loss:0.8813599408963717\n",
      "train loss:1.0278230607096706\n",
      "train loss:0.9584180643674793\n",
      "train loss:1.0213118872233011\n",
      "train loss:0.9150161068866296\n",
      "train loss:1.0733979386691614\n",
      "train loss:1.1156285719452463\n",
      "train loss:0.8101110202390912\n",
      "train loss:0.8494933758455412\n",
      "train loss:0.9222953395830011\n",
      "train loss:1.020459845494323\n",
      "train loss:1.1234037285337508\n",
      "train loss:1.0806752654155545\n",
      "train loss:0.78223878706384\n",
      "train loss:0.911532488391895\n",
      "train loss:0.8771907943106\n",
      "train loss:0.9432086559945436\n",
      "train loss:1.0131453788106817\n",
      "train loss:1.0125771860283712\n",
      "train loss:0.8738450505991102\n",
      "train loss:0.9277933292642773\n",
      "train loss:0.9077718086867208\n",
      "train loss:0.876649704954169\n",
      "train loss:1.0256974454255945\n",
      "train loss:1.0142614013822417\n",
      "train loss:0.8771726221584113\n",
      "train loss:0.8547141086567845\n",
      "train loss:0.8752047313443928\n",
      "train loss:0.9649620638496158\n",
      "train loss:1.039878264184926\n",
      "train loss:1.0198449800570142\n",
      "train loss:0.7909511735347208\n",
      "train loss:0.8860403782113415\n",
      "train loss:1.0383267847064284\n",
      "train loss:0.7786608892799544\n",
      "train loss:0.9322506792219575\n",
      "train loss:0.9028879263102348\n",
      "train loss:0.985723610704047\n",
      "train loss:0.9502606078262236\n",
      "train loss:0.8139855528437253\n",
      "train loss:0.8384169370827466\n",
      "train loss:0.7105456981754459\n",
      "train loss:0.9735096549829367\n",
      "train loss:0.8840102640374351\n",
      "train loss:0.9113957790990638\n",
      "train loss:0.886266159852163\n",
      "train loss:0.9457715832768033\n",
      "train loss:1.0421876730008441\n",
      "train loss:0.9804763387617262\n",
      "train loss:0.8583326420785687\n",
      "train loss:0.9435290076499541\n",
      "train loss:1.0831821396486587\n",
      "train loss:0.7666931219219147\n",
      "train loss:0.9056281215544838\n",
      "train loss:0.8731170642328387\n",
      "train loss:1.0140612926959214\n",
      "train loss:0.9728418573365576\n",
      "train loss:1.0636717569416252\n",
      "train loss:1.0181022282911296\n",
      "train loss:0.8515395195840272\n",
      "train loss:0.7495217073176179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.024580262135142\n",
      "train loss:1.0014404635629623\n",
      "train loss:1.040681689409217\n",
      "train loss:0.9765728888677482\n",
      "train loss:0.7257536933682995\n",
      "train loss:0.8955816677179911\n",
      "train loss:0.9359007647721259\n",
      "train loss:0.9911847337559059\n",
      "train loss:0.7587641607424986\n",
      "train loss:0.9897335295993851\n",
      "train loss:0.9039260253732629\n",
      "train loss:0.8915017961404379\n",
      "train loss:1.02677345141094\n",
      "train loss:0.9598788667316743\n",
      "train loss:0.9439202203052391\n",
      "train loss:0.8542776829999781\n",
      "train loss:0.8660480112373378\n",
      "train loss:0.9851956494530907\n",
      "train loss:0.9749664998857872\n",
      "train loss:1.0110764880581413\n",
      "train loss:0.9436248807648675\n",
      "train loss:1.0394761066664973\n",
      "train loss:0.8408748520943216\n",
      "train loss:0.9082189832015419\n",
      "train loss:1.0125079703003321\n",
      "train loss:0.9160022303595535\n",
      "train loss:1.0454618405337956\n",
      "train loss:0.8388196030911171\n",
      "train loss:1.1319089621596203\n",
      "train loss:0.8841078430420799\n",
      "train loss:0.7941254615748806\n",
      "train loss:0.855180575619599\n",
      "train loss:0.9088478439979211\n",
      "train loss:0.963027434290072\n",
      "train loss:0.794355098442989\n",
      "train loss:0.9653387498088156\n",
      "train loss:1.0469676601802467\n",
      "train loss:0.9696383519190701\n",
      "train loss:0.9514223366704002\n",
      "train loss:0.7267922270573912\n",
      "train loss:0.9212637883694001\n",
      "train loss:0.9331563523172267\n",
      "train loss:0.7855065241008936\n",
      "train loss:0.9044765179786302\n",
      "train loss:0.9965406488553334\n",
      "train loss:0.8662943595142494\n",
      "train loss:0.8828642346298063\n",
      "train loss:0.8834542282319308\n",
      "train loss:0.9393298532697847\n",
      "train loss:0.9943522466911884\n",
      "train loss:1.0297614827756836\n",
      "train loss:0.9909933350831188\n",
      "train loss:0.8513823587872372\n",
      "train loss:0.971303151196087\n",
      "train loss:0.8423251174506129\n",
      "train loss:0.9772109556950496\n",
      "train loss:1.0793072058483733\n",
      "train loss:0.9608981703341947\n",
      "train loss:0.9952433768997018\n",
      "train loss:1.0608885156837997\n",
      "train loss:0.9782409551915131\n",
      "train loss:1.0524328584309648\n",
      "train loss:0.8367283140233281\n",
      "train loss:1.1510998582877285\n",
      "train loss:0.7745856560895173\n",
      "train loss:0.9348668226214473\n",
      "train loss:0.9088240112597522\n",
      "train loss:0.8679129339434588\n",
      "train loss:0.7045176435564231\n",
      "train loss:0.8996945603538902\n",
      "train loss:0.8452149468086114\n",
      "train loss:0.9099012213597517\n",
      "train loss:0.8501532208878149\n",
      "train loss:0.8419646333939004\n",
      "train loss:0.9006964013009536\n",
      "train loss:0.7080635010234226\n",
      "train loss:0.8377568958187512\n",
      "train loss:0.8776498551031863\n",
      "train loss:1.051662653051781\n",
      "train loss:0.9119200864499328\n",
      "train loss:0.9557980204337482\n",
      "train loss:0.8510977170552096\n",
      "train loss:1.0040837907831506\n",
      "train loss:0.9420272442072707\n",
      "train loss:0.9597626916127879\n",
      "train loss:0.9554482214070613\n",
      "train loss:0.7204836503055811\n",
      "train loss:0.8210941932411764\n",
      "train loss:0.9955520166939296\n",
      "train loss:0.9277673273771893\n",
      "train loss:0.8503012582261594\n",
      "train loss:0.9007168753164934\n",
      "train loss:0.8590202943746966\n",
      "train loss:0.9787929253971334\n",
      "train loss:0.899047203010614\n",
      "train loss:1.137182904069635\n",
      "train loss:0.9402630663584921\n",
      "train loss:0.9005918072734247\n",
      "train loss:1.0664158269585045\n",
      "train loss:0.9995477546682509\n",
      "train loss:0.785899767900323\n",
      "train loss:0.8635737510398185\n",
      "train loss:0.8086130228054942\n",
      "train loss:1.1019429177355262\n",
      "train loss:0.8358882562453079\n",
      "train loss:0.9681802033492035\n",
      "train loss:0.761657543624628\n",
      "train loss:1.0466134720442588\n",
      "train loss:0.9977961531266569\n",
      "train loss:0.9554409997666902\n",
      "=== epoch:14, train acc:0.988, test acc:0.992 ===\n",
      "train loss:0.8910254948082702\n",
      "train loss:0.9121303393553908\n",
      "train loss:1.028638373039283\n",
      "train loss:0.934076418642396\n",
      "train loss:1.053088542052732\n",
      "train loss:0.9819669124526975\n",
      "train loss:0.8433441150095089\n",
      "train loss:1.065546769897136\n",
      "train loss:0.9190001480010218\n",
      "train loss:0.786380546426619\n",
      "train loss:0.9659681105813941\n",
      "train loss:0.8770166905241565\n",
      "train loss:0.8426710780787461\n",
      "train loss:0.9240977374576999\n",
      "train loss:0.962881578304433\n",
      "train loss:0.8403747137232342\n",
      "train loss:0.7310766898680048\n",
      "train loss:0.9888648421981783\n",
      "train loss:0.8856767283625214\n",
      "train loss:0.993273195570809\n",
      "train loss:0.7718334637945456\n",
      "train loss:0.993601863657825\n",
      "train loss:0.9800733439177339\n",
      "train loss:0.9280923036501791\n",
      "train loss:0.9871156310014761\n",
      "train loss:0.7950613067968421\n",
      "train loss:0.8343285339514357\n",
      "train loss:0.8138047590483647\n",
      "train loss:1.0780033800389195\n",
      "train loss:0.96034894671142\n",
      "train loss:0.8647688136720452\n",
      "train loss:1.162703937438948\n",
      "train loss:0.9696379037537513\n",
      "train loss:0.8467939720703845\n",
      "train loss:1.021058577835752\n",
      "train loss:0.8768385539799637\n",
      "train loss:0.9297841772724952\n",
      "train loss:0.9519993573390402\n",
      "train loss:0.8743123149881263\n",
      "train loss:0.7034361933813051\n",
      "train loss:1.0061050871551733\n",
      "train loss:0.951541029150009\n",
      "train loss:1.0688743148761264\n",
      "train loss:1.0584400242225918\n",
      "train loss:0.9266916178933964\n",
      "train loss:0.7196757097036931\n",
      "train loss:0.958225937578656\n",
      "train loss:0.736976152238832\n",
      "train loss:1.060960664720607\n",
      "train loss:0.9350853047212287\n",
      "train loss:0.9177955133887042\n",
      "train loss:0.9097598825275804\n",
      "train loss:0.8459323919341231\n",
      "train loss:1.0172371001672738\n",
      "train loss:0.9256469119207845\n",
      "train loss:0.9016560855928621\n",
      "train loss:0.984829442892379\n",
      "train loss:0.999543106991081\n",
      "train loss:1.0016618261408843\n",
      "train loss:0.9505452075551203\n",
      "train loss:0.9206760736879022\n",
      "train loss:0.8230810934848307\n",
      "train loss:0.9896727165856393\n",
      "train loss:0.8712429371832492\n",
      "train loss:1.010969442167667\n",
      "train loss:0.9421144873191064\n",
      "train loss:1.0257109900868715\n",
      "train loss:0.979023134705577\n",
      "train loss:0.967988911273807\n",
      "train loss:0.9377999838360287\n",
      "train loss:0.76405230036906\n",
      "train loss:1.017321821538562\n",
      "train loss:0.815243755004075\n",
      "train loss:0.9889182957159066\n",
      "train loss:1.1045466806175224\n",
      "train loss:0.8089825991767162\n",
      "train loss:0.9884235695734362\n",
      "train loss:0.7799670943169958\n",
      "train loss:0.858107736208676\n",
      "train loss:0.9650230362335399\n",
      "train loss:0.8122473344917924\n",
      "train loss:1.0631189748387104\n",
      "train loss:0.8760091080438974\n",
      "train loss:0.9793096562367528\n",
      "train loss:0.9267220114502633\n",
      "train loss:0.9024121268878854\n",
      "train loss:1.0259855739160855\n",
      "train loss:0.7912523113605943\n",
      "train loss:0.8969874818224564\n",
      "train loss:0.9346317620077624\n",
      "train loss:0.8649836162977355\n",
      "train loss:1.197760083613079\n",
      "train loss:0.827442080399162\n",
      "train loss:0.9459039528017839\n",
      "train loss:0.913043249060684\n",
      "train loss:0.988751478382207\n",
      "train loss:0.9174195002810044\n",
      "train loss:0.9285527797468454\n",
      "train loss:0.9556724322942313\n",
      "train loss:0.9597718393130407\n",
      "train loss:0.9901429587642931\n",
      "train loss:1.0105125780831508\n",
      "train loss:1.0279774728510518\n",
      "train loss:1.0716707176968148\n",
      "train loss:1.02136700016837\n",
      "train loss:0.7539063024482799\n",
      "train loss:0.8439848565791468\n",
      "train loss:1.054240293513581\n",
      "train loss:0.8648006760916419\n",
      "train loss:1.0410686912426848\n",
      "train loss:0.9785596410654303\n",
      "train loss:1.18169358486336\n",
      "train loss:0.8850733857680253\n",
      "train loss:1.184873761905275\n",
      "train loss:0.8774157284962075\n",
      "train loss:0.9185206418368792\n",
      "train loss:0.9903166163668738\n",
      "train loss:0.9777404756318799\n",
      "train loss:0.8922965049466349\n",
      "train loss:0.8573846015775483\n",
      "train loss:0.894936090985661\n",
      "train loss:0.8140919949160306\n",
      "train loss:1.011342373493187\n",
      "train loss:1.0046776966358975\n",
      "train loss:1.0584401496127103\n",
      "train loss:1.0056663071353937\n",
      "train loss:0.9408984354445535\n",
      "train loss:0.9475336794556043\n",
      "train loss:0.9978109622491336\n",
      "train loss:0.6247211287381585\n",
      "train loss:0.9681816447841114\n",
      "train loss:1.0417410648495826\n",
      "train loss:1.0222507495993094\n",
      "train loss:0.875653366641308\n",
      "train loss:0.7252483923325949\n",
      "train loss:0.8151921742232688\n",
      "train loss:1.0311762719532218\n",
      "train loss:1.0761427704275197\n",
      "train loss:0.804946113968799\n",
      "train loss:0.9562724367708343\n",
      "train loss:0.8059634257109327\n",
      "train loss:0.8850382644842437\n",
      "train loss:0.9373133780304695\n",
      "train loss:0.7676729503191236\n",
      "train loss:0.7884944656301447\n",
      "train loss:1.0480357799035587\n",
      "train loss:0.8467019660860039\n",
      "train loss:1.0057579284837153\n",
      "train loss:1.1347372896805457\n",
      "train loss:0.9858822078893187\n",
      "train loss:1.0072743048984996\n",
      "train loss:0.8749237558448081\n",
      "train loss:0.9024399065331946\n",
      "train loss:0.9485485620668811\n",
      "train loss:0.9262334048686077\n",
      "train loss:0.983496037502251\n",
      "train loss:0.7790702985423994\n",
      "train loss:0.9335155052759225\n",
      "train loss:1.0831462136845216\n",
      "train loss:1.0179550635909436\n",
      "train loss:0.8466385532249906\n",
      "train loss:0.9839441179700817\n",
      "train loss:0.9935919119278996\n",
      "train loss:1.0040982224987431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8957373200015055\n",
      "train loss:0.8303850143677028\n",
      "train loss:0.9375136020752372\n",
      "train loss:0.9323699793862847\n",
      "train loss:0.8813006916823702\n",
      "train loss:0.8423374388432723\n",
      "train loss:0.8582837865328357\n",
      "train loss:0.962925146511235\n",
      "train loss:0.9746991055820037\n",
      "train loss:1.005366336200195\n",
      "train loss:0.9131931887728365\n",
      "train loss:1.2085872555957022\n",
      "train loss:0.9171098217718442\n",
      "train loss:0.8782953698577518\n",
      "train loss:1.0861435088529539\n",
      "train loss:0.8755070537917966\n",
      "train loss:1.1325685285863651\n",
      "train loss:0.7935262743673606\n",
      "train loss:1.0490703890094828\n",
      "train loss:0.7633086520394633\n",
      "train loss:0.8920053160210739\n",
      "train loss:0.9585598986804623\n",
      "train loss:0.8638077828584501\n",
      "train loss:0.767458096436822\n",
      "train loss:0.9306638023932382\n",
      "train loss:1.0512953333688055\n",
      "train loss:0.8929473563071179\n",
      "train loss:0.8210684724945119\n",
      "train loss:0.8505763603723568\n",
      "train loss:0.9726743332200348\n",
      "train loss:0.9159860303568927\n",
      "train loss:0.8953728427528883\n",
      "train loss:0.9808242998170874\n",
      "train loss:0.8727135418602593\n",
      "train loss:0.9756718730705174\n",
      "train loss:1.0702915764045071\n",
      "train loss:1.071811367853737\n",
      "train loss:0.9308478355888203\n",
      "train loss:0.7303997895707002\n",
      "train loss:0.9126195993780232\n",
      "train loss:0.9122324141301406\n",
      "train loss:1.08264711902983\n",
      "train loss:0.9791378589415477\n",
      "train loss:0.9914723525204867\n",
      "train loss:0.8663647069786513\n",
      "train loss:0.8843113131836199\n",
      "train loss:0.8816238970772671\n",
      "train loss:1.0938109959200717\n",
      "train loss:0.95509035610632\n",
      "train loss:1.1291803128073739\n",
      "train loss:0.9263841427146784\n",
      "train loss:0.9901002529011257\n",
      "train loss:1.0491034247011992\n",
      "train loss:0.9760425417670662\n",
      "train loss:1.046023555729121\n",
      "train loss:0.847661999417886\n",
      "train loss:0.8882998971072458\n",
      "train loss:0.8294277266780066\n",
      "train loss:0.9251523103315332\n",
      "train loss:1.0731901831723407\n",
      "train loss:1.0046528846975062\n",
      "train loss:0.8926723575081452\n",
      "train loss:0.9459441348992107\n",
      "train loss:0.8729388302132883\n",
      "train loss:0.7145305035950176\n",
      "train loss:0.9620480204783425\n",
      "train loss:0.855864042925445\n",
      "train loss:0.8307640993763138\n",
      "train loss:0.7867274908916932\n",
      "train loss:0.9544869483645816\n",
      "train loss:0.8480838030296252\n",
      "train loss:0.8780166290585717\n",
      "train loss:0.9825616299572814\n",
      "train loss:0.7172249707766531\n",
      "train loss:1.0003044708931264\n",
      "train loss:0.8373282829413325\n",
      "train loss:0.9008653628567567\n",
      "train loss:0.8161781624665977\n",
      "train loss:0.8640027473636949\n",
      "train loss:0.905257874713822\n",
      "train loss:1.0485518952368134\n",
      "train loss:0.9614659868688107\n",
      "train loss:0.8585969927516127\n",
      "train loss:0.8939672855876674\n",
      "train loss:1.0574625119669836\n",
      "train loss:0.946605130510285\n",
      "train loss:0.9367359884899937\n",
      "train loss:0.9134408641414206\n",
      "train loss:0.8380269542693821\n",
      "train loss:0.8675783736506678\n",
      "train loss:1.0031895472743164\n",
      "train loss:0.9639849247487904\n",
      "train loss:0.9781563569182397\n",
      "train loss:0.8302416889378579\n",
      "train loss:1.0590146688127098\n",
      "train loss:1.0632369512174287\n",
      "train loss:0.9125413552555618\n",
      "train loss:1.1013356286886409\n",
      "train loss:1.0544553678933823\n",
      "train loss:0.8658802802865047\n",
      "train loss:0.933997276857181\n",
      "train loss:0.9486922280535779\n",
      "train loss:0.9048652940311834\n",
      "train loss:0.7070730471746153\n",
      "train loss:0.8855258694819514\n",
      "train loss:0.8995257459608288\n",
      "train loss:1.0674656059984982\n",
      "train loss:0.8702202291099287\n",
      "train loss:1.1052573221317257\n",
      "train loss:0.9919407509060116\n",
      "train loss:0.8588642717586326\n",
      "train loss:0.8137184187133198\n",
      "train loss:1.0124593410132565\n",
      "train loss:0.8903429479510041\n",
      "train loss:0.9444662779712825\n",
      "train loss:0.8215272443820908\n",
      "train loss:0.8507474654103838\n",
      "train loss:0.8514715614227611\n",
      "train loss:0.8210924535089817\n",
      "train loss:0.895921952647693\n",
      "train loss:1.0912615256914855\n",
      "train loss:0.9581367224370037\n",
      "train loss:0.8739872669542246\n",
      "train loss:0.8132215594835738\n",
      "train loss:0.8981367300086912\n",
      "train loss:1.0884106595418819\n",
      "train loss:0.9530186958918808\n",
      "train loss:0.9213650815903562\n",
      "train loss:0.7638507774123211\n",
      "train loss:0.8005868741662486\n",
      "train loss:0.9789567847305146\n",
      "train loss:0.7594378968579294\n",
      "train loss:0.8999853763098092\n",
      "train loss:1.1368399011615589\n",
      "train loss:0.8666351115974261\n",
      "train loss:1.085939466271913\n",
      "train loss:1.0614802098011797\n",
      "train loss:0.9669537394009464\n",
      "train loss:0.8904675659263819\n",
      "train loss:0.9658648465004525\n",
      "train loss:0.9651223643003651\n",
      "train loss:0.9176816679849753\n",
      "train loss:0.9697329745780375\n",
      "train loss:0.9309143938081499\n",
      "train loss:0.8909649125533484\n",
      "train loss:0.8430569906947691\n",
      "train loss:0.7580199151732255\n",
      "train loss:0.9061019905946082\n",
      "train loss:0.796114063404474\n",
      "train loss:0.8119716901481999\n",
      "train loss:0.7748152028509118\n",
      "train loss:0.9311060451072141\n",
      "train loss:0.8043317516438493\n",
      "train loss:0.9073568551003823\n",
      "train loss:1.0163465999207943\n",
      "train loss:0.896515700735667\n",
      "train loss:1.0876397071842445\n",
      "train loss:0.8459711372831339\n",
      "train loss:0.9191563792517949\n",
      "train loss:0.7879039387392893\n",
      "train loss:0.810899566174805\n",
      "train loss:0.8994568038950317\n",
      "train loss:0.8562648151855413\n",
      "train loss:0.7350386323212947\n",
      "train loss:0.8333907393420273\n",
      "train loss:0.8678072325069904\n",
      "train loss:0.9356786923628937\n",
      "train loss:0.9293278273527228\n",
      "train loss:0.9124478221752567\n",
      "train loss:0.9597807739374552\n",
      "train loss:0.9824262320438447\n",
      "train loss:0.7626308990594218\n",
      "train loss:0.8070003212581072\n",
      "train loss:0.9701588928042761\n",
      "train loss:0.9021818440108589\n",
      "train loss:0.8789493322127738\n",
      "train loss:1.0063899332894923\n",
      "train loss:0.8829897840511377\n",
      "train loss:0.9194046966835652\n",
      "train loss:0.8847016307515677\n",
      "train loss:1.0293884195878398\n",
      "train loss:0.9251821302842776\n",
      "train loss:0.8873181683305821\n",
      "train loss:1.0619548423631415\n",
      "train loss:1.0007206361367187\n",
      "train loss:0.8967803953034763\n",
      "train loss:0.8320243746251136\n",
      "train loss:0.8075466146493211\n",
      "train loss:0.9119703555793426\n",
      "train loss:0.9760313438390226\n",
      "train loss:0.8888458521896324\n",
      "train loss:0.8476793224912136\n",
      "train loss:1.088983847437385\n",
      "train loss:1.104361848379842\n",
      "train loss:1.0162758652464636\n",
      "train loss:0.9554235806829867\n",
      "train loss:0.9539124039971242\n",
      "train loss:0.9242193010701587\n",
      "train loss:0.9065902704337948\n",
      "train loss:1.0345667675477757\n",
      "train loss:0.8104609838476386\n",
      "train loss:0.8560497901693697\n",
      "train loss:1.0332690557975914\n",
      "train loss:1.006576672573263\n",
      "train loss:1.1019608153526037\n",
      "train loss:0.953075847187462\n",
      "train loss:0.822175426488826\n",
      "train loss:1.042575182209569\n",
      "train loss:0.8695410535105361\n",
      "train loss:0.8690240635973057\n",
      "train loss:0.9266038619519942\n",
      "train loss:1.120546691052507\n",
      "train loss:0.6995467724052747\n",
      "train loss:0.7853669450824273\n",
      "train loss:0.8803375410595897\n",
      "train loss:0.9455290936975956\n",
      "train loss:1.125524535941886\n",
      "train loss:0.9510569301993766\n",
      "train loss:1.0185823736331339\n",
      "train loss:0.9170131764403904\n",
      "train loss:0.8202590476125651\n",
      "train loss:1.0313810833520776\n",
      "train loss:0.8846412704650206\n",
      "train loss:0.7678770706190463\n",
      "train loss:0.8971618043789337\n",
      "train loss:0.8635836541001458\n",
      "train loss:0.8689926816020255\n",
      "train loss:1.008302676708249\n",
      "train loss:1.0530711954958913\n",
      "train loss:0.96970167091846\n",
      "train loss:0.9907883287610456\n",
      "train loss:0.7673618757877796\n",
      "train loss:0.8632563116153675\n",
      "train loss:0.7652290795691004\n",
      "train loss:1.0549208561026686\n",
      "train loss:1.0196172296283408\n",
      "train loss:0.9416756957958661\n",
      "train loss:0.8650079624535071\n",
      "train loss:1.0296783263735343\n",
      "train loss:0.8559529981292804\n",
      "train loss:0.8742774207102539\n",
      "train loss:0.9953776669207247\n",
      "train loss:1.2170173780246547\n",
      "train loss:0.733461177141635\n",
      "train loss:0.8450126058033125\n",
      "train loss:0.9596051799432\n",
      "train loss:0.8495269307541652\n",
      "train loss:0.7837657410954325\n",
      "train loss:0.9489898001372293\n",
      "train loss:0.9720477156747274\n",
      "train loss:0.8383377015353152\n",
      "train loss:1.0018141783580086\n",
      "train loss:1.003248926557924\n",
      "train loss:0.8123663540418908\n",
      "train loss:0.7324714174782083\n",
      "train loss:0.9726586711877602\n",
      "train loss:0.8496412249596935\n",
      "train loss:0.8893862426464695\n",
      "train loss:0.9631252672405801\n",
      "train loss:0.9347948593516999\n",
      "train loss:1.1280107563068291\n",
      "train loss:1.124701073105589\n",
      "train loss:0.9310731538178182\n",
      "train loss:0.9070679984284388\n",
      "train loss:1.147975643161406\n",
      "train loss:1.1980744498660472\n",
      "train loss:0.9427472923067778\n",
      "train loss:0.8256395445711578\n",
      "train loss:0.9078235171423372\n",
      "train loss:0.9995722753788345\n",
      "train loss:0.8101861038211378\n",
      "train loss:0.7283186337467886\n",
      "train loss:1.0093314876025998\n",
      "train loss:0.8086377058962809\n",
      "train loss:1.0392625792807875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9777517852776815\n",
      "train loss:0.9543803117313532\n",
      "train loss:0.8834415844912715\n",
      "train loss:0.8224597174436823\n",
      "train loss:1.0491609727525435\n",
      "train loss:1.0077647677834431\n",
      "train loss:0.9533207079532608\n",
      "train loss:0.8249827095193356\n",
      "train loss:0.9053770856205293\n",
      "train loss:0.9404885280622763\n",
      "train loss:1.0371652478801527\n",
      "train loss:0.9709815654636091\n",
      "train loss:0.9156856384061265\n",
      "train loss:0.959504200168811\n",
      "train loss:1.0219463299483098\n",
      "train loss:0.9913903138351025\n",
      "train loss:0.8669609131496978\n",
      "train loss:0.8406965521333609\n",
      "train loss:0.8932070276758215\n",
      "train loss:0.828402382524759\n",
      "train loss:0.9835505398316987\n",
      "train loss:0.7789963808736605\n",
      "train loss:0.8900067480157999\n",
      "train loss:0.837156647393499\n",
      "train loss:0.8856989801199932\n",
      "train loss:0.8546068786651412\n",
      "train loss:0.8856020922103748\n",
      "train loss:1.053504707008407\n",
      "train loss:1.0198999277408423\n",
      "train loss:0.9058054251098226\n",
      "train loss:0.9229386892813513\n",
      "train loss:0.99990359668477\n",
      "train loss:0.9722584305673092\n",
      "train loss:0.9533856529645515\n",
      "train loss:0.9267582948782396\n",
      "train loss:0.9480647809055591\n",
      "train loss:0.8715258579279188\n",
      "train loss:1.0254232298804467\n",
      "train loss:1.0750455521643514\n",
      "train loss:0.9336447604536263\n",
      "train loss:1.0483784576617419\n",
      "train loss:0.875302551876148\n",
      "train loss:0.8514345415197764\n",
      "train loss:0.942805109262791\n",
      "train loss:0.9032039249339705\n",
      "train loss:0.8940057333329304\n",
      "train loss:0.7892221692315095\n",
      "train loss:1.0914747901231068\n",
      "train loss:1.0521292401796645\n",
      "train loss:0.8794930238495117\n",
      "train loss:0.9068256182411651\n",
      "train loss:0.8946123902392226\n",
      "train loss:0.9898416299888124\n",
      "train loss:1.0284505268204651\n",
      "train loss:0.9665797788089598\n",
      "train loss:0.937450821998477\n",
      "train loss:1.0026468042738126\n",
      "train loss:0.8184896512385305\n",
      "train loss:0.9320912505090301\n",
      "train loss:1.0031267442531087\n",
      "train loss:0.9425485636003027\n",
      "train loss:0.9204317714478896\n",
      "train loss:0.9305627164485323\n",
      "train loss:0.8134865095000375\n",
      "train loss:0.8436866012401144\n",
      "train loss:0.9772750759579732\n",
      "train loss:0.8562992489406502\n",
      "train loss:0.7633488362784684\n",
      "train loss:0.8752456327454035\n",
      "train loss:1.0148805878105198\n",
      "train loss:0.8568167248297567\n",
      "train loss:0.8374598152316165\n",
      "train loss:0.8053077053718327\n",
      "train loss:0.9389546666018286\n",
      "train loss:0.8766220486438948\n",
      "train loss:0.9792200406395891\n",
      "train loss:0.8626443723883267\n",
      "train loss:0.9057679313791285\n",
      "train loss:1.0633847363448603\n",
      "train loss:0.8516910497696276\n",
      "train loss:0.6772350387913942\n",
      "train loss:0.8558017362374939\n",
      "train loss:0.6489999858727991\n",
      "train loss:0.9791348425984009\n",
      "train loss:0.9800058755691846\n",
      "train loss:0.9521659761853222\n",
      "train loss:0.8770474247148288\n",
      "train loss:0.966688514557997\n",
      "train loss:0.9745288755200785\n",
      "train loss:0.9492183093535771\n",
      "train loss:0.9055609379662926\n",
      "train loss:1.089582236136215\n",
      "train loss:0.7783299512059934\n",
      "train loss:0.7092172513758251\n",
      "train loss:0.9532253041549099\n",
      "train loss:0.9842945772917663\n",
      "train loss:0.8707883330496006\n",
      "train loss:0.8837885656041605\n",
      "train loss:0.9394076416934339\n",
      "train loss:0.8017717502076473\n",
      "train loss:0.871868622630596\n",
      "train loss:0.9421556753992927\n",
      "train loss:0.9355525902526806\n",
      "train loss:0.9352960114808861\n",
      "train loss:0.9783102664134603\n",
      "train loss:0.9914861174765744\n",
      "train loss:0.8706343466424393\n",
      "train loss:0.9607532059191949\n",
      "train loss:0.8995590422216384\n",
      "train loss:0.8346383506964937\n",
      "train loss:0.8592160316653732\n",
      "train loss:1.015892217083635\n",
      "train loss:0.8960637784592096\n",
      "train loss:1.026883038824511\n",
      "train loss:0.929036526931251\n",
      "train loss:0.964003650525827\n",
      "train loss:0.8637178449675538\n",
      "train loss:0.8961440066504516\n",
      "train loss:1.0135534254972942\n",
      "train loss:1.0094408378411908\n",
      "train loss:0.8545853672117283\n",
      "train loss:0.9979098933160957\n",
      "train loss:1.1182794391905806\n",
      "train loss:0.7725674452265063\n",
      "train loss:0.8828431144627318\n",
      "train loss:0.995605704944896\n",
      "train loss:0.9842770804559443\n",
      "train loss:1.054732891828685\n",
      "train loss:1.021473971838658\n",
      "train loss:1.0157639631046813\n",
      "train loss:0.8602283660952448\n",
      "train loss:1.143997027508388\n",
      "train loss:0.8939477790524388\n",
      "train loss:0.9192936640034287\n",
      "train loss:1.0678114043498197\n",
      "train loss:0.8880153678382469\n",
      "train loss:0.9434777673660784\n",
      "train loss:0.789403650857875\n",
      "train loss:0.9698238359765006\n",
      "train loss:0.9451806770228557\n",
      "train loss:0.8941077679057097\n",
      "train loss:0.828506903084054\n",
      "train loss:1.179543781927439\n",
      "train loss:0.7483470572145515\n",
      "train loss:0.858349247068558\n",
      "train loss:1.0503545170561075\n",
      "train loss:0.8245166780459428\n",
      "train loss:0.8199466184512345\n",
      "train loss:0.871561094045449\n",
      "train loss:0.937593320580265\n",
      "train loss:1.1084098471711405\n",
      "train loss:0.7739832019101359\n",
      "train loss:0.996555037408668\n",
      "train loss:1.092996818918997\n",
      "train loss:0.8983877192127697\n",
      "train loss:0.7910332700809285\n",
      "train loss:0.8016110500940619\n",
      "train loss:0.9047963095592197\n",
      "train loss:0.8520964877225714\n",
      "train loss:0.8256609713886643\n",
      "train loss:0.9459209467093107\n",
      "=== epoch:15, train acc:0.987, test acc:0.989 ===\n",
      "train loss:0.9680635599759172\n",
      "train loss:0.7167633470894141\n",
      "train loss:0.9040665890729904\n",
      "train loss:1.0586439870739008\n",
      "train loss:0.9464200302427205\n",
      "train loss:0.8702390879892853\n",
      "train loss:1.1217716056367428\n",
      "train loss:0.8223784434538177\n",
      "train loss:0.950645658734732\n",
      "train loss:0.9291684744009681\n",
      "train loss:0.8144262631943678\n",
      "train loss:0.8679255097352516\n",
      "train loss:0.9054240486176117\n",
      "train loss:1.004238556699486\n",
      "train loss:0.902531950553304\n",
      "train loss:0.7934400845865561\n",
      "train loss:0.8264783349345258\n",
      "train loss:0.8795673126010223\n",
      "train loss:1.0758352202190522\n",
      "train loss:0.8729790264450155\n",
      "train loss:1.0326923781318045\n",
      "train loss:1.004324433614647\n",
      "train loss:0.9018492009069515\n",
      "train loss:0.8278214728577147\n",
      "train loss:0.7902407124498484\n",
      "train loss:0.808938363895915\n",
      "train loss:0.8615854171998018\n",
      "train loss:0.9323666429473834\n",
      "train loss:1.1831240168472539\n",
      "train loss:1.0331951952341403\n",
      "train loss:0.8017786529489528\n",
      "train loss:0.9522182070993779\n",
      "train loss:0.8475999574951254\n",
      "train loss:0.8487125354180216\n",
      "train loss:0.9341493380526539\n",
      "train loss:0.6267386141689576\n",
      "train loss:0.8572274535171138\n",
      "train loss:0.8704909820758668\n",
      "train loss:0.9269834183407348\n",
      "train loss:0.9373303030395077\n",
      "train loss:0.826289579384009\n",
      "train loss:0.9161425222006148\n",
      "train loss:0.9132320929463985\n",
      "train loss:0.7989494219677621\n",
      "train loss:0.9101109773811791\n",
      "train loss:0.8925265460722973\n",
      "train loss:0.8344699857976893\n",
      "train loss:0.9358410753505999\n",
      "train loss:0.8580927172284504\n",
      "train loss:0.8989303383357173\n",
      "train loss:0.8485435932361683\n",
      "train loss:0.9957441884396969\n",
      "train loss:0.9338573956768593\n",
      "train loss:0.8837906318318592\n",
      "train loss:0.9532650869040157\n",
      "train loss:1.0847836523194223\n",
      "train loss:0.9608457542305966\n",
      "train loss:0.9716585693200802\n",
      "train loss:0.7242573115778438\n",
      "train loss:0.8135611343909908\n",
      "train loss:1.1590000443873205\n",
      "train loss:0.9048583970195277\n",
      "train loss:0.9713194921315236\n",
      "train loss:1.0736921445384415\n",
      "train loss:0.9386875108184738\n",
      "train loss:0.9111554073694045\n",
      "train loss:0.8000110934260093\n",
      "train loss:0.9735047131869493\n",
      "train loss:1.0472380739596026\n",
      "train loss:1.1190975763240807\n",
      "train loss:0.8879522152211682\n",
      "train loss:1.0025326459469348\n",
      "train loss:0.9496355667088656\n",
      "train loss:0.8433389531757701\n",
      "train loss:0.8465694438965349\n",
      "train loss:0.8934845655926147\n",
      "train loss:0.8865315737208639\n",
      "train loss:0.8837357468010348\n",
      "train loss:0.9805773786909591\n",
      "train loss:1.045956859918919\n",
      "train loss:0.9282930549059464\n",
      "train loss:0.9268744247432257\n",
      "train loss:0.9749140297484236\n",
      "train loss:0.9650410316041514\n",
      "train loss:0.9867196341130742\n",
      "train loss:0.8764478350858874\n",
      "train loss:0.8750633102313513\n",
      "train loss:0.9481599685233616\n",
      "train loss:0.958097948939793\n",
      "train loss:1.004163382489543\n",
      "train loss:0.9624559221674194\n",
      "train loss:1.04113693133697\n",
      "train loss:0.9087582146154518\n",
      "train loss:0.9278076756065885\n",
      "train loss:0.9847719308683481\n",
      "train loss:1.012693577379872\n",
      "train loss:1.0371001660434933\n",
      "train loss:0.9459398442016687\n",
      "train loss:0.8841254895730678\n",
      "train loss:0.8516972031595365\n",
      "train loss:1.0792565000950554\n",
      "train loss:0.9411923554918152\n",
      "train loss:0.9310203487078944\n",
      "train loss:0.905586298706802\n",
      "train loss:0.8629427603896452\n",
      "train loss:0.8393849881151797\n",
      "train loss:0.9662149882012814\n",
      "train loss:0.9445492066555126\n",
      "train loss:0.9699555511253172\n",
      "train loss:1.072226719099621\n",
      "train loss:0.9691615985260321\n",
      "train loss:0.9631370809925334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9734249507509509\n",
      "train loss:1.0293658697916164\n",
      "train loss:0.8908439881415142\n",
      "train loss:0.9986298570776099\n",
      "train loss:0.9690166229070265\n",
      "train loss:0.9266496572563383\n",
      "train loss:0.9728948478487767\n",
      "train loss:0.916304448227714\n",
      "train loss:0.8293514727509078\n",
      "train loss:0.8437445157058334\n",
      "train loss:1.1034939332074871\n",
      "train loss:0.8754200925743657\n",
      "train loss:0.8980349478198807\n",
      "train loss:0.8506706802984866\n",
      "train loss:0.9046322729717204\n",
      "train loss:0.8865870059207371\n",
      "train loss:1.01576843030806\n",
      "train loss:0.8525319152835871\n",
      "train loss:0.9621439549530044\n",
      "train loss:1.0312020993222952\n",
      "train loss:1.0978729905325024\n",
      "train loss:0.807674162800584\n",
      "train loss:0.7262502793288849\n",
      "train loss:0.7236806791222271\n",
      "train loss:0.8908501775429766\n",
      "train loss:1.0227529399419835\n",
      "train loss:1.0230085551950743\n",
      "train loss:0.7983340923124617\n",
      "train loss:0.9168796375121768\n",
      "train loss:0.862202436179549\n",
      "train loss:0.8036028470048275\n",
      "train loss:0.9722087092183841\n",
      "train loss:0.8732650445682346\n",
      "train loss:1.0351187923121328\n",
      "train loss:0.8010891667706543\n",
      "train loss:0.7468954647692557\n",
      "train loss:1.0255532162227674\n",
      "train loss:0.951615470102373\n",
      "train loss:0.9861758836434052\n",
      "train loss:0.9966929098687529\n",
      "train loss:0.9002472026071966\n",
      "train loss:0.8771072342918035\n",
      "train loss:0.9512604800669052\n",
      "train loss:0.9511898999101446\n",
      "train loss:0.9502860431685236\n",
      "train loss:0.8850443175666673\n",
      "train loss:0.9791632397213762\n",
      "train loss:1.0064059863417152\n",
      "train loss:0.914392386611083\n",
      "train loss:0.9009933922991985\n",
      "train loss:1.0200108388124987\n",
      "train loss:1.1780158867026504\n",
      "train loss:0.7742436115245455\n",
      "train loss:0.8814876357723378\n",
      "train loss:0.9199406729326733\n",
      "train loss:0.9306034608642051\n",
      "train loss:1.013354103973596\n",
      "train loss:1.1117570633740725\n",
      "train loss:1.1093709901522188\n",
      "train loss:1.0324544095890569\n",
      "train loss:0.8750590240954338\n",
      "train loss:1.110858327176069\n",
      "train loss:0.9463091249059683\n",
      "train loss:1.0102598646738332\n",
      "train loss:1.111750406833461\n",
      "train loss:1.0006399503529126\n",
      "train loss:0.8886870113027813\n",
      "train loss:0.7707151657991105\n",
      "train loss:0.8525683866475089\n",
      "train loss:0.8302899941885744\n",
      "train loss:1.0336090603861245\n",
      "train loss:0.918042573975833\n",
      "train loss:0.9081059850681935\n",
      "train loss:0.9370714509672737\n",
      "train loss:0.8187546638478403\n",
      "train loss:0.7638238911974115\n",
      "train loss:0.9969417350715082\n",
      "train loss:0.803884802223202\n",
      "train loss:1.0535764101119056\n",
      "train loss:0.9166139974176635\n",
      "train loss:0.8489783611492371\n",
      "train loss:0.992386189416504\n",
      "train loss:0.9607739152277515\n",
      "train loss:0.9541366282853572\n",
      "train loss:1.1156900903820672\n",
      "train loss:0.7359647800169041\n",
      "train loss:0.7812658056533658\n",
      "train loss:0.9117133879616779\n",
      "train loss:0.9274304686079207\n",
      "train loss:1.0915107331675116\n",
      "train loss:0.8568281258492974\n",
      "train loss:1.1529077716936493\n",
      "train loss:0.8156601688897421\n",
      "train loss:1.0393143072825703\n",
      "train loss:1.0071942006878136\n",
      "train loss:0.8978568713138891\n",
      "train loss:0.8847156958595357\n",
      "train loss:1.0031280977294579\n",
      "train loss:0.7848221497520741\n",
      "train loss:0.9466486332213299\n",
      "train loss:0.9772468830030582\n",
      "train loss:0.9400391483933348\n",
      "train loss:0.8600246937135695\n",
      "train loss:0.9595368759519484\n",
      "train loss:0.9693714232430424\n",
      "train loss:0.8522888427229389\n",
      "train loss:0.8822063992087462\n",
      "train loss:0.8914018078454898\n",
      "train loss:0.887192842643995\n",
      "train loss:0.9099760605057331\n",
      "train loss:0.8751863395874727\n",
      "train loss:1.0498573324125384\n",
      "train loss:0.9818485573967429\n",
      "train loss:0.7536049628831892\n",
      "train loss:0.8898088132651902\n",
      "train loss:1.0063386938275658\n",
      "train loss:1.0192360152769344\n",
      "train loss:0.8726052737960517\n",
      "train loss:0.9654430547043883\n",
      "train loss:1.0772545249141627\n",
      "train loss:0.8025458834329189\n",
      "train loss:0.9827286390229947\n",
      "train loss:0.9282722325434092\n",
      "train loss:0.9255433874959768\n",
      "train loss:0.627003034193053\n",
      "train loss:0.998044208506612\n",
      "train loss:0.8906341118169564\n",
      "train loss:0.9423628596321538\n",
      "train loss:0.8542690631074471\n",
      "train loss:1.0617980010336943\n",
      "train loss:0.891050992714322\n",
      "train loss:1.064443971675613\n",
      "train loss:0.8028253391038035\n",
      "train loss:1.0265876643951346\n",
      "train loss:0.8706330680949254\n",
      "train loss:0.9044504605825907\n",
      "train loss:0.8963858284876189\n",
      "train loss:0.9827050792430526\n",
      "train loss:1.0308030294241606\n",
      "train loss:0.9680080166707629\n",
      "train loss:0.7951376766930243\n",
      "train loss:0.7329685141992638\n",
      "train loss:1.0055671904323094\n",
      "train loss:1.0888077324019638\n",
      "train loss:0.8123181548456092\n",
      "train loss:0.8887590114846633\n",
      "train loss:0.9146036136273956\n",
      "train loss:0.9504975285083419\n",
      "train loss:0.9051236395528839\n",
      "train loss:0.772103319899897\n",
      "train loss:0.8651650594279546\n",
      "train loss:0.9312530046225256\n",
      "train loss:0.9896229627960619\n",
      "train loss:0.9610112696693655\n",
      "train loss:0.6759335240410396\n",
      "train loss:0.9369801871772822\n",
      "train loss:0.8921316927822577\n",
      "train loss:0.8248872026984322\n",
      "train loss:0.9268634480637413\n",
      "train loss:0.8938695125440259\n",
      "train loss:0.992768046083096\n",
      "train loss:0.8159703020072032\n",
      "train loss:0.7982582548793424\n",
      "train loss:0.9925737535511661\n",
      "train loss:0.8642203658586748\n",
      "train loss:0.8911975086567354\n",
      "train loss:0.9745991417927443\n",
      "train loss:0.9683083904305481\n",
      "train loss:1.0138614723753787\n",
      "train loss:0.8878834465113935\n",
      "train loss:0.9837169155282747\n",
      "train loss:0.9358480961145034\n",
      "train loss:0.9360429690743814\n",
      "train loss:0.9769156517039935\n",
      "train loss:0.8605676027270144\n",
      "train loss:0.8292995806088832\n",
      "train loss:1.0175985104254281\n",
      "train loss:0.8531024944714648\n",
      "train loss:0.9990019994037752\n",
      "train loss:0.8792622077314464\n",
      "train loss:0.9012242849259092\n",
      "train loss:0.9618997197155531\n",
      "train loss:0.8208562334485099\n",
      "train loss:1.0440100904868237\n",
      "train loss:1.1102681990867693\n",
      "train loss:0.9232319595947428\n",
      "train loss:0.8408542893801406\n",
      "train loss:0.9512829275431299\n",
      "train loss:0.8470378025497147\n",
      "train loss:0.8111140769168058\n",
      "train loss:0.9311221631116245\n",
      "train loss:0.9515481899555931\n",
      "train loss:0.8520251122084104\n",
      "train loss:1.0298056190618698\n",
      "train loss:0.8767329568196405\n",
      "train loss:0.8705427162971227\n",
      "train loss:0.872845566956451\n",
      "train loss:0.9719563195177152\n",
      "train loss:0.8643870002500016\n",
      "train loss:0.8195981988426618\n",
      "train loss:0.9063146069309621\n",
      "train loss:1.016812445897829\n",
      "train loss:0.7840207895093336\n",
      "train loss:0.9949891599923474\n",
      "train loss:1.204361002803672\n",
      "train loss:0.8238220005214152\n",
      "train loss:0.8647420415823628\n",
      "train loss:0.9281879985291323\n",
      "train loss:0.8914633373083762\n",
      "train loss:0.9073610596481301\n",
      "train loss:0.8749621940924773\n",
      "train loss:0.8411683379574609\n",
      "train loss:0.7521910943986925\n",
      "train loss:0.9900300599228217\n",
      "train loss:0.9618303752534668\n",
      "train loss:1.0372807502134418\n",
      "train loss:1.0073386826600268\n",
      "train loss:0.8646392812948845\n",
      "train loss:0.8439191382290293\n",
      "train loss:0.9304278659188011\n",
      "train loss:0.9714422584822441\n",
      "train loss:0.9125983310113764\n",
      "train loss:0.8033127656863409\n",
      "train loss:0.9698962858258321\n",
      "train loss:0.7891023874185099\n",
      "train loss:0.9197808983630003\n",
      "train loss:0.8052293701891949\n",
      "train loss:0.9384798425365262\n",
      "train loss:1.0816864232118795\n",
      "train loss:0.9096758757583895\n",
      "train loss:0.8758536503877231\n",
      "train loss:0.9669651653109769\n",
      "train loss:0.836757593318917\n",
      "train loss:0.9060690957606603\n",
      "train loss:0.8967082339879612\n",
      "train loss:0.8357298533413752\n",
      "train loss:0.9627151586403409\n",
      "train loss:0.7403479815470352\n",
      "train loss:1.01393328471927\n",
      "train loss:0.9987566591967179\n",
      "train loss:0.9770985617480037\n",
      "train loss:0.7868283324862753\n",
      "train loss:0.9748712603486495\n",
      "train loss:0.9510817027748945\n",
      "train loss:0.9688842267202934\n",
      "train loss:0.7274307443925533\n",
      "train loss:0.987432797746658\n",
      "train loss:0.9880279452044366\n",
      "train loss:0.9810634125178058\n",
      "train loss:0.8944539901908254\n",
      "train loss:0.9659664177102453\n",
      "train loss:0.8397321993289764\n",
      "train loss:0.9061405262473938\n",
      "train loss:0.9891592322248141\n",
      "train loss:1.0031115604122829\n",
      "train loss:1.000067509134924\n",
      "train loss:0.9444440852360766\n",
      "train loss:0.9168898517659498\n",
      "train loss:0.8569986548473029\n",
      "train loss:0.8857504448907093\n",
      "train loss:0.7865772940605769\n",
      "train loss:0.8687595744355957\n",
      "train loss:0.9625231700307011\n",
      "train loss:0.9632082620718055\n",
      "train loss:0.7941777445755023\n",
      "train loss:0.8848671189851341\n",
      "train loss:0.9267247076010646\n",
      "train loss:0.8280403615718457\n",
      "train loss:0.8873863985588819\n",
      "train loss:0.773663183087283\n",
      "train loss:0.9056694961546933\n",
      "train loss:0.716823841501251\n",
      "train loss:0.9978318755697917\n",
      "train loss:0.8456649019788328\n",
      "train loss:0.9720256873420559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8647382914668931\n",
      "train loss:0.8972054685011396\n",
      "train loss:0.7406794217826896\n",
      "train loss:0.8632090255823489\n",
      "train loss:0.8304008339059535\n",
      "train loss:0.9403565577933061\n",
      "train loss:1.0315919132678262\n",
      "train loss:0.8975423037099988\n",
      "train loss:0.8731776364136737\n",
      "train loss:1.0490843147255182\n",
      "train loss:1.0354818690939893\n",
      "train loss:0.9015977740281267\n",
      "train loss:0.9749183158564082\n",
      "train loss:0.7931733042932929\n",
      "train loss:0.9184042121294433\n",
      "train loss:0.7881864646900678\n",
      "train loss:0.8350146399471337\n",
      "train loss:0.9332295432500614\n",
      "train loss:0.8276705284299131\n",
      "train loss:0.9465706123010754\n",
      "train loss:1.058916533943784\n",
      "train loss:0.7972638187241945\n",
      "train loss:0.9591822537094827\n",
      "train loss:0.954332428878252\n",
      "train loss:0.9917366946025905\n",
      "train loss:0.9115952884610664\n",
      "train loss:0.8857414498358631\n",
      "train loss:0.8403698167076972\n",
      "train loss:1.036033988108369\n",
      "train loss:0.9695731854628348\n",
      "train loss:0.8652025792016725\n",
      "train loss:1.0222400148064543\n",
      "train loss:0.8715105257632494\n",
      "train loss:0.8813249628241347\n",
      "train loss:0.9951625108269944\n",
      "train loss:0.9726040472350715\n",
      "train loss:0.8902131091865223\n",
      "train loss:0.9142834707290562\n",
      "train loss:0.988992445720008\n",
      "train loss:0.7777029891868412\n",
      "train loss:0.92091427428444\n",
      "train loss:0.9467844744380239\n",
      "train loss:0.8793695188686012\n",
      "train loss:0.944346418188176\n",
      "train loss:0.7545788464850475\n",
      "train loss:0.847748834491821\n",
      "train loss:0.9439310006297305\n",
      "train loss:1.0535416260028183\n",
      "train loss:1.1745029647226222\n",
      "train loss:0.8506152806102234\n",
      "train loss:0.7808044569110675\n",
      "train loss:1.0498419860174275\n",
      "train loss:0.9072937623350009\n",
      "train loss:0.8990180448406488\n",
      "train loss:0.724999799654388\n",
      "train loss:0.8860900004446539\n",
      "train loss:1.0025025239750722\n",
      "train loss:0.9440312801384814\n",
      "train loss:0.9692688466671352\n",
      "train loss:1.0595753556254472\n",
      "train loss:1.0232766151561996\n",
      "train loss:0.8957959495682924\n",
      "train loss:1.003245271568512\n",
      "train loss:0.9235630973719718\n",
      "train loss:0.934800325096287\n",
      "train loss:1.212794487026362\n",
      "train loss:0.8629108769814161\n",
      "train loss:0.9371565031040977\n",
      "train loss:0.9271569609089322\n",
      "train loss:1.1226970206184805\n",
      "train loss:0.9114418225309575\n",
      "train loss:1.021801168958603\n",
      "train loss:0.9792502133404714\n",
      "train loss:0.9542712650833889\n",
      "train loss:0.7416428306201914\n",
      "train loss:0.8708616492978285\n",
      "train loss:1.0498689803000554\n",
      "train loss:0.838630891225565\n",
      "train loss:0.8899845903025577\n",
      "train loss:0.9437616349056357\n",
      "train loss:1.1531859266134588\n",
      "train loss:0.9244148634067696\n",
      "train loss:0.8298149775564728\n",
      "train loss:0.8679748572971563\n",
      "train loss:0.9795181225691604\n",
      "train loss:0.7853618967441363\n",
      "train loss:0.9275199668198016\n",
      "train loss:0.781575591241739\n",
      "train loss:0.8744994494262639\n",
      "train loss:0.8888409567625791\n",
      "train loss:0.8093744339643297\n",
      "train loss:0.980291867523926\n",
      "train loss:0.9719316436839943\n",
      "train loss:0.9855406685318016\n",
      "train loss:0.8613709821723988\n",
      "train loss:0.8632974257562975\n",
      "train loss:0.8954551273068816\n",
      "train loss:0.8596130989455072\n",
      "train loss:0.9271495289847327\n",
      "train loss:0.9151835821914007\n",
      "train loss:0.7189953533621098\n",
      "train loss:1.0769670459275935\n",
      "train loss:0.9996226990183291\n",
      "train loss:0.7224518859280153\n",
      "train loss:0.9956484938216298\n",
      "train loss:1.034731405632594\n",
      "train loss:0.7896890525763223\n",
      "train loss:0.9831268543344486\n",
      "train loss:0.9105274092980687\n",
      "train loss:0.8512744346768149\n",
      "train loss:0.9473263711151111\n",
      "train loss:1.006354082973839\n",
      "train loss:0.9948495398036319\n",
      "train loss:0.7660961890421377\n",
      "train loss:0.9162482851522239\n",
      "train loss:0.8232721711223934\n",
      "train loss:0.8690288432562414\n",
      "train loss:0.9505521745078858\n",
      "train loss:1.0095200873152212\n",
      "train loss:0.8479014728078351\n",
      "train loss:0.9001737739866762\n",
      "train loss:0.8740908337543867\n",
      "train loss:0.7455708727593477\n",
      "train loss:0.8336372702228736\n",
      "train loss:0.800399610414869\n",
      "train loss:0.9413472385918652\n",
      "train loss:0.8069394140794387\n",
      "train loss:0.8795450556189942\n",
      "train loss:1.0752408203970636\n",
      "train loss:0.8632121220756214\n",
      "train loss:0.7886865823103194\n",
      "train loss:1.0010428016841795\n",
      "train loss:0.8699908736563728\n",
      "train loss:0.9149233865046632\n",
      "train loss:0.9921532157564088\n",
      "train loss:0.8585536374882001\n",
      "train loss:0.755967557136216\n",
      "train loss:0.9973376437968333\n",
      "train loss:0.9408036987738336\n",
      "train loss:1.0274693186893848\n",
      "train loss:0.863860706589311\n",
      "train loss:0.76992992140634\n",
      "train loss:1.0155540165495784\n",
      "train loss:0.8169925707864175\n",
      "train loss:0.9631153878421911\n",
      "train loss:0.9991001029909072\n",
      "train loss:0.86948468173251\n",
      "train loss:0.8122873152051312\n",
      "train loss:0.836901300635607\n",
      "train loss:0.778640441156075\n",
      "train loss:0.957558474026268\n",
      "train loss:0.8317011556552639\n",
      "train loss:0.8933246923548777\n",
      "train loss:0.8997866986601314\n",
      "train loss:0.7254292723295535\n",
      "train loss:1.012887384672635\n",
      "train loss:0.9020859645220106\n",
      "train loss:0.9609811122625997\n",
      "train loss:0.8640460029018174\n",
      "train loss:0.8750841350469666\n",
      "train loss:0.7540065822811024\n",
      "train loss:0.9708096316071253\n",
      "train loss:0.865382295253819\n",
      "train loss:0.8407508540259455\n",
      "train loss:0.9312759062423797\n",
      "train loss:1.0863120598478797\n",
      "train loss:0.8091825187662743\n",
      "train loss:0.9037614254426093\n",
      "train loss:0.7878919206711851\n",
      "train loss:0.9006834868152347\n",
      "train loss:0.9246353715123967\n",
      "train loss:0.9193735857087562\n",
      "train loss:0.9148480803327821\n",
      "train loss:0.9815041830132347\n",
      "train loss:0.7837691517045323\n",
      "train loss:0.9309199236233894\n",
      "train loss:0.8677057085156253\n",
      "train loss:0.7575642166000388\n",
      "train loss:0.9181807112246786\n",
      "train loss:0.8209470143360176\n",
      "train loss:0.767319829671749\n",
      "train loss:0.8618801820920338\n",
      "train loss:0.6479515965680522\n",
      "train loss:1.230790897896845\n",
      "train loss:0.9096197131137828\n",
      "train loss:0.9085915243510695\n",
      "train loss:0.9240792321554278\n",
      "train loss:0.9429357262076679\n",
      "train loss:0.7103563563218871\n",
      "train loss:0.7485648721463268\n",
      "train loss:0.8735309761426551\n",
      "train loss:0.9995998789109147\n",
      "train loss:1.0267097949622\n",
      "train loss:0.8417603095945662\n",
      "train loss:1.0825417246548403\n",
      "train loss:0.913014010759781\n",
      "train loss:0.8439329193117474\n",
      "train loss:1.015502152656697\n",
      "train loss:0.7681042280602459\n",
      "train loss:0.7573121990400392\n",
      "train loss:0.893501813648794\n",
      "train loss:1.0711177453501728\n",
      "train loss:0.9995683968271419\n",
      "train loss:0.8577765497304403\n",
      "train loss:0.8831298487370305\n",
      "train loss:0.7911487913197409\n",
      "train loss:0.8043639395904512\n",
      "train loss:0.9813216281713194\n",
      "train loss:0.8865618006194838\n",
      "train loss:0.8947553358317787\n",
      "train loss:1.0418308564489482\n",
      "train loss:0.8920605223422371\n",
      "train loss:0.87324170615254\n",
      "=== epoch:16, train acc:0.991, test acc:0.994 ===\n",
      "train loss:0.7743623758717431\n",
      "train loss:0.970533454315196\n",
      "train loss:0.9037031449082247\n",
      "train loss:0.993738179318813\n",
      "train loss:0.7865133522470856\n",
      "train loss:0.9100547147054716\n",
      "train loss:1.0445513634804524\n",
      "train loss:0.8628491832691048\n",
      "train loss:0.9286661648468159\n",
      "train loss:0.7935515943946915\n",
      "train loss:0.9377394863817422\n",
      "train loss:0.983577703107366\n",
      "train loss:0.8886932258533986\n",
      "train loss:0.8769148949936342\n",
      "train loss:0.9569653286252989\n",
      "train loss:0.8200145134537654\n",
      "train loss:0.8010238793901315\n",
      "train loss:0.8118251478139489\n",
      "train loss:0.8802710699004898\n",
      "train loss:0.8934247319077302\n",
      "train loss:0.7493720964755477\n",
      "train loss:0.983692264147746\n",
      "train loss:0.9599687765789617\n",
      "train loss:0.94185134581536\n",
      "train loss:1.1025478887422142\n",
      "train loss:1.0395210340730614\n",
      "train loss:1.0869099180005073\n",
      "train loss:1.001109888083024\n",
      "train loss:0.959111677694665\n",
      "train loss:0.9459958596033234\n",
      "train loss:1.0885399015728026\n",
      "train loss:0.8741692830686373\n",
      "train loss:0.8979438307625698\n",
      "train loss:1.0687542370508054\n",
      "train loss:0.9617547723723844\n",
      "train loss:0.8075917441996847\n",
      "train loss:0.8878538784107625\n",
      "train loss:0.9821077211207444\n",
      "train loss:0.9594167915050038\n",
      "train loss:1.0591443262624143\n",
      "train loss:1.0329954325444428\n",
      "train loss:0.8538665937603137\n",
      "train loss:0.9426090732978208\n",
      "train loss:0.9854263301419387\n",
      "train loss:0.8465277483727753\n",
      "train loss:0.8070395051881332\n",
      "train loss:0.9575747492494462\n",
      "train loss:0.8585218812363736\n",
      "train loss:0.99738071613007\n",
      "train loss:0.8886501315957521\n",
      "train loss:1.0716015823938345\n",
      "train loss:1.0150796697972695\n",
      "train loss:0.9562528577988261\n",
      "train loss:0.9142877666861655\n",
      "train loss:0.8736776676538267\n",
      "train loss:0.8765987006931395\n",
      "train loss:0.9841886462318093\n",
      "train loss:0.879562028710383\n",
      "train loss:0.8049864492581047\n",
      "train loss:1.0286987389320392\n",
      "train loss:0.9553361881324206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9249085150775442\n",
      "train loss:0.990629648018649\n",
      "train loss:1.1303830340255643\n",
      "train loss:1.014595054993098\n",
      "train loss:1.0552272806414644\n",
      "train loss:0.9270403817441293\n",
      "train loss:0.9458626318428551\n",
      "train loss:0.9785228000793272\n",
      "train loss:0.88413710938156\n",
      "train loss:0.863918895237616\n",
      "train loss:1.044587063903664\n",
      "train loss:0.872470125370141\n",
      "train loss:0.9967877436365111\n",
      "train loss:1.0303138187490022\n",
      "train loss:0.9743556116363077\n",
      "train loss:0.7484519145300665\n",
      "train loss:1.067756024888308\n",
      "train loss:1.1159103110360789\n",
      "train loss:0.9203886832639584\n",
      "train loss:0.7538240028281704\n",
      "train loss:0.7794312563514655\n",
      "train loss:0.9898608112982223\n",
      "train loss:0.9507262412549926\n",
      "train loss:1.054861880866639\n",
      "train loss:0.9952110410346523\n",
      "train loss:1.049730730085353\n",
      "train loss:0.960198605982674\n",
      "train loss:0.865606806703289\n",
      "train loss:0.7944110116310693\n",
      "train loss:0.9464791423301837\n",
      "train loss:1.0497775183610896\n",
      "train loss:0.9490579208501326\n",
      "train loss:0.8053834518041336\n",
      "train loss:0.9795632619290082\n",
      "train loss:0.8540016333751004\n",
      "train loss:0.8899073341601519\n",
      "train loss:0.911878956486764\n",
      "train loss:0.7984869783607702\n",
      "train loss:0.9689959862703396\n",
      "train loss:0.9095842705886109\n",
      "train loss:0.9920090138900367\n",
      "train loss:0.8203035942215616\n",
      "train loss:0.9003468136314026\n",
      "train loss:0.9117459411882645\n",
      "train loss:0.9234184210159389\n",
      "train loss:0.7198714178065291\n",
      "train loss:0.8302029169130458\n",
      "train loss:1.1047662448892996\n",
      "train loss:0.8419152035987261\n",
      "train loss:0.8841281903622398\n",
      "train loss:0.9270840572571976\n",
      "train loss:1.1554003459294377\n",
      "train loss:0.9431216729147366\n",
      "train loss:0.7952699766887507\n",
      "train loss:0.9662728055725981\n",
      "train loss:0.9363743783945409\n",
      "train loss:0.8349132398469294\n",
      "train loss:0.8194420817764865\n",
      "train loss:0.8625896741209974\n",
      "train loss:0.8611235909902305\n",
      "train loss:1.1467720288798444\n",
      "train loss:1.009614674492969\n",
      "train loss:1.0342266436434189\n",
      "train loss:0.9526499759320132\n",
      "train loss:0.949790432615667\n",
      "train loss:0.9718020109455807\n",
      "train loss:0.9503207672704567\n",
      "train loss:0.8400603461909403\n",
      "train loss:1.0212355720516961\n",
      "train loss:0.7868344115478543\n",
      "train loss:0.9556928415793777\n",
      "train loss:0.7789787845775689\n",
      "train loss:0.810320230785364\n",
      "train loss:0.7648264673302382\n",
      "train loss:0.8153152710664038\n",
      "train loss:0.8145396914911842\n",
      "train loss:0.8400466966180093\n",
      "train loss:1.0662724722126373\n",
      "train loss:0.9206434660375542\n",
      "train loss:1.0136642219444603\n",
      "train loss:0.8729207285694165\n",
      "train loss:0.9740772939431872\n",
      "train loss:1.0797607834835512\n",
      "train loss:0.8720538794663629\n",
      "train loss:0.8820047103012417\n",
      "train loss:0.8944588230366947\n",
      "train loss:0.8582316776154335\n",
      "train loss:0.9529997832227233\n",
      "train loss:0.941917982357865\n",
      "train loss:0.8336864960744447\n",
      "train loss:0.869504282774242\n",
      "train loss:0.953846534379227\n",
      "train loss:0.9521775030499897\n",
      "train loss:0.7551331742337578\n",
      "train loss:0.7514709409069797\n",
      "train loss:0.9802787531784568\n",
      "train loss:0.5607241679133803\n",
      "train loss:0.9890168853464923\n",
      "train loss:0.9241771994100878\n",
      "train loss:0.7796278012165595\n",
      "train loss:0.9214046268318051\n",
      "train loss:0.7872292045932785\n",
      "train loss:0.8722562918091796\n",
      "train loss:0.8954811541616725\n",
      "train loss:0.9005606336178158\n",
      "train loss:0.873800393722782\n",
      "train loss:0.892461495762688\n",
      "train loss:0.8533464109120489\n",
      "train loss:0.7712540902461551\n",
      "train loss:0.7915424246693437\n",
      "train loss:0.954582346053424\n",
      "train loss:0.8376897207864245\n",
      "train loss:0.9280350579763303\n",
      "train loss:1.09903399234336\n",
      "train loss:0.903149160528737\n",
      "train loss:0.7748321444567697\n",
      "train loss:1.0514110222618487\n",
      "train loss:0.8221693648223343\n",
      "train loss:0.9379462745765657\n",
      "train loss:0.9273710750562852\n",
      "train loss:0.8244353896949705\n",
      "train loss:0.7489505459360921\n",
      "train loss:0.9016223626742427\n",
      "train loss:0.8644742013352292\n",
      "train loss:0.9520870821682642\n",
      "train loss:0.8327948749530372\n",
      "train loss:0.8874319857381017\n",
      "train loss:0.8446615721683136\n",
      "train loss:0.8638478506024194\n",
      "train loss:0.8330326687538379\n",
      "train loss:1.016027081208158\n",
      "train loss:0.8408708410616593\n",
      "train loss:0.8276689200001615\n",
      "train loss:0.8579972923172764\n",
      "train loss:0.8605919952854716\n",
      "train loss:0.8335554777346351\n",
      "train loss:0.7840768111888593\n",
      "train loss:0.8642464724532243\n",
      "train loss:0.8977136175624306\n",
      "train loss:0.9426212552246734\n",
      "train loss:0.8655079704923684\n",
      "train loss:0.8177485341051296\n",
      "train loss:0.8581688380096105\n",
      "train loss:0.6973418101585449\n",
      "train loss:0.8987222643215682\n",
      "train loss:0.905443290416486\n",
      "train loss:1.2036674588926501\n",
      "train loss:0.8912335342933939\n",
      "train loss:1.005481674856425\n",
      "train loss:1.2412970073552545\n",
      "train loss:0.9321009723312049\n",
      "train loss:0.8147244321800978\n",
      "train loss:0.8785918997883995\n",
      "train loss:0.7580043389579016\n",
      "train loss:0.8139247861914718\n",
      "train loss:0.9710058365111226\n",
      "train loss:1.0287723446813397\n",
      "train loss:1.0363959827300062\n",
      "train loss:0.8853187754570268\n",
      "train loss:0.8394982774185124\n",
      "train loss:0.8656891880988014\n",
      "train loss:1.015253944305638\n",
      "train loss:0.8650302105277552\n",
      "train loss:1.029894244253448\n",
      "train loss:1.0719184573563216\n",
      "train loss:0.8636906941047516\n",
      "train loss:0.9946362621333225\n",
      "train loss:0.8948655403857358\n",
      "train loss:0.8576954622958576\n",
      "train loss:0.9528939706041385\n",
      "train loss:1.0561481018067853\n",
      "train loss:1.027401090437965\n",
      "train loss:0.9050727563010429\n",
      "train loss:0.9314564101155411\n",
      "train loss:1.1059420910564137\n",
      "train loss:0.9493640619086097\n",
      "train loss:0.8431016124972059\n",
      "train loss:0.87036216577472\n",
      "train loss:0.9866699455877631\n",
      "train loss:0.868009270286553\n",
      "train loss:0.893073319528192\n",
      "train loss:0.9552414206463017\n",
      "train loss:0.9645676413024293\n",
      "train loss:0.7741628725132874\n",
      "train loss:0.8250278045094862\n",
      "train loss:1.0084375676303972\n",
      "train loss:0.8690249979234593\n",
      "train loss:0.9713779370108807\n",
      "train loss:0.960419709832579\n",
      "train loss:1.0024673503201962\n",
      "train loss:0.9194969126210505\n",
      "train loss:0.847237211976819\n",
      "train loss:0.9568097061146809\n",
      "train loss:0.7887616313102004\n",
      "train loss:1.0556621989180375\n",
      "train loss:0.9376180136652955\n",
      "train loss:0.9607994334528839\n",
      "train loss:0.937589406654001\n",
      "train loss:0.8778641585114235\n",
      "train loss:0.9813057324862733\n",
      "train loss:1.0580957252778111\n",
      "train loss:0.9919998359834653\n",
      "train loss:0.8131123271277432\n",
      "train loss:0.8909751093463579\n",
      "train loss:0.9427479822891561\n",
      "train loss:1.0730997746360011\n",
      "train loss:0.9049957920957774\n",
      "train loss:0.6315893826369742\n",
      "train loss:0.7941671612470583\n",
      "train loss:0.9821564065549766\n",
      "train loss:1.075061890015892\n",
      "train loss:0.8720602558711587\n",
      "train loss:1.0538247987304945\n",
      "train loss:0.8444896216103692\n",
      "train loss:1.0707307719842452\n",
      "train loss:1.053616075753968\n",
      "train loss:1.0084656335608129\n",
      "train loss:1.1172590826554114\n",
      "train loss:0.7796353084312351\n",
      "train loss:0.8319632733530351\n",
      "train loss:0.951185287179449\n",
      "train loss:0.9147290416337469\n",
      "train loss:0.9481178969594769\n",
      "train loss:0.9456351532256025\n",
      "train loss:0.9419856144615082\n",
      "train loss:0.8746095980183032\n",
      "train loss:0.8837133181147027\n",
      "train loss:0.9873096073629752\n",
      "train loss:0.9671394972081953\n",
      "train loss:0.9691801455494958\n",
      "train loss:0.9753344556434119\n",
      "train loss:0.8913629704023205\n",
      "train loss:0.8074098583673012\n",
      "train loss:0.9232209319480318\n",
      "train loss:0.8408762135891789\n",
      "train loss:0.815508995748322\n",
      "train loss:0.812765818912635\n",
      "train loss:0.9783750549549352\n",
      "train loss:0.8534282769849182\n",
      "train loss:1.1076361018098955\n",
      "train loss:0.9466260947954467\n",
      "train loss:0.9848878209134665\n",
      "train loss:0.894634937678563\n",
      "train loss:0.9108351571821361\n",
      "train loss:0.920784958806037\n",
      "train loss:0.8217565489289579\n",
      "train loss:0.878868319815655\n",
      "train loss:1.009569715677508\n",
      "train loss:1.042222209020703\n",
      "train loss:0.943047396192605\n",
      "train loss:0.8513181691288776\n",
      "train loss:0.8195663830395428\n",
      "train loss:0.7538268545724862\n",
      "train loss:0.8762588567037871\n",
      "train loss:0.9543123935225928\n",
      "train loss:1.0239368645443563\n",
      "train loss:0.9853077977626883\n",
      "train loss:1.0222788793006379\n",
      "train loss:0.835740438313655\n",
      "train loss:0.847506863125183\n",
      "train loss:0.9401738497214923\n",
      "train loss:0.9916599520639825\n",
      "train loss:0.8966690111299274\n",
      "train loss:1.0651289215513484\n",
      "train loss:0.9195180682969369\n",
      "train loss:1.1028569036859537\n",
      "train loss:0.7878141357122743\n",
      "train loss:0.7879529221122303\n",
      "train loss:0.7922967607617263\n",
      "train loss:0.9524308128943175\n",
      "train loss:1.0553215674608816\n",
      "train loss:1.0636238836170373\n",
      "train loss:0.9914624646330665\n",
      "train loss:1.1071958295505404\n",
      "train loss:1.1497590007874245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9190741708209527\n",
      "train loss:1.043048352550333\n",
      "train loss:1.0499505420203177\n",
      "train loss:0.8273176698021824\n",
      "train loss:0.9111823755273182\n",
      "train loss:0.8867088990821881\n",
      "train loss:0.9487955423299058\n",
      "train loss:0.840453890861883\n",
      "train loss:0.8857865519602848\n",
      "train loss:1.1378779040377693\n",
      "train loss:1.1166011085992862\n",
      "train loss:1.0559453943576127\n",
      "train loss:0.9483420534245282\n",
      "train loss:1.0090311062697526\n",
      "train loss:0.9039709817783375\n",
      "train loss:1.011953383077787\n",
      "train loss:0.8819939739959106\n",
      "train loss:0.8451364445425921\n",
      "train loss:0.900573531953654\n",
      "train loss:0.8261601191063146\n",
      "train loss:1.0715186651954485\n",
      "train loss:1.0739395686918536\n",
      "train loss:0.9796312999708134\n",
      "train loss:0.9907175785689745\n",
      "train loss:0.8771633466558676\n",
      "train loss:0.8230954111825661\n",
      "train loss:1.0236981880437273\n",
      "train loss:0.7945116859492442\n",
      "train loss:0.9858286341609106\n",
      "train loss:0.9027719809389149\n",
      "train loss:0.9464247055985763\n",
      "train loss:0.9832904922730554\n",
      "train loss:0.6096298640146681\n",
      "train loss:1.0579569354714438\n",
      "train loss:0.9735339920576048\n",
      "train loss:0.9043717387213723\n",
      "train loss:1.043077111063385\n",
      "train loss:0.8278669236777185\n",
      "train loss:0.8481026183199871\n",
      "train loss:0.9420598353474716\n",
      "train loss:0.84883817095401\n",
      "train loss:0.9386821250568288\n",
      "train loss:0.8773408885180771\n",
      "train loss:0.9861468890113378\n",
      "train loss:0.8539516089438992\n",
      "train loss:0.8821558591791443\n",
      "train loss:0.877480249046225\n",
      "train loss:0.9132103202201282\n",
      "train loss:0.9636109577329545\n",
      "train loss:0.8406778391901648\n",
      "train loss:0.8472787418323109\n",
      "train loss:0.8065063659489209\n",
      "train loss:0.9923770094588577\n",
      "train loss:0.8067757563862505\n",
      "train loss:0.8975405936698244\n",
      "train loss:0.9548577257527778\n",
      "train loss:1.0053414039877495\n",
      "train loss:0.9103455466187096\n",
      "train loss:0.8705974438170878\n",
      "train loss:1.0023890115696843\n",
      "train loss:0.8819684409191436\n",
      "train loss:0.8734230401367036\n",
      "train loss:0.8759727312790879\n",
      "train loss:0.9856023751667017\n",
      "train loss:0.7944841977497558\n",
      "train loss:0.9498110661964213\n",
      "train loss:0.9361216158422784\n",
      "train loss:0.9268277527092303\n",
      "train loss:0.9738511991606312\n",
      "train loss:0.9485911885733028\n",
      "train loss:0.9564184653708945\n",
      "train loss:0.8958505106503521\n",
      "train loss:0.7726263082490967\n",
      "train loss:0.980793273683391\n",
      "train loss:0.8095735090039028\n",
      "train loss:0.9553496130707605\n",
      "train loss:0.865029530692786\n",
      "train loss:0.8800338468166109\n",
      "train loss:0.9187815032631669\n",
      "train loss:0.829361800867543\n",
      "train loss:1.0015164503487766\n",
      "train loss:0.8899571179136835\n",
      "train loss:1.1281399506227832\n",
      "train loss:0.9371939168688255\n",
      "train loss:0.8556402691098122\n",
      "train loss:0.876684370501225\n",
      "train loss:0.989271284678008\n",
      "train loss:0.8384470604145755\n",
      "train loss:1.0617515363844416\n",
      "train loss:0.7996467367036706\n",
      "train loss:0.827778514371762\n",
      "train loss:0.7833197145435227\n",
      "train loss:0.8687310326791932\n",
      "train loss:0.8910265228640952\n",
      "train loss:0.8468033327949108\n",
      "train loss:1.087715039208149\n",
      "train loss:0.8420739239680387\n",
      "train loss:0.9580764657173663\n",
      "train loss:0.9922506815440691\n",
      "train loss:0.8155965407883177\n",
      "train loss:1.1123920060671062\n",
      "train loss:0.9129359106697612\n",
      "train loss:1.0798980293671603\n",
      "train loss:0.833947950127989\n",
      "train loss:1.0180300204247232\n",
      "train loss:1.1008604311698371\n",
      "train loss:0.9414899169921508\n",
      "train loss:0.7703201431609099\n",
      "train loss:1.038034900060979\n",
      "train loss:0.8086791610556961\n",
      "train loss:0.8697238402823885\n",
      "train loss:0.8672021314828631\n",
      "train loss:0.8725355586222744\n",
      "train loss:0.9663461320824517\n",
      "train loss:0.8966394975506219\n",
      "train loss:1.0518495816901932\n",
      "train loss:0.8651189328585349\n",
      "train loss:0.7858689329398483\n",
      "train loss:0.728192867810985\n",
      "train loss:0.7986991979916671\n",
      "train loss:0.9211572370182466\n",
      "train loss:0.870907700616671\n",
      "train loss:1.0150628883561448\n",
      "train loss:0.8174727824864314\n",
      "train loss:0.8338449456544587\n",
      "train loss:0.9751737082447127\n",
      "train loss:1.082242930907183\n",
      "train loss:0.7851951220501447\n",
      "train loss:0.9988853605797088\n",
      "train loss:0.8768213533179986\n",
      "train loss:0.8709381478600403\n",
      "train loss:1.0319037742854602\n",
      "train loss:0.7614058189861036\n",
      "train loss:0.9026971902899423\n",
      "train loss:0.8971917504880405\n",
      "train loss:0.8958821080034987\n",
      "train loss:0.7225457045470195\n",
      "train loss:0.7927876332633197\n",
      "train loss:0.9731422321867992\n",
      "train loss:0.9264744219556359\n",
      "train loss:0.9461459404479103\n",
      "train loss:0.9828799466327712\n",
      "train loss:0.8164986764187909\n",
      "train loss:0.9861731666237974\n",
      "train loss:0.9877648794482201\n",
      "train loss:0.9453484336106256\n",
      "train loss:1.1352749835092864\n",
      "train loss:0.9527650313173514\n",
      "train loss:1.070321072496233\n",
      "train loss:0.9320082993179051\n",
      "train loss:0.9502414995926464\n",
      "train loss:0.8684750296859696\n",
      "train loss:0.8808339513508145\n",
      "train loss:1.0756297579741352\n",
      "train loss:0.8714976936508465\n",
      "train loss:1.051890868795199\n",
      "train loss:0.9374908867410803\n",
      "train loss:0.9893337949516162\n",
      "train loss:0.9945560629421195\n",
      "train loss:0.8522919801105366\n",
      "train loss:1.0136141349326726\n",
      "train loss:0.8961864715350611\n",
      "train loss:0.7900510691526237\n",
      "train loss:0.8642558634397303\n",
      "train loss:0.9986994694572121\n",
      "train loss:0.8603674847765737\n",
      "train loss:0.9450836886351996\n",
      "train loss:0.9289232556255397\n",
      "train loss:0.9491359520372511\n",
      "train loss:0.8328727392037901\n",
      "train loss:1.018661587241878\n",
      "train loss:0.9153887818222708\n",
      "train loss:0.821214608496221\n",
      "train loss:0.9860257823868258\n",
      "train loss:0.839952079677383\n",
      "train loss:0.9819938471683681\n",
      "train loss:0.8487884968040476\n",
      "train loss:0.9657897775081713\n",
      "train loss:0.8379313749860644\n",
      "train loss:0.9381467589827838\n",
      "train loss:0.888544056980671\n",
      "train loss:0.9443867216385293\n",
      "train loss:0.8606259992859252\n",
      "train loss:0.9132754080242742\n",
      "train loss:0.9911773680786061\n",
      "train loss:0.9761696386498394\n",
      "train loss:0.8335088044869097\n",
      "train loss:0.888088430889777\n",
      "train loss:0.7811219521074849\n",
      "train loss:0.8986311633261401\n",
      "train loss:1.0021456464488112\n",
      "train loss:0.8796520605752337\n",
      "train loss:0.8232392150884952\n",
      "train loss:0.9504237469671498\n",
      "train loss:1.0009014188417806\n",
      "train loss:0.8623763416693184\n",
      "train loss:1.052964597446319\n",
      "train loss:0.8809595785403447\n",
      "train loss:0.9966029195954828\n",
      "train loss:0.9244292750265164\n",
      "train loss:0.8769232428358933\n",
      "train loss:0.7590075653319609\n",
      "train loss:0.9596260279046888\n",
      "train loss:0.9001217049399688\n",
      "train loss:1.048382033201791\n",
      "train loss:0.886053908008221\n",
      "train loss:0.9667828689513206\n",
      "train loss:0.8674664119582236\n",
      "train loss:0.8993482317849189\n",
      "train loss:0.8532883634771552\n",
      "train loss:1.044198741475216\n",
      "train loss:0.825312817598153\n",
      "train loss:1.0247382891357868\n",
      "train loss:0.9246742112983425\n",
      "train loss:1.1291574203852384\n",
      "train loss:1.09434188008794\n",
      "train loss:0.9239357556313097\n",
      "train loss:1.022175383738159\n",
      "train loss:0.7612561337811292\n",
      "train loss:0.8901994538088096\n",
      "train loss:0.9729665772074323\n",
      "train loss:0.9464325543062918\n",
      "train loss:0.9101440808548239\n",
      "train loss:0.9464072027925652\n",
      "train loss:0.801956311466888\n",
      "train loss:1.0309532911090442\n",
      "train loss:0.8099518564965326\n",
      "train loss:0.9965537634604172\n",
      "train loss:1.0172431306868703\n",
      "train loss:1.1639543148886984\n",
      "train loss:1.0113857029820676\n",
      "train loss:0.8682283139689883\n",
      "train loss:0.9362948967721433\n",
      "train loss:0.9921809496638572\n",
      "train loss:0.9418096900978\n",
      "train loss:0.9343748904345474\n",
      "train loss:0.9752139121315615\n",
      "train loss:0.8709665317023672\n",
      "train loss:1.040795005367186\n",
      "train loss:1.031878110658884\n",
      "train loss:0.8222097670666259\n",
      "train loss:0.9245710444230782\n",
      "train loss:0.8667105313188934\n",
      "train loss:0.9475544664568787\n",
      "train loss:0.835990644760565\n",
      "train loss:1.1677305498692605\n",
      "train loss:0.7409393585293381\n",
      "train loss:0.8786402149456569\n",
      "train loss:0.8984819167683695\n",
      "train loss:0.8479629917870984\n",
      "train loss:0.9447934904913166\n",
      "train loss:0.8029895743429641\n",
      "train loss:0.9458901560077385\n",
      "train loss:0.8660071733889367\n",
      "train loss:1.0697143132877287\n",
      "train loss:0.8103277705207793\n",
      "train loss:0.9752913414601617\n",
      "train loss:0.9456779102732499\n",
      "train loss:1.0607119998086134\n",
      "train loss:0.8394776818749067\n",
      "train loss:1.028390521952151\n",
      "train loss:0.9974759158401958\n",
      "train loss:0.7658639360183632\n",
      "train loss:1.0030005871516003\n",
      "=== epoch:17, train acc:0.989, test acc:0.988 ===\n",
      "train loss:0.9672081260694892\n",
      "train loss:0.8480780375104525\n",
      "train loss:0.8894284973165871\n",
      "train loss:0.9166255586563337\n",
      "train loss:1.0159966790747932\n",
      "train loss:1.0752637345292337\n",
      "train loss:0.8744558768369955\n",
      "train loss:0.7784967662643685\n",
      "train loss:0.9451131280443206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8857135975755503\n",
      "train loss:0.9048646207088292\n",
      "train loss:1.0219225416321651\n",
      "train loss:0.8501563149521022\n",
      "train loss:0.9756326719972849\n",
      "train loss:0.8543980786017913\n",
      "train loss:1.0268372148195406\n",
      "train loss:0.9302815216426968\n",
      "train loss:0.9621935867296041\n",
      "train loss:0.9620803567585858\n",
      "train loss:0.8461974836594383\n",
      "train loss:0.9299448912803081\n",
      "train loss:0.9176145299519959\n",
      "train loss:0.8865501400850033\n",
      "train loss:0.8562063278820198\n",
      "train loss:0.9900593888170384\n",
      "train loss:0.8538271335304976\n",
      "train loss:0.8802457372721098\n",
      "train loss:0.9366249537896582\n",
      "train loss:0.8985225401493746\n",
      "train loss:0.9776225551785912\n",
      "train loss:0.9048510351579582\n",
      "train loss:1.1257472754558064\n",
      "train loss:0.8303829485029507\n",
      "train loss:1.009572833431377\n",
      "train loss:0.9733037618455058\n",
      "train loss:0.897610738469579\n",
      "train loss:1.1073033291315386\n",
      "train loss:0.8484063113672142\n",
      "train loss:0.8737160202709284\n",
      "train loss:0.9403331189882702\n",
      "train loss:0.8985998166457136\n",
      "train loss:0.978174919457163\n",
      "train loss:0.8830586475626104\n",
      "train loss:0.9592712692516426\n",
      "train loss:0.9978110391769254\n",
      "train loss:0.896181068297448\n",
      "train loss:0.8802310527918573\n",
      "train loss:0.849433790321471\n",
      "train loss:1.0324791935390623\n",
      "train loss:0.9965547003003905\n",
      "train loss:0.9053840451081241\n",
      "train loss:0.8937979124768398\n",
      "train loss:0.7254179255061481\n",
      "train loss:0.9836498756502877\n",
      "train loss:0.9557443557348929\n",
      "train loss:1.007116653535667\n",
      "train loss:0.7941761966154945\n",
      "train loss:0.9611027372277688\n",
      "train loss:0.9999135095396403\n",
      "train loss:0.81581634690322\n",
      "train loss:0.9400438267388528\n",
      "train loss:0.9791590025937598\n",
      "train loss:0.9132006746831189\n",
      "train loss:0.8455391100604271\n",
      "train loss:1.0735981336322464\n",
      "train loss:0.876952713747806\n",
      "train loss:0.8514786900825443\n",
      "train loss:0.7857383533840888\n",
      "train loss:0.7651173702934428\n",
      "train loss:0.9776285162326659\n",
      "train loss:1.0276199430467967\n",
      "train loss:0.9576332551502347\n",
      "train loss:1.023334728202678\n",
      "train loss:0.8902982871018998\n",
      "train loss:1.0406288730349633\n",
      "train loss:0.8358753515374515\n",
      "train loss:0.8886049252291511\n",
      "train loss:1.0494726951442135\n",
      "train loss:0.8381179162370935\n",
      "train loss:1.093728932464588\n",
      "train loss:0.7965071803150334\n",
      "train loss:0.9919993772953427\n",
      "train loss:1.0153733941108054\n",
      "train loss:1.0194669823463998\n",
      "train loss:0.8930261390182251\n",
      "train loss:0.8306899817886859\n",
      "train loss:0.8115744102727269\n",
      "train loss:1.0633893323255825\n",
      "train loss:0.953356254935282\n",
      "train loss:0.9238714158777707\n",
      "train loss:0.972987099753591\n",
      "train loss:0.7534947058148822\n",
      "train loss:0.832983579102638\n",
      "train loss:0.8273378314686862\n",
      "train loss:0.8831638280058045\n",
      "train loss:0.9998679607414778\n",
      "train loss:0.7975229128535584\n",
      "train loss:0.77137405296644\n",
      "train loss:0.914255635406698\n",
      "train loss:0.940450594342022\n",
      "train loss:0.9084628589585765\n",
      "train loss:0.8840353774805783\n",
      "train loss:0.999455656971413\n",
      "train loss:1.1336569734296298\n",
      "train loss:0.9607840007982733\n",
      "train loss:0.827558328787255\n",
      "train loss:0.8395411197758222\n",
      "train loss:1.0048602940360893\n",
      "train loss:0.9291783641454394\n",
      "train loss:0.846055339878289\n",
      "train loss:0.9092561809322801\n",
      "train loss:0.8553702681742757\n",
      "train loss:0.9614428308931363\n",
      "train loss:0.9382601470356099\n",
      "train loss:0.8575158161751614\n",
      "train loss:0.7720311123271845\n",
      "train loss:1.023698523091732\n",
      "train loss:0.9901215242794073\n",
      "train loss:0.9480095602945977\n",
      "train loss:0.8793971531582727\n",
      "train loss:0.8015122851499494\n",
      "train loss:0.9251375775440159\n",
      "train loss:0.9176541471950647\n",
      "train loss:0.9328821442906338\n",
      "train loss:0.8647121751599448\n",
      "train loss:0.9200049690327802\n",
      "train loss:0.8306043919499063\n",
      "train loss:1.0414755389311794\n",
      "train loss:0.8509416672729962\n",
      "train loss:0.8744891509543862\n",
      "train loss:0.9251555107113265\n",
      "train loss:0.9308836684503663\n",
      "train loss:0.8505770073041791\n",
      "train loss:0.8411808088272085\n",
      "train loss:1.0267363276832133\n",
      "train loss:0.9516580652154311\n",
      "train loss:0.8970684721971278\n",
      "train loss:0.9112245806560645\n",
      "train loss:0.7489434839001035\n",
      "train loss:1.0331168979486567\n",
      "train loss:1.101829820965914\n",
      "train loss:0.8746461491107874\n",
      "train loss:0.9705074010724536\n",
      "train loss:0.8846711179803506\n",
      "train loss:1.0659094599669858\n",
      "train loss:1.060920877267684\n",
      "train loss:0.8779297569001752\n",
      "train loss:0.8836013225601979\n",
      "train loss:0.834989548632162\n",
      "train loss:0.7852891711315331\n",
      "train loss:0.900967713726359\n",
      "train loss:0.9169549640258378\n",
      "train loss:0.8262003653378625\n",
      "train loss:0.9198430719455267\n",
      "train loss:0.9343530933204138\n",
      "train loss:0.8129827732093687\n",
      "train loss:0.7841523971289548\n",
      "train loss:0.8018796584091342\n",
      "train loss:0.9448930110982503\n",
      "train loss:0.7960125737755263\n",
      "train loss:0.9754463863064887\n",
      "train loss:0.8917981897074442\n",
      "train loss:0.9073834223147865\n",
      "train loss:0.9227193284257749\n",
      "train loss:0.756352702564437\n",
      "train loss:0.9421258763205657\n",
      "train loss:1.0583913806947927\n",
      "train loss:0.9697624626163305\n",
      "train loss:0.8474457840003659\n",
      "train loss:0.7287918108260351\n",
      "train loss:1.0480579391538722\n",
      "train loss:0.8308665786771098\n",
      "train loss:1.0861662610520908\n",
      "train loss:0.9054813738797605\n",
      "train loss:0.8855412464142092\n",
      "train loss:0.860925324733025\n",
      "train loss:1.1187263971915724\n",
      "train loss:0.894035132134849\n",
      "train loss:0.9018266840197451\n",
      "train loss:0.9937135178382001\n",
      "train loss:0.8970582519876339\n",
      "train loss:0.8385807005035362\n",
      "train loss:1.0587860444495525\n",
      "train loss:0.9501846431227823\n",
      "train loss:0.8422837718902761\n",
      "train loss:0.8943338408202893\n",
      "train loss:0.8544640123018539\n",
      "train loss:0.8280520285216072\n",
      "train loss:0.8836376816560141\n",
      "train loss:0.7943458472508652\n",
      "train loss:0.8823131250187553\n",
      "train loss:0.9457823885606913\n",
      "train loss:0.8347080998063368\n",
      "train loss:0.7838634725860524\n",
      "train loss:0.9598426805789556\n",
      "train loss:0.7372652855021065\n",
      "train loss:0.8219597152852978\n",
      "train loss:0.871682508431888\n",
      "train loss:0.8141424412443026\n",
      "train loss:0.9559642197366887\n",
      "train loss:0.9664939105422096\n",
      "train loss:0.8549044648146209\n",
      "train loss:1.0021385626487578\n",
      "train loss:1.0116152593557857\n",
      "train loss:1.035127446942511\n",
      "train loss:0.8860482792118459\n",
      "train loss:0.8090378182611399\n",
      "train loss:0.9500789831452094\n",
      "train loss:0.8645938761190101\n",
      "train loss:0.8514325406335184\n",
      "train loss:0.847331047397861\n",
      "train loss:0.8773829760809381\n",
      "train loss:0.9460430468846956\n",
      "train loss:1.0681169823039816\n",
      "train loss:0.8764157934158707\n",
      "train loss:0.7827224665794371\n",
      "train loss:0.8748326121201877\n",
      "train loss:1.024762999683396\n",
      "train loss:0.8444506508941734\n",
      "train loss:0.9616390722286142\n",
      "train loss:0.7893023411849677\n",
      "train loss:0.8983511294753452\n",
      "train loss:0.9175654981694887\n",
      "train loss:0.9006086317139829\n",
      "train loss:1.0386339828865827\n",
      "train loss:0.9632017424299839\n",
      "train loss:0.968570383903296\n",
      "train loss:0.8776854612364925\n",
      "train loss:0.8103115205057653\n",
      "train loss:0.8416159260434641\n",
      "train loss:0.8529539455869873\n",
      "train loss:0.8943764438301912\n",
      "train loss:0.9508922265828236\n",
      "train loss:0.9335759865201609\n",
      "train loss:0.9150257136410389\n",
      "train loss:0.753052775170078\n",
      "train loss:0.9675375283903448\n",
      "train loss:0.9357493872157643\n",
      "train loss:0.8967987272116134\n",
      "train loss:0.9149316400300793\n",
      "train loss:1.001854175345269\n",
      "train loss:1.0463464135387235\n",
      "train loss:0.8715140970325236\n",
      "train loss:0.8060668070373738\n",
      "train loss:1.0087764706320899\n",
      "train loss:0.9151712949887377\n",
      "train loss:0.8823821198607571\n",
      "train loss:0.9455057706832369\n",
      "train loss:0.9482870254521011\n",
      "train loss:0.9839202987676114\n",
      "train loss:0.9202028253784265\n",
      "train loss:0.9198300189506863\n",
      "train loss:1.1194120079921497\n",
      "train loss:0.9950156066688784\n",
      "train loss:0.8900316024567292\n",
      "train loss:0.9304332993489397\n",
      "train loss:0.9449293475670865\n",
      "train loss:0.9258312814882358\n",
      "train loss:0.9279511326941738\n",
      "train loss:0.8935292613012361\n",
      "train loss:0.8365276561493309\n",
      "train loss:0.8511066181597984\n",
      "train loss:1.0825593472192612\n",
      "train loss:0.9561667837241968\n",
      "train loss:0.9573561327692316\n",
      "train loss:1.129754691346558\n",
      "train loss:1.0868760752790976\n",
      "train loss:0.9175382328860188\n",
      "train loss:1.071332511380725\n",
      "train loss:0.8865001060925799\n",
      "train loss:1.0092055904490977\n",
      "train loss:0.9155421782499663\n",
      "train loss:1.1075171087094402\n",
      "train loss:0.9805341617123657\n",
      "train loss:0.9357615838508617\n",
      "train loss:0.8489731661048634\n",
      "train loss:1.0029196846904809\n",
      "train loss:0.9121305812174118\n",
      "train loss:0.9506151407762228\n",
      "train loss:0.9248853055818285\n",
      "train loss:0.8453342600563437\n",
      "train loss:1.0605751006793909\n",
      "train loss:0.7517822138726501\n",
      "train loss:0.8875593697485106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9767508328531972\n",
      "train loss:0.8280939780957616\n",
      "train loss:0.9213217384415373\n",
      "train loss:0.9982621989261149\n",
      "train loss:0.9134655044266625\n",
      "train loss:1.0062343262074254\n",
      "train loss:0.864691197679673\n",
      "train loss:0.944406191785273\n",
      "train loss:0.8649710785174156\n",
      "train loss:0.876697336713941\n",
      "train loss:1.0452732506225895\n",
      "train loss:0.9039878800057304\n",
      "train loss:0.8118022067687183\n",
      "train loss:1.0390446092902161\n",
      "train loss:0.9645601704621766\n",
      "train loss:1.1305349212351299\n",
      "train loss:1.0475226802452107\n",
      "train loss:0.923921511798492\n",
      "train loss:0.9106507025192893\n",
      "train loss:1.089713911713313\n",
      "train loss:1.0034872542884334\n",
      "train loss:0.7835924897854253\n",
      "train loss:0.8909821524169281\n",
      "train loss:0.8545241180007759\n",
      "train loss:0.7497018789863401\n",
      "train loss:0.8528145084703932\n",
      "train loss:1.0410378637427384\n",
      "train loss:0.9881539944113079\n",
      "train loss:0.8505498553235031\n",
      "train loss:0.8527560155118377\n",
      "train loss:0.9485381735110007\n",
      "train loss:0.8782248543427059\n",
      "train loss:0.8470306517641352\n",
      "train loss:0.8355580220220125\n",
      "train loss:0.9191868309239807\n",
      "train loss:0.9368335312446494\n",
      "train loss:0.784827612353801\n",
      "train loss:0.9903794322253006\n",
      "train loss:0.9101967543597935\n",
      "train loss:0.8927124260038074\n",
      "train loss:0.9430149600275582\n",
      "train loss:0.9715574283093615\n",
      "train loss:0.720123885150671\n",
      "train loss:0.9007812475610523\n",
      "train loss:1.014319795477246\n",
      "train loss:0.9413832764529008\n",
      "train loss:0.8392790159797577\n",
      "train loss:0.8976957726673589\n",
      "train loss:1.1006032635850054\n",
      "train loss:0.8623247543281652\n",
      "train loss:0.9303648332972346\n",
      "train loss:1.0093894616592645\n",
      "train loss:0.9842588838371509\n",
      "train loss:0.8879943219649483\n",
      "train loss:0.8262494066650007\n",
      "train loss:0.7843127863338516\n",
      "train loss:0.8440605667388428\n",
      "train loss:0.7559238747101213\n",
      "train loss:0.9106707327974766\n",
      "train loss:0.9256322211041472\n",
      "train loss:0.9605332889299677\n",
      "train loss:0.8904794335693523\n",
      "train loss:0.93725578532129\n",
      "train loss:0.9189789608512346\n",
      "train loss:0.9320987956542264\n",
      "train loss:0.8456504391985641\n",
      "train loss:0.9514725887554331\n",
      "train loss:0.8486785876810097\n",
      "train loss:0.8226854566446324\n",
      "train loss:0.8200559576971042\n",
      "train loss:0.9380780547391271\n",
      "train loss:0.781755241821094\n",
      "train loss:0.9938662083137038\n",
      "train loss:0.9666313934223725\n",
      "train loss:1.0464312018234898\n",
      "train loss:0.9452271075976872\n",
      "train loss:0.8221525500890877\n",
      "train loss:0.7241438228434938\n",
      "train loss:0.8818862028292801\n",
      "train loss:0.9805179607080418\n",
      "train loss:0.9152295316493203\n",
      "train loss:1.0369685011514589\n",
      "train loss:0.8977686789103907\n",
      "train loss:0.854940920362794\n",
      "train loss:1.0917888264564588\n",
      "train loss:0.9938465480689022\n",
      "train loss:0.9043156699542102\n",
      "train loss:1.0250742643411044\n",
      "train loss:1.0516733054955223\n",
      "train loss:0.8608963510772699\n",
      "train loss:0.8649173158960314\n",
      "train loss:0.80094935201015\n",
      "train loss:0.926270459370694\n",
      "train loss:0.8683236402832122\n",
      "train loss:0.9188237838008323\n",
      "train loss:0.9393066971442953\n",
      "train loss:0.7061056724736471\n",
      "train loss:0.8943772937609742\n",
      "train loss:0.779278421912068\n",
      "train loss:0.917039975675322\n",
      "train loss:0.8595996160980789\n",
      "train loss:0.9545505838209577\n",
      "train loss:0.7581148236420429\n",
      "train loss:0.7766588718641002\n",
      "train loss:0.8912782242181478\n",
      "train loss:0.9978834214159781\n",
      "train loss:0.8649459249691301\n",
      "train loss:0.9041982797242264\n",
      "train loss:0.9829473287658709\n",
      "train loss:0.8081084136785764\n",
      "train loss:1.1019169465849499\n",
      "train loss:0.818694701779848\n",
      "train loss:0.833810872003925\n",
      "train loss:0.9515909172143797\n",
      "train loss:0.82981921632982\n",
      "train loss:0.7846720367455774\n",
      "train loss:1.0952102313541527\n",
      "train loss:0.7779308257602859\n",
      "train loss:0.9971307257082447\n",
      "train loss:0.9152557162553857\n",
      "train loss:1.0191450102132233\n",
      "train loss:0.8493689439440563\n",
      "train loss:0.9053058800497774\n",
      "train loss:0.8762061971031342\n",
      "train loss:0.9016210056779673\n",
      "train loss:1.038997796363569\n",
      "train loss:0.9905117388919557\n",
      "train loss:0.9570589777902948\n",
      "train loss:0.8481195360744783\n",
      "train loss:0.8367354880789102\n",
      "train loss:0.7242005762424\n",
      "train loss:0.9394735081529817\n",
      "train loss:1.1131829431251807\n",
      "train loss:0.911866368852887\n",
      "train loss:0.8888879228665825\n",
      "train loss:0.8277861777374806\n",
      "train loss:0.8411512964266017\n",
      "train loss:0.9513481318293562\n",
      "train loss:0.7492270802499812\n",
      "train loss:0.9156650987790979\n",
      "train loss:0.8726184110921527\n",
      "train loss:1.0116548984460503\n",
      "train loss:0.9104697098596811\n",
      "train loss:0.9261089326295102\n",
      "train loss:0.9898764882779916\n",
      "train loss:0.8641327152544733\n",
      "train loss:1.0058842601738556\n",
      "train loss:0.8630507116810358\n",
      "train loss:0.9522744405283613\n",
      "train loss:0.9224949110118031\n",
      "train loss:0.9608378512305723\n",
      "train loss:0.8037048871830291\n",
      "train loss:0.8481386584258338\n",
      "train loss:0.9500785402225538\n",
      "train loss:0.9129478705750487\n",
      "train loss:1.0263845686030892\n",
      "train loss:0.90079271730986\n",
      "train loss:0.8878623328962608\n",
      "train loss:0.9958069886337482\n",
      "train loss:0.9098178519490525\n",
      "train loss:0.8081641397324788\n",
      "train loss:0.7955707670180183\n",
      "train loss:0.9935790955699076\n",
      "train loss:0.8424103450281889\n",
      "train loss:0.8415706374625025\n",
      "train loss:0.9368974602291539\n",
      "train loss:0.892843937810414\n",
      "train loss:0.6757985757302243\n",
      "train loss:0.9518102819128519\n",
      "train loss:0.7944074884294785\n",
      "train loss:0.9697868637448164\n",
      "train loss:0.957730544277004\n",
      "train loss:0.9356550719870576\n",
      "train loss:0.9467885113532245\n",
      "train loss:0.8755272744283386\n",
      "train loss:0.9841482064808418\n",
      "train loss:0.9387698707890694\n",
      "train loss:0.764362264364651\n",
      "train loss:0.9693352786498802\n",
      "train loss:0.8955381461846657\n",
      "train loss:0.8861539285009034\n",
      "train loss:1.0569820452645649\n",
      "train loss:1.0303859536063689\n",
      "train loss:1.0092846931187425\n",
      "train loss:0.874047508773398\n",
      "train loss:0.82931564527818\n",
      "train loss:1.0612655745688244\n",
      "train loss:0.9369906070267584\n",
      "train loss:0.9857050044081551\n",
      "train loss:0.9938411456250796\n",
      "train loss:1.0540273415679324\n",
      "train loss:1.1347935955757933\n",
      "train loss:0.8654032160480896\n",
      "train loss:0.9454087423955326\n",
      "train loss:0.9438349999607517\n",
      "train loss:0.8784867592057585\n",
      "train loss:0.9755524392929336\n",
      "train loss:0.9883580707842586\n",
      "train loss:0.8398070962922823\n",
      "train loss:0.9687519572942851\n",
      "train loss:0.8954949022577067\n",
      "train loss:0.9889812229539388\n",
      "train loss:0.8393948972380167\n",
      "train loss:0.7987641055696189\n",
      "train loss:0.8475069800772741\n",
      "train loss:0.9507983121921211\n",
      "train loss:0.8912822589395291\n",
      "train loss:0.9599338696697393\n",
      "train loss:0.9391781592313277\n",
      "train loss:0.9447834401035885\n",
      "train loss:0.8298393171276665\n",
      "train loss:0.8371720316598688\n",
      "train loss:0.8700223660297851\n",
      "train loss:0.7602725377064985\n",
      "train loss:0.8667007081067696\n",
      "train loss:0.8824411386102078\n",
      "train loss:0.911959432773338\n",
      "train loss:0.8844389249561644\n",
      "train loss:0.8046315721849063\n",
      "train loss:1.077701075434092\n",
      "train loss:0.7681164419487865\n",
      "train loss:0.9953074606333822\n",
      "train loss:1.0439198697758463\n",
      "train loss:0.9583451263353909\n",
      "train loss:0.7758371715196769\n",
      "train loss:0.9766813508078996\n",
      "train loss:0.8621835428866631\n",
      "train loss:0.8673195902340108\n",
      "train loss:0.8807929151361311\n",
      "train loss:1.0468007754221553\n",
      "train loss:0.9980019173121414\n",
      "train loss:0.9225624571321589\n",
      "train loss:0.8177445395925546\n",
      "train loss:0.9426080400517821\n",
      "train loss:0.929075994995063\n",
      "train loss:1.049733876343207\n",
      "train loss:1.041237464104248\n",
      "train loss:0.9255898397848238\n",
      "train loss:0.8985447575116473\n",
      "train loss:1.0087437119681508\n",
      "train loss:0.9203263524987573\n",
      "train loss:1.017871806200131\n",
      "train loss:1.0075940707811966\n",
      "train loss:0.9612437458078067\n",
      "train loss:0.8439963163121711\n",
      "train loss:0.9521092722778188\n",
      "train loss:1.0850886813210956\n",
      "train loss:0.9600637619504481\n",
      "train loss:0.7517553158178533\n",
      "train loss:0.8481189674576208\n",
      "train loss:0.7482528470338439\n",
      "train loss:0.8879961604939004\n",
      "train loss:0.9978820250885722\n",
      "train loss:0.9409787993300769\n",
      "train loss:0.7775526108249635\n",
      "train loss:0.9717619336955332\n",
      "train loss:1.010918225172818\n",
      "train loss:0.9104366501707978\n",
      "train loss:0.8306714127208303\n",
      "train loss:0.9797040100957191\n",
      "train loss:0.8723501070065208\n",
      "train loss:1.0139519229739309\n",
      "train loss:0.7865317316574654\n",
      "train loss:1.0783457780045278\n",
      "train loss:0.9601007036136696\n",
      "train loss:0.8895387936066776\n",
      "train loss:0.9503210309858617\n",
      "train loss:0.881241123526551\n",
      "train loss:0.8228637353110183\n",
      "train loss:0.8022120773953921\n",
      "train loss:0.9190995713726109\n",
      "train loss:0.958695974162041\n",
      "train loss:0.750599824181958\n",
      "train loss:1.024746805747201\n",
      "train loss:0.933708343149132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9740379741299761\n",
      "train loss:1.131214712202133\n",
      "train loss:0.8994686063643877\n",
      "train loss:0.9158844063076667\n",
      "train loss:1.0447008996020712\n",
      "train loss:0.9604909763599833\n",
      "train loss:0.8349080465478778\n",
      "train loss:1.0136672114469207\n",
      "train loss:0.9371411950820594\n",
      "train loss:0.7561411557632108\n",
      "train loss:1.067344676689912\n",
      "train loss:1.0973229589294857\n",
      "train loss:1.0207028666529498\n",
      "train loss:0.6919905987723791\n",
      "train loss:0.87566575026737\n",
      "train loss:0.7824405767888368\n",
      "train loss:0.9931073055872061\n",
      "train loss:0.8788599942628923\n",
      "train loss:0.8717123353428208\n",
      "train loss:0.900834563301056\n",
      "train loss:1.0528046554452317\n",
      "train loss:0.8138840658247223\n",
      "train loss:0.9741498375066265\n",
      "train loss:1.13955066025139\n",
      "train loss:0.9397911046120402\n",
      "train loss:1.0938251390196012\n",
      "train loss:0.9838683959717214\n",
      "train loss:0.83037982309336\n",
      "train loss:0.8664591345124658\n",
      "train loss:0.9026823699858312\n",
      "train loss:1.0473217102582284\n",
      "train loss:1.0520895177655725\n",
      "train loss:0.8972141260927167\n",
      "train loss:0.8601692292524363\n",
      "train loss:0.8140758779771022\n",
      "train loss:0.9465759347191164\n",
      "train loss:0.8878821149037998\n",
      "train loss:0.8898947005283521\n",
      "train loss:0.69930801744167\n",
      "train loss:0.8899800499489724\n",
      "train loss:0.921468099747344\n",
      "=== epoch:18, train acc:0.987, test acc:0.989 ===\n",
      "train loss:0.9451668743927993\n",
      "train loss:0.9560344980551798\n",
      "train loss:0.8787153665341839\n",
      "train loss:0.9425519630844095\n",
      "train loss:0.9188806286297185\n",
      "train loss:0.7908290528286396\n",
      "train loss:0.9683446688010313\n",
      "train loss:0.9689005016813631\n",
      "train loss:0.8665634188797364\n",
      "train loss:1.0418203968268804\n",
      "train loss:0.8488030901790522\n",
      "train loss:1.035047171951914\n",
      "train loss:0.8049501045662651\n",
      "train loss:0.9859950885894184\n",
      "train loss:0.9233117567420287\n",
      "train loss:0.9579663478997206\n",
      "train loss:0.8804213793511799\n",
      "train loss:1.0732929635225885\n",
      "train loss:0.8692549926669938\n",
      "train loss:1.0062068608228663\n",
      "train loss:0.8878361718365406\n",
      "train loss:1.0064431797734092\n",
      "train loss:0.7774815697701117\n",
      "train loss:1.0144678222118622\n",
      "train loss:0.8389082518018944\n",
      "train loss:0.9441642824696314\n",
      "train loss:0.7568940072569496\n",
      "train loss:0.9173019671098771\n",
      "train loss:0.9725472630812733\n",
      "train loss:0.8666496066261641\n",
      "train loss:0.72881747308982\n",
      "train loss:1.124408708105687\n",
      "train loss:0.8865114036498852\n",
      "train loss:0.9495592309204034\n",
      "train loss:0.9689277161889228\n",
      "train loss:0.9087066613262286\n",
      "train loss:0.7983742733949115\n",
      "train loss:0.9896687479449193\n",
      "train loss:0.8836292045943526\n",
      "train loss:0.9114319990717134\n",
      "train loss:0.9831823930022046\n",
      "train loss:0.7830386719495328\n",
      "train loss:0.9943652996446889\n",
      "train loss:0.784835110105456\n",
      "train loss:0.9177475966393663\n",
      "train loss:1.0839614650192275\n",
      "train loss:0.9008581678094005\n",
      "train loss:1.0132643993277766\n",
      "train loss:0.789254548233786\n",
      "train loss:0.9123228886181554\n",
      "train loss:0.9348375788269544\n",
      "train loss:0.8925893702755302\n",
      "train loss:0.8458753397644863\n",
      "train loss:0.9171660448150887\n",
      "train loss:1.0786552548959598\n",
      "train loss:0.9429863440367373\n",
      "train loss:0.9631979938500207\n",
      "train loss:0.8472813526381404\n",
      "train loss:0.9322271040208205\n",
      "train loss:0.8047097846694957\n",
      "train loss:1.0252787929657083\n",
      "train loss:1.0685706543634375\n",
      "train loss:0.7589654924703848\n",
      "train loss:0.8223512020108843\n",
      "train loss:0.9835441818456827\n",
      "train loss:0.9896994432678735\n",
      "train loss:0.9328469052603502\n",
      "train loss:0.8026214354801272\n",
      "train loss:0.8906012521863446\n",
      "train loss:0.829688784534669\n",
      "train loss:1.23737931882233\n",
      "train loss:1.0727506524317283\n",
      "train loss:1.0893918433243799\n",
      "train loss:0.9161185391984182\n",
      "train loss:1.0783114332816768\n",
      "train loss:1.0382865603619187\n",
      "train loss:0.9804763330835868\n",
      "train loss:0.8354687438557249\n",
      "train loss:0.9265585143569731\n",
      "train loss:0.9705658830277645\n",
      "train loss:0.8671965639852174\n",
      "train loss:0.8598291683600613\n",
      "train loss:1.0696467914520447\n",
      "train loss:0.926782143333343\n",
      "train loss:0.637931382564813\n",
      "train loss:1.1574899377321706\n",
      "train loss:1.016011312568199\n",
      "train loss:0.7063851944569806\n",
      "train loss:0.9935509651702241\n",
      "train loss:0.8977868596283567\n",
      "train loss:0.9722676980698134\n",
      "train loss:1.1386308742535518\n",
      "train loss:0.9622969573761673\n",
      "train loss:0.7780340395539567\n",
      "train loss:1.001142251839391\n",
      "train loss:0.8116584550892999\n",
      "train loss:0.9439634090296096\n",
      "train loss:1.0014665055793923\n",
      "train loss:0.9800928549231677\n",
      "train loss:0.8650235172744007\n",
      "train loss:0.8075321190699539\n",
      "train loss:0.9167775465420149\n",
      "train loss:0.9905778875012443\n",
      "train loss:0.9093835281708703\n",
      "train loss:0.8600923838534352\n",
      "train loss:0.8772718247603091\n",
      "train loss:1.0824380110824006\n",
      "train loss:0.9385229730379772\n",
      "train loss:0.8000367718847664\n",
      "train loss:0.9576013936191364\n",
      "train loss:0.9329648475768528\n",
      "train loss:0.9282142076558821\n",
      "train loss:0.9050189075288657\n",
      "train loss:0.9468449426251253\n",
      "train loss:1.0001279475247622\n",
      "train loss:1.0173389770632055\n",
      "train loss:0.806667526125711\n",
      "train loss:1.0061608139726692\n",
      "train loss:0.9627692775376795\n",
      "train loss:0.8457397290947202\n",
      "train loss:0.8050403568686445\n",
      "train loss:0.8420220618779254\n",
      "train loss:0.8141501943782522\n",
      "train loss:0.8277751403173622\n",
      "train loss:0.7109554200292465\n",
      "train loss:0.9293437312687814\n",
      "train loss:0.84586125367691\n",
      "train loss:0.825781946879669\n",
      "train loss:0.8269881280462716\n",
      "train loss:0.8511200627476521\n",
      "train loss:0.9260688309654346\n",
      "train loss:0.8430607534197087\n",
      "train loss:1.0590150853009863\n",
      "train loss:0.9294730566262251\n",
      "train loss:0.8580871645965202\n",
      "train loss:0.9425580320860973\n",
      "train loss:0.9209717540643436\n",
      "train loss:0.6953433745527018\n",
      "train loss:1.0300725255915772\n",
      "train loss:0.8346987153441535\n",
      "train loss:0.883484139141582\n",
      "train loss:0.7074752224637774\n",
      "train loss:1.1109735686729578\n",
      "train loss:0.8763985997338648\n",
      "train loss:0.9863261692310915\n",
      "train loss:1.0003234499684266\n",
      "train loss:0.8827437306241805\n",
      "train loss:0.959830766127748\n",
      "train loss:0.9455281234937266\n",
      "train loss:0.8639970572763463\n",
      "train loss:1.072511437461799\n",
      "train loss:0.7979448134681368\n",
      "train loss:0.988473795438232\n",
      "train loss:1.0562584152908072\n",
      "train loss:0.8948856389241707\n",
      "train loss:0.8424459734359776\n",
      "train loss:0.9743513399529189\n",
      "train loss:0.8302406996687851\n",
      "train loss:1.0308828814054605\n",
      "train loss:0.7751189202875517\n",
      "train loss:0.6757919517321114\n",
      "train loss:0.8487031144291529\n",
      "train loss:0.8848066723770878\n",
      "train loss:0.8713607914200858\n",
      "train loss:1.0632907981541855\n",
      "train loss:0.9001494373651692\n",
      "train loss:0.8864185401857533\n",
      "train loss:0.8525317708998899\n",
      "train loss:0.8726448478018771\n",
      "train loss:0.9801120688172955\n",
      "train loss:0.9602635418290135\n",
      "train loss:0.9979920024913865\n",
      "train loss:0.9452593579723674\n",
      "train loss:0.8385621789854655\n",
      "train loss:0.8550669036167753\n",
      "train loss:0.8105804772095521\n",
      "train loss:0.9815352420821034\n",
      "train loss:0.9349759855946452\n",
      "train loss:0.9167233550814029\n",
      "train loss:0.7608867995115621\n",
      "train loss:0.9361488459877607\n",
      "train loss:0.9503692705213922\n",
      "train loss:0.8731466776705737\n",
      "train loss:0.7635859731259803\n",
      "train loss:0.9173366028822084\n",
      "train loss:0.8115630197707326\n",
      "train loss:0.8923478470163593\n",
      "train loss:1.0575252667602522\n",
      "train loss:0.8767626920646135\n",
      "train loss:1.033012372763948\n",
      "train loss:0.729451123006627\n",
      "train loss:0.8189848112766639\n",
      "train loss:0.8256591502229589\n",
      "train loss:0.9998246228158143\n",
      "train loss:0.9404068424318468\n",
      "train loss:0.9101059627467037\n",
      "train loss:1.065107268141724\n",
      "train loss:1.123716267637672\n",
      "train loss:0.8461089720096\n",
      "train loss:0.8743639130232961\n",
      "train loss:0.8238910840486351\n",
      "train loss:0.9648778960020123\n",
      "train loss:0.8639045832605291\n",
      "train loss:0.991507154132097\n",
      "train loss:0.8733839381088702\n",
      "train loss:1.0048994914017866\n",
      "train loss:0.9223438135210023\n",
      "train loss:0.9909199069458957\n",
      "train loss:0.9976474909053151\n",
      "train loss:0.8364509187337559\n",
      "train loss:0.9251129685234658\n",
      "train loss:0.8639906572775174\n",
      "train loss:1.0353782468219905\n",
      "train loss:0.9761635190126023\n",
      "train loss:0.9195505339038842\n",
      "train loss:1.1478812828069547\n",
      "train loss:1.0328652942969259\n",
      "train loss:0.832497372312814\n",
      "train loss:0.8341859188573632\n",
      "train loss:0.8779770337011255\n",
      "train loss:1.0528266945237\n",
      "train loss:0.7751371175502839\n",
      "train loss:0.9108548560164196\n",
      "train loss:0.9026489868286715\n",
      "train loss:0.7607974273852476\n",
      "train loss:0.936654934771742\n",
      "train loss:0.9888546241517322\n",
      "train loss:1.0533377486974262\n",
      "train loss:0.9234964091458895\n",
      "train loss:0.8358990367921738\n",
      "train loss:1.0038766642462655\n",
      "train loss:0.844562738057729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9405210641344134\n",
      "train loss:1.0280050004066288\n",
      "train loss:0.9224891021315691\n",
      "train loss:0.919182794207503\n",
      "train loss:0.9130237956452941\n",
      "train loss:0.8660694518507875\n",
      "train loss:0.9253433146018085\n",
      "train loss:0.8711731305125681\n",
      "train loss:0.7434611741301694\n",
      "train loss:0.969011850067906\n",
      "train loss:1.0448173446505449\n",
      "train loss:0.9368056489107626\n",
      "train loss:0.9067788593426114\n",
      "train loss:0.7734785390140101\n",
      "train loss:0.7107112139497519\n",
      "train loss:0.8798236544333394\n",
      "train loss:0.8196842784820189\n",
      "train loss:1.017865035370147\n",
      "train loss:0.8906467975916047\n",
      "train loss:0.9335046022847422\n",
      "train loss:0.903198185618031\n",
      "train loss:0.9673558470129043\n",
      "train loss:1.017438156410344\n",
      "train loss:1.0711536304319094\n",
      "train loss:0.8931199852255189\n",
      "train loss:0.907136470598372\n",
      "train loss:0.9187801420527917\n",
      "train loss:0.9134453716690062\n",
      "train loss:0.9990784029736771\n",
      "train loss:0.7482051022985102\n",
      "train loss:0.7535872240708374\n",
      "train loss:0.8103926700019588\n",
      "train loss:0.8205974500361328\n",
      "train loss:0.8709622688514306\n",
      "train loss:0.9007925733130083\n",
      "train loss:0.9906095122799501\n",
      "train loss:0.8407348137552862\n",
      "train loss:0.9168679588061821\n",
      "train loss:0.9026899164286354\n",
      "train loss:0.8277526664957263\n",
      "train loss:0.7849132889302618\n",
      "train loss:1.0767451392667169\n",
      "train loss:0.9330753658441597\n",
      "train loss:0.8556239185367097\n",
      "train loss:0.8103398674096206\n",
      "train loss:0.91638394405619\n",
      "train loss:0.7724245016702848\n",
      "train loss:0.8826368423993045\n",
      "train loss:0.7955327311299775\n",
      "train loss:1.0138884254536287\n",
      "train loss:0.7353534751651921\n",
      "train loss:0.9166095067940102\n",
      "train loss:0.9077967493812966\n",
      "train loss:0.9125952138249178\n",
      "train loss:0.8606155044784909\n",
      "train loss:0.8713528729398468\n",
      "train loss:0.9455412306307879\n",
      "train loss:0.9119866423721557\n",
      "train loss:1.032918701479523\n",
      "train loss:0.9496996947772363\n",
      "train loss:0.9540313246349517\n",
      "train loss:0.7735332692706216\n",
      "train loss:0.9000506095024293\n",
      "train loss:0.9862868984409703\n",
      "train loss:0.8865193861851224\n",
      "train loss:0.8635289517448166\n",
      "train loss:0.9116715394462286\n",
      "train loss:0.9379985348023618\n",
      "train loss:1.066944519900337\n",
      "train loss:0.8088667042908368\n",
      "train loss:0.9979813615090407\n",
      "train loss:0.7860183607646138\n",
      "train loss:0.8403979415926733\n",
      "train loss:0.867989152226762\n",
      "train loss:0.8700443118861111\n",
      "train loss:0.9915087743817531\n",
      "train loss:0.9700898388323584\n",
      "train loss:1.1177282860801276\n",
      "train loss:0.8873306966748186\n",
      "train loss:0.8769300619655881\n",
      "train loss:0.8816096593104688\n",
      "train loss:0.9495221479297652\n",
      "train loss:0.9204776377616907\n",
      "train loss:0.9095348714962701\n",
      "train loss:0.854306329409591\n",
      "train loss:0.9266397211219563\n",
      "train loss:0.9561996110866504\n",
      "train loss:1.0514064499183036\n",
      "train loss:0.8310820920734265\n",
      "train loss:0.9948330898690044\n",
      "train loss:0.9765541101606052\n",
      "train loss:0.8705825003437273\n",
      "train loss:0.9552433539562466\n",
      "train loss:1.0234224409176784\n",
      "train loss:0.814952487080874\n",
      "train loss:0.9311951257404972\n",
      "train loss:0.8104748163171738\n",
      "train loss:0.941929313923369\n",
      "train loss:1.0068905637609191\n",
      "train loss:0.9333783788454211\n",
      "train loss:0.7675769764014668\n",
      "train loss:1.2037453229235588\n",
      "train loss:0.8984824214152531\n",
      "train loss:0.9497011733448537\n",
      "train loss:1.0124691977037932\n",
      "train loss:0.8896472438435619\n",
      "train loss:1.0566192793216929\n",
      "train loss:0.7845457472705313\n",
      "train loss:0.9044979256247412\n",
      "train loss:1.045563205602793\n",
      "train loss:0.9960617773039384\n",
      "train loss:0.8502887782842614\n",
      "train loss:0.9344355740322909\n",
      "train loss:0.9889171025562683\n",
      "train loss:0.9682236923186254\n",
      "train loss:0.8847297475390055\n",
      "train loss:0.8977884797045915\n",
      "train loss:0.8853654785059974\n",
      "train loss:1.0730649555102252\n",
      "train loss:0.9585266607832972\n",
      "train loss:1.0228744364190947\n",
      "train loss:0.8017061565261022\n",
      "train loss:1.0753150621544227\n",
      "train loss:0.9977603322313757\n",
      "train loss:0.8781758032992922\n",
      "train loss:0.9249490202397479\n",
      "train loss:0.7384672055227717\n",
      "train loss:1.0475910081149988\n",
      "train loss:0.9470054972908172\n",
      "train loss:0.9837182443681339\n",
      "train loss:1.034388492791697\n",
      "train loss:0.9892357417231734\n",
      "train loss:0.9849995426937446\n",
      "train loss:0.8147691104133808\n",
      "train loss:0.7985812365059239\n",
      "train loss:1.0339099760254198\n",
      "train loss:0.7403831310983807\n",
      "train loss:0.8781819922959312\n",
      "train loss:0.8615624614586427\n",
      "train loss:0.8825218082768219\n",
      "train loss:1.0014987756843259\n",
      "train loss:0.83970940769705\n",
      "train loss:1.0470160338516414\n",
      "train loss:0.8955743050103755\n",
      "train loss:0.872743646450624\n",
      "train loss:0.9518252134480103\n",
      "train loss:0.9229331157325228\n",
      "train loss:0.8395322206386114\n",
      "train loss:0.8737547796252033\n",
      "train loss:0.8288606173647933\n",
      "train loss:0.950709159215712\n",
      "train loss:0.9047315096874884\n",
      "train loss:0.8348643709649174\n",
      "train loss:0.7626750454357932\n",
      "train loss:0.866279800128319\n",
      "train loss:0.8130354807288329\n",
      "train loss:0.7485263343516525\n",
      "train loss:0.9582709746865686\n",
      "train loss:0.8924483389792279\n",
      "train loss:0.9215439712667998\n",
      "train loss:0.90664347736149\n",
      "train loss:0.8289411281740696\n",
      "train loss:1.007076497214643\n",
      "train loss:0.7084431935935972\n",
      "train loss:1.0377670161754642\n",
      "train loss:0.9165171395858414\n",
      "train loss:0.8809959125146608\n",
      "train loss:0.8270618168556143\n",
      "train loss:0.7959369807173766\n",
      "train loss:0.9363518596118471\n",
      "train loss:0.9067146221543257\n",
      "train loss:0.95826082278543\n",
      "train loss:0.8996148246402833\n",
      "train loss:0.8553568371473408\n",
      "train loss:0.9259676687435217\n",
      "train loss:0.9619357370809611\n",
      "train loss:1.1174906445638932\n",
      "train loss:1.0072114988079317\n",
      "train loss:0.8140024130229625\n",
      "train loss:0.9861557708963956\n",
      "train loss:0.7616620584521411\n",
      "train loss:0.925432386162893\n",
      "train loss:1.028284364844025\n",
      "train loss:0.8533310575003906\n",
      "train loss:0.8561353713547968\n",
      "train loss:0.8922894125112699\n",
      "train loss:0.9786959065200714\n",
      "train loss:0.9872532196402422\n",
      "train loss:0.807838131965183\n",
      "train loss:0.7921819261866014\n",
      "train loss:0.9043491626779335\n",
      "train loss:0.8994946242832481\n",
      "train loss:0.9188445998971\n",
      "train loss:0.9491943861989333\n",
      "train loss:0.892278531708919\n",
      "train loss:0.7557785620979434\n",
      "train loss:1.0261906722951875\n",
      "train loss:0.9178659547700764\n",
      "train loss:0.875420696475444\n",
      "train loss:0.7671653034013652\n",
      "train loss:0.8121406349792291\n",
      "train loss:0.9022141468257971\n",
      "train loss:1.0993551368451873\n",
      "train loss:0.7753065968665033\n",
      "train loss:0.9043690812468972\n",
      "train loss:0.9155055174621358\n",
      "train loss:0.9936560578611053\n",
      "train loss:0.7663199320929298\n",
      "train loss:1.0556525909356407\n",
      "train loss:0.916535111349702\n",
      "train loss:0.9388445441581136\n",
      "train loss:0.9463639021046852\n",
      "train loss:0.9626423958709611\n",
      "train loss:0.7745086079214114\n",
      "train loss:0.9231830416963426\n",
      "train loss:0.9023023520157433\n",
      "train loss:0.9405961779202076\n",
      "train loss:0.9659338535335152\n",
      "train loss:0.9805708303195899\n",
      "train loss:0.908093317635338\n",
      "train loss:0.9152155073482107\n",
      "train loss:0.8758638769251473\n",
      "train loss:0.8207214913548871\n",
      "train loss:0.9286899014701162\n",
      "train loss:0.824465900899545\n",
      "train loss:0.9842137459359435\n",
      "train loss:0.9908257641579559\n",
      "train loss:1.0885244905169456\n",
      "train loss:0.9687679219143991\n",
      "train loss:0.9234222168624061\n",
      "train loss:0.9228289063597751\n",
      "train loss:0.8020151609555515\n",
      "train loss:0.8213396578547806\n",
      "train loss:0.9739308602545533\n",
      "train loss:0.8209043483390923\n",
      "train loss:0.881290136335089\n",
      "train loss:0.9817543495646475\n",
      "train loss:0.9565081173722332\n",
      "train loss:0.7607062308799264\n",
      "train loss:0.8930093219829903\n",
      "train loss:0.9092119325138771\n",
      "train loss:0.9774239548267117\n",
      "train loss:0.857614085798707\n",
      "train loss:0.9185012022331879\n",
      "train loss:0.9434063284107824\n",
      "train loss:0.7362096703310589\n",
      "train loss:0.7667294238359206\n",
      "train loss:0.9619031562065727\n",
      "train loss:0.9554582006929904\n",
      "train loss:1.1052127127270222\n",
      "train loss:0.8172341884578771\n",
      "train loss:0.7868299514791492\n",
      "train loss:0.8940038217284976\n",
      "train loss:0.8720294220529933\n",
      "train loss:1.0490458186002771\n",
      "train loss:0.866784831719059\n",
      "train loss:0.8443573760196785\n",
      "train loss:0.8773706479739255\n",
      "train loss:0.8308218846292348\n",
      "train loss:0.8693729385674865\n",
      "train loss:0.9758266114039066\n",
      "train loss:1.0607755640610683\n",
      "train loss:0.8742982700533243\n",
      "train loss:0.8969919314811614\n",
      "train loss:0.8974609649633633\n",
      "train loss:0.7452388412427315\n",
      "train loss:0.8917631586852488\n",
      "train loss:0.9200214016417472\n",
      "train loss:0.9057295758183156\n",
      "train loss:0.9878309523393312\n",
      "train loss:0.9334270728478167\n",
      "train loss:0.9612176701326771\n",
      "train loss:0.8860755705142443\n",
      "train loss:0.8335456179435667\n",
      "train loss:0.9218122414304503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7879743315228103\n",
      "train loss:0.9057188066851406\n",
      "train loss:0.9012536612470172\n",
      "train loss:0.9773321878186928\n",
      "train loss:0.8271342806677581\n",
      "train loss:0.8292502917730706\n",
      "train loss:0.9272229440237518\n",
      "train loss:0.8352232838015723\n",
      "train loss:0.883087345462271\n",
      "train loss:0.8085822668247544\n",
      "train loss:1.0041362562631908\n",
      "train loss:0.682774688580181\n",
      "train loss:1.143950652041266\n",
      "train loss:0.8470817588458881\n",
      "train loss:1.0210627246438992\n",
      "train loss:0.8518095764696858\n",
      "train loss:0.8409885378307898\n",
      "train loss:0.9818943825511615\n",
      "train loss:0.9594594623551298\n",
      "train loss:0.7542108765836708\n",
      "train loss:1.0396426010084772\n",
      "train loss:0.9673463919858021\n",
      "train loss:0.9977996745000989\n",
      "train loss:0.8763468061450952\n",
      "train loss:1.0564901445693835\n",
      "train loss:0.787870379139444\n",
      "train loss:0.7560877595828457\n",
      "train loss:0.7471210321511883\n",
      "train loss:0.8928934506638929\n",
      "train loss:0.6804515470242275\n",
      "train loss:0.9669063926783434\n",
      "train loss:0.8649222751786105\n",
      "train loss:1.0557992733617767\n",
      "train loss:1.0594619202154603\n",
      "train loss:0.9306069544013706\n",
      "train loss:0.95051678799515\n",
      "train loss:0.9804888893940609\n",
      "train loss:0.9002021636129333\n",
      "train loss:0.9767676354668757\n",
      "train loss:0.8873960579772251\n",
      "train loss:0.7139045958446095\n",
      "train loss:0.9228603387716356\n",
      "train loss:1.0866932476464908\n",
      "train loss:0.8090666545478145\n",
      "train loss:1.0540512411294876\n",
      "train loss:0.8436777985585302\n",
      "train loss:0.9679408652632394\n",
      "train loss:0.8764136188930225\n",
      "train loss:1.0265034523423657\n",
      "train loss:0.8107078793641592\n",
      "train loss:0.8574623627345187\n",
      "train loss:0.9410773309491941\n",
      "train loss:0.9101169624890794\n",
      "train loss:0.9234902198914618\n",
      "train loss:0.7445370286222961\n",
      "train loss:1.0160566483302365\n",
      "train loss:0.8972926768933229\n",
      "train loss:0.939635962289831\n",
      "train loss:0.8175071818817432\n",
      "train loss:1.014664523543364\n",
      "train loss:0.7871082780564487\n",
      "train loss:0.9430940808878446\n",
      "train loss:0.8017494586471113\n",
      "train loss:0.8538412701008303\n",
      "train loss:0.7637843622693653\n",
      "train loss:0.7566901563686502\n",
      "train loss:0.9133879234849905\n",
      "train loss:0.8588480715447286\n",
      "train loss:0.8937014757325378\n",
      "train loss:0.8789290201616167\n",
      "train loss:0.7445523296621736\n",
      "train loss:0.9158427444244163\n",
      "train loss:0.8560158596359113\n",
      "train loss:1.0062700718680546\n",
      "train loss:0.7824504436160966\n",
      "train loss:0.8033466479349934\n",
      "train loss:0.9433143319189631\n",
      "train loss:0.7289030586642616\n",
      "train loss:0.8146019889116056\n",
      "train loss:0.8993086446273795\n",
      "train loss:0.9587516473011028\n",
      "train loss:0.7426823949540975\n",
      "train loss:0.9709983734356638\n",
      "train loss:1.0335745477809766\n",
      "train loss:0.97324254202835\n",
      "train loss:0.9761092361917862\n",
      "train loss:0.833975937964384\n",
      "train loss:0.9129593492974084\n",
      "train loss:0.8499850588425949\n",
      "train loss:0.8334812782164286\n",
      "train loss:0.9555133125795785\n",
      "train loss:0.8209100907986874\n",
      "train loss:1.0475310120522157\n",
      "=== epoch:19, train acc:0.991, test acc:0.993 ===\n",
      "train loss:0.7234967060306242\n",
      "train loss:0.7865369136829545\n",
      "train loss:0.9049921447519771\n",
      "train loss:0.7038647560295179\n",
      "train loss:0.864742201708632\n",
      "train loss:0.8826746375385965\n",
      "train loss:0.998241429214513\n",
      "train loss:0.8626297498691148\n",
      "train loss:0.9343801770304705\n",
      "train loss:0.842295472414299\n",
      "train loss:0.9013183706319358\n",
      "train loss:1.0407640811560224\n",
      "train loss:0.782994605734421\n",
      "train loss:0.9263138221770856\n",
      "train loss:0.9116078168778646\n",
      "train loss:0.8842245242548512\n",
      "train loss:1.040567110799147\n",
      "train loss:0.8190464328238726\n",
      "train loss:1.044305104882625\n",
      "train loss:0.9391659543461615\n",
      "train loss:0.8983402047976421\n",
      "train loss:0.9604672289484548\n",
      "train loss:0.8104444701649942\n",
      "train loss:1.0274225790589313\n",
      "train loss:0.9055503327193094\n",
      "train loss:0.8023277849497374\n",
      "train loss:0.7917039820800413\n",
      "train loss:1.006642906436617\n",
      "train loss:1.2057430238102835\n",
      "train loss:0.9505573108338926\n",
      "train loss:0.8247090578434636\n",
      "train loss:1.0305547212526245\n",
      "train loss:0.8501984513735191\n",
      "train loss:1.0162556285611992\n",
      "train loss:0.9436628813540979\n",
      "train loss:0.9059201555903972\n",
      "train loss:0.9016792839527455\n",
      "train loss:0.8074329196950255\n",
      "train loss:0.9063892445262286\n",
      "train loss:0.9260573687690554\n",
      "train loss:0.8435975496031348\n",
      "train loss:0.8563233146925374\n",
      "train loss:0.9330874325884411\n",
      "train loss:0.9652485307485688\n",
      "train loss:0.9005903834948144\n",
      "train loss:0.9660784402633803\n",
      "train loss:0.9937214991347183\n",
      "train loss:0.9228163520038413\n",
      "train loss:0.8367971970720892\n",
      "train loss:0.8832454869665134\n",
      "train loss:0.8210880620318409\n",
      "train loss:0.9276326327018382\n",
      "train loss:0.8386297756463874\n",
      "train loss:0.9332199739201384\n",
      "train loss:0.8376105462723185\n",
      "train loss:0.9360423032219002\n",
      "train loss:0.9891340999760325\n",
      "train loss:0.9017020245038638\n",
      "train loss:0.8045579107102333\n",
      "train loss:1.0617883566343531\n",
      "train loss:0.9582243160878636\n",
      "train loss:0.8032058160962248\n",
      "train loss:0.8109171126396381\n",
      "train loss:0.9190595555174964\n",
      "train loss:0.9070613605161095\n",
      "train loss:0.887199077575018\n",
      "train loss:0.8069110674666687\n",
      "train loss:0.9341553355916673\n",
      "train loss:1.0363548519951302\n",
      "train loss:0.9635972354275044\n",
      "train loss:0.9135984115686001\n",
      "train loss:1.0021685612427458\n",
      "train loss:0.9821736506604443\n",
      "train loss:0.8959889082473644\n",
      "train loss:0.9478589387158151\n",
      "train loss:0.8817561110842899\n",
      "train loss:0.6320093412601016\n",
      "train loss:0.7399455912092786\n",
      "train loss:0.9255551437028565\n",
      "train loss:0.8824312085935097\n",
      "train loss:0.736298978276439\n",
      "train loss:1.0655490551092333\n",
      "train loss:0.9147364987663003\n",
      "train loss:0.9480921014592706\n",
      "train loss:1.1168681124149547\n",
      "train loss:0.9665522197720402\n",
      "train loss:0.721463530830863\n",
      "train loss:0.9377466123063283\n",
      "train loss:0.8063784032727142\n",
      "train loss:0.8052684397154529\n",
      "train loss:1.0086025970168095\n",
      "train loss:0.914303115538474\n",
      "train loss:0.9791009937077959\n",
      "train loss:0.9990867319206115\n",
      "train loss:0.9804346777946443\n",
      "train loss:0.9573986256320707\n",
      "train loss:0.9247128760419823\n",
      "train loss:0.7601468906598909\n",
      "train loss:0.9039583523897092\n",
      "train loss:0.9404794220014472\n",
      "train loss:0.925465283207914\n",
      "train loss:0.8379257187646726\n",
      "train loss:0.9524090687499868\n",
      "train loss:0.9089361087656732\n",
      "train loss:0.8346426820363065\n",
      "train loss:1.0878264784699025\n",
      "train loss:0.8829157412757618\n",
      "train loss:0.9319389185052135\n",
      "train loss:0.7343080785638202\n",
      "train loss:0.9257064765036734\n",
      "train loss:0.9083139658994441\n",
      "train loss:0.8792773008135947\n",
      "train loss:0.8803922838184611\n",
      "train loss:1.0048916665125411\n",
      "train loss:0.8879335628362646\n",
      "train loss:0.9774530024127712\n",
      "train loss:0.8677783474589273\n",
      "train loss:0.8150008586392411\n",
      "train loss:0.8836360174783887\n",
      "train loss:0.725543228085021\n",
      "train loss:0.8662270666697143\n",
      "train loss:0.9862866936646628\n",
      "train loss:0.8941644363573624\n",
      "train loss:0.8083227543478703\n",
      "train loss:0.8511251594990634\n",
      "train loss:0.8319336155142885\n",
      "train loss:0.7735690460544727\n",
      "train loss:1.072893126530489\n",
      "train loss:0.9179001136102433\n",
      "train loss:1.1079944551073928\n",
      "train loss:0.9525834782058306\n",
      "train loss:0.8266021679143185\n",
      "train loss:0.960974035259797\n",
      "train loss:0.8553152519744844\n",
      "train loss:0.8931072199934832\n",
      "train loss:0.8378418848815372\n",
      "train loss:0.8762106622593262\n",
      "train loss:1.1071154689931268\n",
      "train loss:0.8606052713638548\n",
      "train loss:0.9271727113138867\n",
      "train loss:0.9114979080604445\n",
      "train loss:0.7210406119149552\n",
      "train loss:0.8471977056673168\n",
      "train loss:0.9231798304954111\n",
      "train loss:0.9168398536304866\n",
      "train loss:0.8208377365556323\n",
      "train loss:0.9285922808771809\n",
      "train loss:0.7630669239922794\n",
      "train loss:1.0041301051492226\n",
      "train loss:0.8962405288904768\n",
      "train loss:0.8596695975047599\n",
      "train loss:0.8630360105666993\n",
      "train loss:0.8049108169468988\n",
      "train loss:0.9742748307423034\n",
      "train loss:0.8310526765481783\n",
      "train loss:0.9146532018913942\n",
      "train loss:0.8809704823603102\n",
      "train loss:1.0613129052659172\n",
      "train loss:0.8207728524495566\n",
      "train loss:0.8995317308519065\n",
      "train loss:1.0375599193632592\n",
      "train loss:0.903152384840974\n",
      "train loss:0.9419991142850037\n",
      "train loss:0.8540647748867259\n",
      "train loss:0.9143791866402958\n",
      "train loss:0.9195090184215274\n",
      "train loss:0.841245560910404\n",
      "train loss:1.0048183263446733\n",
      "train loss:0.932039016659819\n",
      "train loss:0.9586815143601882\n",
      "train loss:0.9377328702560341\n",
      "train loss:0.7883412898400334\n",
      "train loss:1.045074987048788\n",
      "train loss:0.8478062159979946\n",
      "train loss:0.9570568900136212\n",
      "train loss:0.7198577677477447\n",
      "train loss:0.8625416696228408\n",
      "train loss:0.8738056027725689\n",
      "train loss:0.7910479722822362\n",
      "train loss:0.8678234853590632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8006856085627784\n",
      "train loss:0.9281215024048389\n",
      "train loss:0.9812214309309407\n",
      "train loss:0.7164660267087848\n",
      "train loss:0.9220463394553805\n",
      "train loss:0.8132578101276312\n",
      "train loss:0.8774203992998919\n",
      "train loss:0.6729949315661596\n",
      "train loss:0.990640687720292\n",
      "train loss:0.9919873489221888\n",
      "train loss:0.9027922903757144\n",
      "train loss:0.8619788459376941\n",
      "train loss:0.9594906251379995\n",
      "train loss:0.8080953448261853\n",
      "train loss:0.8724811430648338\n",
      "train loss:1.0417684027477234\n",
      "train loss:0.9794012170008604\n",
      "train loss:0.8060644092216279\n",
      "train loss:0.8440623756818568\n",
      "train loss:0.8508234731648485\n",
      "train loss:0.7978774214748148\n",
      "train loss:0.6737409995720938\n",
      "train loss:0.9722460193758786\n",
      "train loss:1.0569378806356384\n",
      "train loss:0.8384029357737799\n",
      "train loss:0.7787417171640911\n",
      "train loss:1.0003136644838087\n",
      "train loss:0.8600887126321222\n",
      "train loss:1.0434792044894305\n",
      "train loss:0.8767240383269918\n",
      "train loss:0.8792381997084853\n",
      "train loss:0.9937789145110711\n",
      "train loss:0.9771345571309316\n",
      "train loss:0.8211156286925657\n",
      "train loss:0.8578424935732281\n",
      "train loss:1.051667795486583\n",
      "train loss:0.939272014233001\n",
      "train loss:0.9134860048076874\n",
      "train loss:0.9446674631221229\n",
      "train loss:0.9344795533496069\n",
      "train loss:0.8267690223027933\n",
      "train loss:0.8581457762385688\n",
      "train loss:0.9005438499246193\n",
      "train loss:0.7373532464384212\n",
      "train loss:0.8927476434507433\n",
      "train loss:0.9075568432528793\n",
      "train loss:0.9720120144221859\n",
      "train loss:0.9375753909500346\n",
      "train loss:1.01307045782883\n",
      "train loss:0.9389225022392595\n",
      "train loss:0.9202842322694126\n",
      "train loss:0.9349448635475202\n",
      "train loss:0.8072396839289007\n",
      "train loss:0.8601660532276718\n",
      "train loss:0.8843103906410067\n",
      "train loss:0.8571624958658088\n",
      "train loss:0.8441708226018033\n",
      "train loss:0.8881993183160979\n",
      "train loss:0.8331809292486152\n",
      "train loss:0.9425692264317135\n",
      "train loss:0.9231539953204633\n",
      "train loss:0.9308162521278992\n",
      "train loss:0.8160788290653694\n",
      "train loss:0.9725962638688808\n",
      "train loss:1.026973155507401\n",
      "train loss:0.8039878925206321\n",
      "train loss:0.9288294680468954\n",
      "train loss:0.7561558948590961\n",
      "train loss:0.9867195018907462\n",
      "train loss:0.8655126645402094\n",
      "train loss:0.7521625455271768\n",
      "train loss:0.8187560788934155\n",
      "train loss:0.9456799531633289\n",
      "train loss:0.9262634955069063\n",
      "train loss:0.826854343703908\n",
      "train loss:1.140038277587171\n",
      "train loss:0.9547799991998775\n",
      "train loss:0.9779995638717602\n",
      "train loss:1.0677807245980615\n",
      "train loss:0.9413471333455355\n",
      "train loss:0.9334005969252341\n",
      "train loss:0.8251407725234969\n",
      "train loss:0.9937724038485999\n",
      "train loss:0.8263615613809979\n",
      "train loss:0.8597215117245242\n",
      "train loss:0.885986157276005\n",
      "train loss:0.9603654233911495\n",
      "train loss:0.76785694857943\n",
      "train loss:0.8248456697223736\n",
      "train loss:0.9378767934690506\n",
      "train loss:0.8361653235184147\n",
      "train loss:1.0014410874017272\n",
      "train loss:0.988171451343124\n",
      "train loss:0.777340544313344\n",
      "train loss:0.8290220854065125\n",
      "train loss:0.8826890883509418\n",
      "train loss:0.8693418390177406\n",
      "train loss:0.7711910131504317\n",
      "train loss:0.9169606267949959\n",
      "train loss:0.8491073316876268\n",
      "train loss:0.9969113939290096\n",
      "train loss:0.8936401239896063\n",
      "train loss:0.8521345700890098\n",
      "train loss:0.9296652498133934\n",
      "train loss:0.8295416918103021\n",
      "train loss:0.9633153553053456\n",
      "train loss:0.9123461270684236\n",
      "train loss:0.8316598669007773\n",
      "train loss:0.9895324088582937\n",
      "train loss:1.0425001561268656\n",
      "train loss:0.8102150127611053\n",
      "train loss:0.7577335600527753\n",
      "train loss:0.764738099217558\n",
      "train loss:0.8925077495033196\n",
      "train loss:0.8772372514440485\n",
      "train loss:0.9885502642926535\n",
      "train loss:0.8373785440492182\n",
      "train loss:1.0640154432559896\n",
      "train loss:1.1086758380042356\n",
      "train loss:1.0093884619509084\n",
      "train loss:0.8801406959836479\n",
      "train loss:0.8935059084051304\n",
      "train loss:0.8885790080151833\n",
      "train loss:0.802517604145813\n",
      "train loss:0.9307611306458248\n",
      "train loss:0.977003864185567\n",
      "train loss:0.9127160315329051\n",
      "train loss:0.8900556224743871\n",
      "train loss:0.8161820682828477\n",
      "train loss:0.8319820138074283\n",
      "train loss:0.8738370523287312\n",
      "train loss:0.8272600395690772\n",
      "train loss:0.7556058956630929\n",
      "train loss:0.8135413995606495\n",
      "train loss:0.8213093594012219\n",
      "train loss:0.837733212180794\n",
      "train loss:0.984003784627321\n",
      "train loss:1.0095406209337574\n",
      "train loss:0.8589185327806902\n",
      "train loss:1.06209380329101\n",
      "train loss:0.864722362548319\n",
      "train loss:0.9198156898519951\n",
      "train loss:0.8831132168949083\n",
      "train loss:0.8727745861914943\n",
      "train loss:0.9461304151071929\n",
      "train loss:0.8532269545270093\n",
      "train loss:0.7460078717776096\n",
      "train loss:0.9077765565128764\n",
      "train loss:0.868937037298769\n",
      "train loss:0.8194193737613915\n",
      "train loss:0.8852593330832361\n",
      "train loss:0.9370222501493874\n",
      "train loss:1.0187705646150587\n",
      "train loss:0.8704866321765367\n",
      "train loss:1.0675304596983723\n",
      "train loss:0.951586304047059\n",
      "train loss:1.0626865615915382\n",
      "train loss:1.0470508734326793\n",
      "train loss:0.8708429749544419\n",
      "train loss:0.8514967314036435\n",
      "train loss:0.8297006252192967\n",
      "train loss:0.8326095203955388\n",
      "train loss:0.8277396503339942\n",
      "train loss:0.9078408278904678\n",
      "train loss:0.9421166360930806\n",
      "train loss:1.073425301136306\n",
      "train loss:0.9230030462296231\n",
      "train loss:0.8457183319597621\n",
      "train loss:0.9452861874737138\n",
      "train loss:0.8980463640222345\n",
      "train loss:1.0142683745882173\n",
      "train loss:0.803162204810132\n",
      "train loss:1.0162909489087608\n",
      "train loss:0.9380846638322332\n",
      "train loss:0.9277227889255409\n",
      "train loss:0.8836005660072814\n",
      "train loss:0.8127324465441564\n",
      "train loss:1.147958544155011\n",
      "train loss:0.7736133503514118\n",
      "train loss:1.028078060814466\n",
      "train loss:0.9255164522268866\n",
      "train loss:1.0063651104861624\n",
      "train loss:0.7887059606071867\n",
      "train loss:0.8135784599760066\n",
      "train loss:0.9430588095996103\n",
      "train loss:0.881942691540869\n",
      "train loss:1.0366643698396174\n",
      "train loss:0.8554993282008951\n",
      "train loss:0.8235495459657974\n",
      "train loss:0.950379535988425\n",
      "train loss:0.6849547665747344\n",
      "train loss:0.7855952172139996\n",
      "train loss:0.9459276780625467\n",
      "train loss:0.8803547512619981\n",
      "train loss:1.0987943531297222\n",
      "train loss:0.8972504484311647\n",
      "train loss:0.8116641218309614\n",
      "train loss:0.7314331331791177\n",
      "train loss:0.8924068619584554\n",
      "train loss:0.8875239017278631\n",
      "train loss:0.874736427711462\n",
      "train loss:0.9997895507133883\n",
      "train loss:0.7983934799687691\n",
      "train loss:1.0555558871972004\n",
      "train loss:1.0639996282576059\n",
      "train loss:0.9389552059866424\n",
      "train loss:1.1311676045835395\n",
      "train loss:0.7843700698136565\n",
      "train loss:0.8069292124397992\n",
      "train loss:0.8893289291336427\n",
      "train loss:0.918377238213246\n",
      "train loss:1.0488590408154426\n",
      "train loss:1.0031695954570288\n",
      "train loss:0.928363801559172\n",
      "train loss:0.9447162175597862\n",
      "train loss:0.7211804865118558\n",
      "train loss:0.9293521881840877\n",
      "train loss:1.0284937221208517\n",
      "train loss:0.9224234281868802\n",
      "train loss:0.9568560726295914\n",
      "train loss:0.9114399962534769\n",
      "train loss:0.9451281750514433\n",
      "train loss:0.9217742526804347\n",
      "train loss:0.9374906602673155\n",
      "train loss:0.9656905529325597\n",
      "train loss:0.9772417451748155\n",
      "train loss:0.7013725488278211\n",
      "train loss:0.877524943216979\n",
      "train loss:0.7406076882046431\n",
      "train loss:0.8789000901947271\n",
      "train loss:0.8556622983028481\n",
      "train loss:0.9749055937624429\n",
      "train loss:0.8985974315175949\n",
      "train loss:0.944589098871633\n",
      "train loss:0.8796952391203089\n",
      "train loss:1.0584541791475575\n",
      "train loss:0.7943563555608768\n",
      "train loss:0.959171180887914\n",
      "train loss:1.0722057951877297\n",
      "train loss:1.1145493320086504\n",
      "train loss:0.841312405214652\n",
      "train loss:0.9534966023878682\n",
      "train loss:0.7499016676924188\n",
      "train loss:0.7591801257751942\n",
      "train loss:0.9269982302375517\n",
      "train loss:0.834885074508622\n",
      "train loss:0.9697088545502092\n",
      "train loss:0.9404000852452961\n",
      "train loss:0.9147883022669723\n",
      "train loss:0.8561509077453218\n",
      "train loss:1.0095043710845781\n",
      "train loss:0.8958137790934917\n",
      "train loss:0.9579789563070901\n",
      "train loss:0.8859235607694446\n",
      "train loss:0.9286899354305699\n",
      "train loss:0.9140701615068214\n",
      "train loss:1.0404439956208917\n",
      "train loss:1.1040229572058584\n",
      "train loss:0.9048279420862183\n",
      "train loss:0.9807096843388861\n",
      "train loss:0.7992786056137315\n",
      "train loss:0.7318286167014747\n",
      "train loss:0.9111859538625243\n",
      "train loss:0.914142663262359\n",
      "train loss:0.7581276684314636\n",
      "train loss:0.8218039009837409\n",
      "train loss:0.8422917342443434\n",
      "train loss:0.8971915926592424\n",
      "train loss:0.9290801212384\n",
      "train loss:1.115667208198639\n",
      "train loss:0.8901571285154444\n",
      "train loss:0.762195184622571\n",
      "train loss:0.924546793611817\n",
      "train loss:0.8991501900994625\n",
      "train loss:0.7672964496144314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8674463347210204\n",
      "train loss:0.9359732288347195\n",
      "train loss:0.8674888188380383\n",
      "train loss:0.8758750191409067\n",
      "train loss:1.0133809644823462\n",
      "train loss:0.9979669360047372\n",
      "train loss:0.9650054308300758\n",
      "train loss:0.8721784184226703\n",
      "train loss:0.9013382156084968\n",
      "train loss:0.8886693272724179\n",
      "train loss:0.6724013536651259\n",
      "train loss:0.8026466266346897\n",
      "train loss:0.8244638167460816\n",
      "train loss:1.0306933286422255\n",
      "train loss:0.7416161748024757\n",
      "train loss:0.9842839184179323\n",
      "train loss:0.8934885122764272\n",
      "train loss:0.8804402560014559\n",
      "train loss:0.8130476545785537\n",
      "train loss:0.8198353821583588\n",
      "train loss:0.9459386227307344\n",
      "train loss:0.9753739608499429\n",
      "train loss:1.010078140273125\n",
      "train loss:0.9424782441278129\n",
      "train loss:0.8571393938380528\n",
      "train loss:0.9369028368119156\n",
      "train loss:1.1438134451046\n",
      "train loss:0.9218423709209657\n",
      "train loss:0.895207743945777\n",
      "train loss:0.9868930861812467\n",
      "train loss:0.8794169457519264\n",
      "train loss:0.7923321063759148\n",
      "train loss:1.0204981856521373\n",
      "train loss:0.9146137640111995\n",
      "train loss:0.8236598080609353\n",
      "train loss:0.8346054264904074\n",
      "train loss:0.9545489107811617\n",
      "train loss:1.0106801596453756\n",
      "train loss:1.0231280504741327\n",
      "train loss:0.8763880693090025\n",
      "train loss:1.0607181372086965\n",
      "train loss:0.8787550063449008\n",
      "train loss:0.8005966859511185\n",
      "train loss:0.9129570900245016\n",
      "train loss:0.8770824582775143\n",
      "train loss:0.940780788920869\n",
      "train loss:0.7860775430519595\n",
      "train loss:0.796720884769889\n",
      "train loss:0.956752913905378\n",
      "train loss:0.9959694456685532\n",
      "train loss:0.7529088124148583\n",
      "train loss:0.9524145835846168\n",
      "train loss:1.0038524813319913\n",
      "train loss:0.9062515465363508\n",
      "train loss:0.9464098722514303\n",
      "train loss:0.9520596310715933\n",
      "train loss:0.7674807712425127\n",
      "train loss:1.0267431448096462\n",
      "train loss:0.9494336859592568\n",
      "train loss:0.9129532092219873\n",
      "train loss:0.9158662731214158\n",
      "train loss:0.8584635318413093\n",
      "train loss:0.8096314669862167\n",
      "train loss:0.9238053141626623\n",
      "train loss:1.0000606809377879\n",
      "train loss:0.8661645629325992\n",
      "train loss:1.1724168917086142\n",
      "train loss:0.7804462738259228\n",
      "train loss:0.7438596258469525\n",
      "train loss:1.09058205892346\n",
      "train loss:0.9313835823942853\n",
      "train loss:0.7652817482258155\n",
      "train loss:1.0043111463322567\n",
      "train loss:0.828544701712625\n",
      "train loss:1.0230347719769943\n",
      "train loss:1.1671615469476295\n",
      "train loss:0.9338827898581792\n",
      "train loss:1.0831573708416706\n",
      "train loss:0.9015786702978249\n",
      "train loss:0.8337193863217014\n",
      "train loss:0.8455949006529542\n",
      "train loss:0.9064824101294624\n",
      "train loss:0.9784218722519831\n",
      "train loss:0.907601918961204\n",
      "train loss:0.9623324490372082\n",
      "train loss:0.9064800975171898\n",
      "train loss:0.9538050022720589\n",
      "train loss:0.8261502296063782\n",
      "train loss:0.9142444142286369\n",
      "train loss:0.9252329922789209\n",
      "train loss:0.79475884477342\n",
      "train loss:0.7346315388921496\n",
      "train loss:1.0852617847315442\n",
      "train loss:0.7518467280152764\n",
      "train loss:0.9441602965031088\n",
      "train loss:0.7539531471235976\n",
      "train loss:0.9373168173498204\n",
      "train loss:0.8006583118793072\n",
      "train loss:0.919262485890583\n",
      "train loss:1.059332586903609\n",
      "train loss:0.7435804090719063\n",
      "train loss:0.8085576240044112\n",
      "train loss:0.8779735250934693\n",
      "train loss:1.0705955262024505\n",
      "train loss:0.8768197118703921\n",
      "train loss:0.6933047356850295\n",
      "train loss:0.8025823943675681\n",
      "train loss:0.6870786196134645\n",
      "train loss:0.9326822843549095\n",
      "train loss:0.8894489513610104\n",
      "train loss:0.9261861286727785\n",
      "train loss:0.9534227196538981\n",
      "train loss:0.8509329457360845\n",
      "train loss:0.8498842268550305\n",
      "train loss:0.9071166009646373\n",
      "train loss:0.8475146320741951\n",
      "train loss:0.8609987674853289\n",
      "train loss:1.0016848394007314\n",
      "train loss:0.9834465008063971\n",
      "train loss:0.9339533530370282\n",
      "train loss:0.7914054932027228\n",
      "train loss:1.065093712498844\n",
      "train loss:0.8864446642168873\n",
      "train loss:0.9200726398552329\n",
      "train loss:1.0650789152756515\n",
      "train loss:0.9139544936812045\n",
      "train loss:0.9875910464058593\n",
      "train loss:0.8302528942479571\n",
      "train loss:0.8943936754913062\n",
      "train loss:0.8361662543794425\n",
      "train loss:0.8301127873478369\n",
      "train loss:0.9478359289235021\n",
      "train loss:0.7735607617881599\n",
      "train loss:0.9523260573311656\n",
      "train loss:1.0790984308006797\n",
      "train loss:0.8822516702704332\n",
      "train loss:0.9352406672373357\n",
      "train loss:1.1668966064139552\n",
      "train loss:0.9696251105467512\n",
      "train loss:0.9184341358879606\n",
      "train loss:0.760875637536277\n",
      "train loss:0.8628025999825192\n",
      "train loss:0.8327592952571728\n",
      "train loss:0.8659217368679321\n",
      "train loss:0.7914722135068375\n",
      "=== epoch:20, train acc:0.991, test acc:0.993 ===\n",
      "train loss:0.8473342945367037\n",
      "train loss:0.8621073001925109\n",
      "train loss:0.7526351627573608\n",
      "train loss:1.111964920720502\n",
      "train loss:0.9045482933587814\n",
      "train loss:0.8864958776397454\n",
      "train loss:0.88224874340242\n",
      "train loss:0.7434019783745878\n",
      "train loss:0.9011625599124374\n",
      "train loss:0.8791671229917859\n",
      "train loss:0.8158362795377185\n",
      "train loss:0.9177918212060573\n",
      "train loss:0.9720848381402046\n",
      "train loss:0.8874942484110929\n",
      "train loss:0.6618846713375511\n",
      "train loss:0.9663945692414204\n",
      "train loss:0.754415950118574\n",
      "train loss:0.8438666969868013\n",
      "train loss:0.8928725130137727\n",
      "train loss:0.9051197525334008\n",
      "train loss:0.9434307996939539\n",
      "train loss:0.843475266811122\n",
      "train loss:0.9476153305544847\n",
      "train loss:0.9075583268060337\n",
      "train loss:0.9507933421952319\n",
      "train loss:0.9726723118648841\n",
      "train loss:0.8745562596894664\n",
      "train loss:0.9557381566827661\n",
      "train loss:0.7277266038020502\n",
      "train loss:0.9759317869257815\n",
      "train loss:0.8670539892347914\n",
      "train loss:1.0059251202061346\n",
      "train loss:0.9623485336582257\n",
      "train loss:0.898897434190649\n",
      "train loss:1.0846520602035088\n",
      "train loss:1.117850721323543\n",
      "train loss:0.9169767117811591\n",
      "train loss:0.9051989083460142\n",
      "train loss:0.839798998163133\n",
      "train loss:0.8959593707050968\n",
      "train loss:0.9459091618112023\n",
      "train loss:0.9758821705969943\n",
      "train loss:0.941090579479372\n",
      "train loss:0.8113565779441104\n",
      "train loss:0.8482577202954339\n",
      "train loss:0.9610794027610272\n",
      "train loss:0.990306129524048\n",
      "train loss:0.8775140853152501\n",
      "train loss:0.8769405467625246\n",
      "train loss:0.8160237800152941\n",
      "train loss:0.9508804706492913\n",
      "train loss:0.8853354841065246\n",
      "train loss:0.804024746750505\n",
      "train loss:0.8107449646050786\n",
      "train loss:0.8979529809268889\n",
      "train loss:0.7515819112199249\n",
      "train loss:0.8932719245424052\n",
      "train loss:0.7785003526283779\n",
      "train loss:1.0176729810463405\n",
      "train loss:0.8226835514687313\n",
      "train loss:0.8035847083154877\n",
      "train loss:0.9340676478109975\n",
      "train loss:0.9249143459125357\n",
      "train loss:0.8192650843861113\n",
      "train loss:0.9368004449874886\n",
      "train loss:0.7705228124271691\n",
      "train loss:0.8734888637678627\n",
      "train loss:0.9735401554971442\n",
      "train loss:0.9668243397972528\n",
      "train loss:0.8852575541631915\n",
      "train loss:1.0230935964625152\n",
      "train loss:0.7082626538814023\n",
      "train loss:0.9640932179155164\n",
      "train loss:0.823094860825496\n",
      "train loss:0.9119622615620715\n",
      "train loss:0.9020820148403124\n",
      "train loss:0.9302265598118123\n",
      "train loss:0.848020715699034\n",
      "train loss:0.7862403608176304\n",
      "train loss:0.9240124860656771\n",
      "train loss:0.8877862073924087\n",
      "train loss:0.9897280112938269\n",
      "train loss:0.9483576288510385\n",
      "train loss:0.963392150349469\n",
      "train loss:0.9124157003836558\n",
      "train loss:0.7280350778290212\n",
      "train loss:0.8616322085144605\n",
      "train loss:0.8649106203670042\n",
      "train loss:0.8320003211170068\n",
      "train loss:0.7565965492988527\n",
      "train loss:0.8241227694170311\n",
      "train loss:0.9879692329750731\n",
      "train loss:0.793223246179648\n",
      "train loss:0.8565783728177983\n",
      "train loss:0.9287105638634217\n",
      "train loss:0.9129106900802298\n",
      "train loss:0.9392918793424907\n",
      "train loss:0.9437484479459244\n",
      "train loss:0.8684942122205801\n",
      "train loss:0.8164159180649277\n",
      "train loss:0.9852504821502351\n",
      "train loss:0.953139719893327\n",
      "train loss:0.8089063775827888\n",
      "train loss:0.6850359685532293\n",
      "train loss:0.9401119201156923\n",
      "train loss:0.8365165054978873\n",
      "train loss:0.6816513106068908\n",
      "train loss:1.0050146880397286\n",
      "train loss:1.035187010656189\n",
      "train loss:1.0570351435893732\n",
      "train loss:0.8476384397787007\n",
      "train loss:0.9503571233614051\n",
      "train loss:1.0501000709400536\n",
      "train loss:0.8545826989459308\n",
      "train loss:1.0257162506169097\n",
      "train loss:0.8921590139149211\n",
      "train loss:0.7988054176608422\n",
      "train loss:0.8765558964685942\n",
      "train loss:0.9537694815737515\n",
      "train loss:0.8363379913921568\n",
      "train loss:0.7924046614801061\n",
      "train loss:1.1273108272662737\n",
      "train loss:0.8285440624979904\n",
      "train loss:0.7277752619491199\n",
      "train loss:0.8400004664722504\n",
      "train loss:0.9180867700667396\n",
      "train loss:0.7836166225195353\n",
      "train loss:0.881811227559287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9994429672998435\n",
      "train loss:1.0704113460924294\n",
      "train loss:0.9498942705597783\n",
      "train loss:1.0443532663013402\n",
      "train loss:0.8045918315005387\n",
      "train loss:0.9532263418577039\n",
      "train loss:1.0367949745373246\n",
      "train loss:0.9747955912990187\n",
      "train loss:0.6588891882964671\n",
      "train loss:0.8183901741462022\n",
      "train loss:0.7985467583814363\n",
      "train loss:0.9972798881329232\n",
      "train loss:0.9034753340501845\n",
      "train loss:0.915352620737475\n",
      "train loss:0.9405682743477414\n",
      "train loss:0.8579521721260867\n",
      "train loss:0.8448001190573896\n",
      "train loss:1.0961914674478952\n",
      "train loss:0.7612910460441756\n",
      "train loss:0.8251604409639208\n",
      "train loss:0.9327885446272235\n",
      "train loss:0.8408470031737678\n",
      "train loss:0.9458926865054655\n",
      "train loss:0.9958629172208766\n",
      "train loss:1.0477655877057042\n",
      "train loss:1.1259966087953164\n",
      "train loss:0.9547028020423879\n",
      "train loss:0.8870826847334466\n",
      "train loss:1.0221667751344174\n",
      "train loss:0.8998965503668884\n",
      "train loss:0.8771649583496098\n",
      "train loss:0.8506935938932173\n",
      "train loss:0.9463308867751984\n",
      "train loss:0.9134017634401814\n",
      "train loss:0.9031213147217828\n",
      "train loss:0.8614844185052088\n",
      "train loss:1.0085850193167742\n",
      "train loss:0.8671827469606646\n",
      "train loss:1.0139915707082745\n",
      "train loss:0.952039468082222\n",
      "train loss:0.9709390776183655\n",
      "train loss:0.885727326088076\n",
      "train loss:0.8732072374651593\n",
      "train loss:0.8816829408941212\n",
      "train loss:0.9569069088671407\n",
      "train loss:0.8305622612840987\n",
      "train loss:0.8700998156248844\n",
      "train loss:0.9911715502298155\n",
      "train loss:0.9613359774939751\n",
      "train loss:1.0292492165056564\n",
      "train loss:0.9306480070477419\n",
      "train loss:0.7787618190286411\n",
      "train loss:0.9332935635747449\n",
      "train loss:0.9476878999924051\n",
      "train loss:1.0812016701676663\n",
      "train loss:0.8669506271047485\n",
      "train loss:0.8688931590385081\n",
      "train loss:0.9624285677267078\n",
      "train loss:0.9723850695174857\n",
      "train loss:0.9024380583461228\n",
      "train loss:0.9713386349998667\n",
      "train loss:1.0221304137008735\n",
      "train loss:0.8071571254499509\n",
      "train loss:0.9846731684008083\n",
      "train loss:1.1382901302757842\n",
      "train loss:0.7639455101884106\n",
      "train loss:1.0135072410337254\n",
      "train loss:0.8216889650040551\n",
      "train loss:0.8066977009725609\n",
      "train loss:1.0387739883227318\n",
      "train loss:1.0230978413453349\n",
      "train loss:0.9685321017404723\n",
      "train loss:0.7605430459323541\n",
      "train loss:0.7698143743565165\n",
      "train loss:0.8988506877418289\n",
      "train loss:0.9076299382627571\n",
      "train loss:0.8878296199131964\n",
      "train loss:0.9826590374653874\n",
      "train loss:0.8216642348446794\n",
      "train loss:1.0233395688943216\n",
      "train loss:0.8975719048847407\n",
      "train loss:0.9653413948311232\n",
      "train loss:0.984268365676522\n",
      "train loss:1.0015317977700082\n",
      "train loss:0.7971644749838283\n",
      "train loss:1.1064696827909613\n",
      "train loss:1.0775042379865063\n",
      "train loss:0.7803955534151497\n",
      "train loss:0.8248175105015576\n",
      "train loss:0.8526789551168357\n",
      "train loss:0.8589886810286639\n",
      "train loss:1.124700751353952\n",
      "train loss:0.8769836985948183\n",
      "train loss:0.8636477424031707\n",
      "train loss:0.9667531581917594\n",
      "train loss:0.9666494282720466\n",
      "train loss:1.1284598810824122\n",
      "train loss:1.0080619026541122\n",
      "train loss:0.9304925186052185\n",
      "train loss:0.971876597083073\n",
      "train loss:0.6793814822893149\n",
      "train loss:0.9720602109427151\n",
      "train loss:0.8985401319602475\n",
      "train loss:1.0176261995746456\n",
      "train loss:0.8130373599407211\n",
      "train loss:0.9407089640313165\n",
      "train loss:0.8446890380908058\n",
      "train loss:0.7786370646094426\n",
      "train loss:0.7680744346353541\n",
      "train loss:0.7993847162364094\n",
      "train loss:0.9460906980753763\n",
      "train loss:1.017065887556913\n",
      "train loss:0.9332586689831609\n",
      "train loss:0.8156229219214697\n",
      "train loss:0.8079931771760814\n",
      "train loss:0.9254311932926136\n",
      "train loss:0.7898977691704994\n",
      "train loss:1.0237813131997582\n",
      "train loss:0.7284919762863198\n",
      "train loss:1.013549885068597\n",
      "train loss:0.8065486854988714\n",
      "train loss:1.074666988875409\n",
      "train loss:0.7550684307032323\n",
      "train loss:0.9489422075308904\n",
      "train loss:0.8700781198831629\n",
      "train loss:0.8751383336862176\n",
      "train loss:0.905157800978765\n",
      "train loss:0.845623732138897\n",
      "train loss:0.8031211809859721\n",
      "train loss:0.7743288342225912\n",
      "train loss:0.8640003293765528\n",
      "train loss:1.0125118125209476\n",
      "train loss:0.7424251126601863\n",
      "train loss:0.8465611782712102\n",
      "train loss:0.9592512285680556\n",
      "train loss:0.8766660869354352\n",
      "train loss:0.8793317107622424\n",
      "train loss:0.8185914535019815\n",
      "train loss:1.0077628670364698\n",
      "train loss:0.8889163271233411\n",
      "train loss:0.8452985986690547\n",
      "train loss:0.934657408402066\n",
      "train loss:0.9492270964160836\n",
      "train loss:1.0064587202154078\n",
      "train loss:0.9880319120782894\n",
      "train loss:0.9747265758127699\n",
      "train loss:0.8812136452891626\n",
      "train loss:0.9588020028279293\n",
      "train loss:0.8717855209831269\n",
      "train loss:0.8260621212334194\n",
      "train loss:0.7491178216175426\n",
      "train loss:0.7884901985450429\n",
      "train loss:1.0829205706046323\n",
      "train loss:0.9011624724745397\n",
      "train loss:0.8746633561208984\n",
      "train loss:0.8727199067524332\n",
      "train loss:0.9491367065681742\n",
      "train loss:0.8576514608043208\n",
      "train loss:0.8511441420198314\n",
      "train loss:0.8793987036873538\n",
      "train loss:1.0573590042382803\n",
      "train loss:0.9511294877127893\n",
      "train loss:0.8937713110162301\n",
      "train loss:0.8703167315275315\n",
      "train loss:0.9744197576134453\n",
      "train loss:1.0268697200385113\n",
      "train loss:0.5946707702814407\n",
      "train loss:0.958981577886729\n",
      "train loss:0.7135950481342066\n",
      "train loss:0.9025107338659172\n",
      "train loss:0.9693936872747357\n",
      "train loss:1.0928596912244073\n",
      "train loss:0.9140127949017771\n",
      "train loss:0.8355924372177549\n",
      "train loss:0.6847189249385214\n",
      "train loss:0.983178244735895\n",
      "train loss:1.0158241429823285\n",
      "train loss:0.7912059268761236\n",
      "train loss:0.8465019977450216\n",
      "train loss:0.7943078545461055\n",
      "train loss:1.001989649771728\n",
      "train loss:0.8202882287842153\n",
      "train loss:1.121788677158646\n",
      "train loss:0.9818237370873436\n",
      "train loss:0.861456662830435\n",
      "train loss:1.0201405710112064\n",
      "train loss:1.0180067709305076\n",
      "train loss:1.0576163311253262\n",
      "train loss:0.9035123323129142\n",
      "train loss:0.8408180781195951\n",
      "train loss:0.9829945457232457\n",
      "train loss:1.1267509049670004\n",
      "train loss:1.0360276849326007\n",
      "train loss:0.9998604855140241\n",
      "train loss:0.9415607996199856\n",
      "train loss:1.0539766237883479\n",
      "train loss:0.9092101745029325\n",
      "train loss:0.8246743071491163\n",
      "train loss:0.8848606762339613\n",
      "train loss:0.9125346918786422\n",
      "train loss:0.9648007634809046\n",
      "train loss:0.8316378361512635\n",
      "train loss:0.9593558356670738\n",
      "train loss:0.9455125272121572\n",
      "train loss:1.0316579446313054\n",
      "train loss:0.8886174652458767\n",
      "train loss:0.8095899144400588\n",
      "train loss:0.8818401064252929\n",
      "train loss:1.0054540213052312\n",
      "train loss:0.8752189306625199\n",
      "train loss:0.9587504447075679\n",
      "train loss:0.9132543640559434\n",
      "train loss:0.8275067419418548\n",
      "train loss:0.9747445553472625\n",
      "train loss:1.006574966287697\n",
      "train loss:0.9653312050478715\n",
      "train loss:1.0396226635773596\n",
      "train loss:0.9418291792623609\n",
      "train loss:0.8245601820877806\n",
      "train loss:0.9585914307764658\n",
      "train loss:1.036144161474188\n",
      "train loss:0.8482517984526738\n",
      "train loss:0.675021039158942\n",
      "train loss:0.8517555432804953\n",
      "train loss:0.8364077754136037\n",
      "train loss:0.796837014520965\n",
      "train loss:0.8138590214344849\n",
      "train loss:0.8653098973082962\n",
      "train loss:0.872897939732433\n",
      "train loss:0.8715725776588436\n",
      "train loss:0.9140230673817332\n",
      "train loss:0.9460086351234771\n",
      "train loss:0.9443822389308585\n",
      "train loss:0.9271572498448967\n",
      "train loss:0.7630271660811846\n",
      "train loss:1.0548066961620284\n",
      "train loss:1.0170211705909133\n",
      "train loss:0.8860402916994322\n",
      "train loss:1.037917131201588\n",
      "train loss:0.8411540829142341\n",
      "train loss:0.8596033517165315\n",
      "train loss:0.722367590923895\n",
      "train loss:0.8492750513620122\n",
      "train loss:0.8800552719290912\n",
      "train loss:0.9557267418515947\n",
      "train loss:0.9579383693324671\n",
      "train loss:1.0081005404589636\n",
      "train loss:0.8973487934311725\n",
      "train loss:0.8267063349667452\n",
      "train loss:0.8621027349260273\n",
      "train loss:1.0703357682269492\n",
      "train loss:0.8518422624659734\n",
      "train loss:0.9709309542159086\n",
      "train loss:0.9018375484691219\n",
      "train loss:0.9754638158910385\n",
      "train loss:0.930260402941377\n",
      "train loss:0.8435107437281338\n",
      "train loss:0.9835108155714894\n",
      "train loss:0.8936078362340019\n",
      "train loss:1.0348451107102477\n",
      "train loss:0.7757758119963212\n",
      "train loss:0.7691408339864033\n",
      "train loss:0.909580506213304\n",
      "train loss:0.9942757119940769\n",
      "train loss:0.8453040041356349\n",
      "train loss:0.8298741226628351\n",
      "train loss:0.9781465348793578\n",
      "train loss:1.0928748405977102\n",
      "train loss:0.717856414121952\n",
      "train loss:0.7699383063670918\n",
      "train loss:0.8976064318812312\n",
      "train loss:0.9500715301179359\n",
      "train loss:0.8471552586767863\n",
      "train loss:0.8593054284856028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8508391744914282\n",
      "train loss:0.9625645279297576\n",
      "train loss:0.8995111572585331\n",
      "train loss:0.8961106282286768\n",
      "train loss:0.9848277978916358\n",
      "train loss:1.1815975025395908\n",
      "train loss:0.8397410223016444\n",
      "train loss:0.905524509050707\n",
      "train loss:1.0136644135932817\n",
      "train loss:1.0530288649285584\n",
      "train loss:0.9542575543056558\n",
      "train loss:0.957708112599443\n",
      "train loss:0.863538557173652\n",
      "train loss:0.8054893145427141\n",
      "train loss:0.9344866868382938\n",
      "train loss:0.9848997219195534\n",
      "train loss:0.828177818347482\n",
      "train loss:0.981274944048757\n",
      "train loss:0.7510572028640086\n",
      "train loss:1.0459680674405287\n",
      "train loss:0.7308137552232743\n",
      "train loss:0.8969009834658802\n",
      "train loss:0.9931571741029964\n",
      "train loss:0.8653752763046064\n",
      "train loss:1.145807441991632\n",
      "train loss:0.8960099638885994\n",
      "train loss:0.8845029536708505\n",
      "train loss:0.807496710547386\n",
      "train loss:0.9691474379563024\n",
      "train loss:1.0292626010373773\n",
      "train loss:0.8162930567841247\n",
      "train loss:0.8686698822664334\n",
      "train loss:0.7931396582773799\n",
      "train loss:0.9916714181138169\n",
      "train loss:1.0266705486106535\n",
      "train loss:0.738768214598862\n",
      "train loss:0.9845212335328237\n",
      "train loss:0.9542939620998909\n",
      "train loss:0.8011956755178788\n",
      "train loss:0.8476225069943879\n",
      "train loss:0.8564897558467837\n",
      "train loss:0.7808236897466524\n",
      "train loss:0.9120231447787275\n",
      "train loss:0.8899326427352936\n",
      "train loss:0.9511548845444361\n",
      "train loss:0.8939902387166556\n",
      "train loss:0.7747406495515324\n",
      "train loss:0.9040305565139083\n",
      "train loss:0.8119718228300485\n",
      "train loss:0.9346323116690253\n",
      "train loss:0.9216155077184129\n",
      "train loss:0.7783535611498068\n",
      "train loss:0.8896576956992271\n",
      "train loss:0.9403847690626851\n",
      "train loss:0.8784671040638328\n",
      "train loss:1.008475657901282\n",
      "train loss:0.9293813869995148\n",
      "train loss:0.7592193147200227\n",
      "train loss:1.1085343676361967\n",
      "train loss:0.8092793998903693\n",
      "train loss:0.8276079909443399\n",
      "train loss:0.8098141136039689\n",
      "train loss:0.8167202485882143\n",
      "train loss:0.8778544770978673\n",
      "train loss:0.8790405796978747\n",
      "train loss:0.6934482790489669\n",
      "train loss:1.1111252962138864\n",
      "train loss:0.8700256328764291\n",
      "train loss:0.81508746279872\n",
      "train loss:0.939201086942166\n",
      "train loss:1.0292467721210357\n",
      "train loss:1.0070454849022916\n",
      "train loss:1.0370799967155688\n",
      "train loss:1.031003529305637\n",
      "train loss:0.9258758293008786\n",
      "train loss:0.775502324119573\n",
      "train loss:1.0741519873178955\n",
      "train loss:0.9446909287009779\n",
      "train loss:0.9454527483740063\n",
      "train loss:0.8727123017377494\n",
      "train loss:0.8486914848871727\n",
      "train loss:0.9453346533852176\n",
      "train loss:0.8135150771093855\n",
      "train loss:0.9589755167959743\n",
      "train loss:0.8581984173231657\n",
      "train loss:0.9242332187370552\n",
      "train loss:0.7645219125962173\n",
      "train loss:1.0231802265684464\n",
      "train loss:0.8490137420148482\n",
      "train loss:0.7936789953521965\n",
      "train loss:0.8833437347819537\n",
      "train loss:0.8834348066305142\n",
      "train loss:1.0074518580277514\n",
      "train loss:0.9651441497861185\n",
      "train loss:0.9113272008259276\n",
      "train loss:0.8214860309252556\n",
      "train loss:1.0641408926390605\n",
      "train loss:0.9417007390673136\n",
      "train loss:0.8533046150797304\n",
      "train loss:0.822512654633832\n",
      "train loss:0.9184168259659198\n",
      "train loss:0.9037630705677081\n",
      "train loss:0.8406476789194012\n",
      "train loss:0.8784955564010172\n",
      "train loss:0.823063202101507\n",
      "train loss:0.9200877193874013\n",
      "train loss:0.8425066789918033\n",
      "train loss:0.7846273371733035\n",
      "train loss:0.9594076086419348\n",
      "train loss:0.9825793059136394\n",
      "train loss:0.9328149974529467\n",
      "train loss:0.8740856189779943\n",
      "train loss:0.8807395814264218\n",
      "train loss:0.9042305499982675\n",
      "train loss:0.9493881428173105\n",
      "train loss:0.8163185933655045\n",
      "train loss:0.8862189497559761\n",
      "train loss:0.8112078796365809\n",
      "train loss:0.8234332736819645\n",
      "train loss:0.8913846840442241\n",
      "train loss:0.9760581262196909\n",
      "train loss:0.914182365133942\n",
      "train loss:0.9989848211412534\n",
      "train loss:0.8564878220883891\n",
      "train loss:0.9467849947017574\n",
      "train loss:0.9162504236773436\n",
      "train loss:0.7940057788374842\n",
      "train loss:0.8484318166503519\n",
      "train loss:0.9014887711777179\n",
      "train loss:0.8866018265667954\n",
      "train loss:0.8296000733493913\n",
      "train loss:0.949481121504401\n",
      "train loss:0.8937609390260784\n",
      "train loss:0.884399500164748\n",
      "train loss:0.7198586859586088\n",
      "train loss:0.9920535180004407\n",
      "train loss:0.9907065703903425\n",
      "train loss:0.8603457764698864\n",
      "train loss:0.8949090268071075\n",
      "train loss:0.9414332554913432\n",
      "train loss:1.0275849679433886\n",
      "train loss:0.8345362314644101\n",
      "train loss:0.847187693005551\n",
      "train loss:0.858648171021412\n",
      "train loss:0.9678270847447041\n",
      "train loss:0.7568627792255179\n",
      "train loss:1.070786877379261\n",
      "train loss:1.0369036523855035\n",
      "train loss:1.0465570296224374\n",
      "train loss:0.9314471778821081\n",
      "train loss:0.9983029785332961\n",
      "train loss:0.8881246606712654\n",
      "train loss:0.978382301565249\n",
      "train loss:0.9576081682876689\n",
      "train loss:0.8553950089887441\n",
      "train loss:1.0860473648723556\n",
      "train loss:0.8290596925240117\n",
      "train loss:0.993771360692924\n",
      "train loss:0.8099933309862061\n",
      "train loss:0.8726711483258014\n",
      "train loss:0.9078258377624365\n",
      "train loss:0.7784157516467984\n",
      "train loss:0.8291185139346529\n",
      "train loss:0.9321788266147821\n",
      "train loss:0.882423599528066\n",
      "train loss:0.8707950825119544\n",
      "train loss:0.9107207511473502\n",
      "train loss:0.7950372900093841\n",
      "train loss:0.8410391852031555\n",
      "train loss:1.037069927365751\n",
      "train loss:0.8693032422259336\n",
      "train loss:0.8435090897713841\n",
      "train loss:0.8572962693422234\n",
      "train loss:0.974988848249465\n",
      "train loss:1.1900135723572098\n",
      "train loss:0.7280182262557469\n",
      "train loss:0.961324017679682\n",
      "train loss:0.8137197340624515\n",
      "train loss:0.8207103793422423\n",
      "train loss:1.0514497858367886\n",
      "train loss:0.9875574451007416\n",
      "train loss:0.9568125269532106\n",
      "train loss:1.0518282323612438\n",
      "train loss:0.8804000182465437\n",
      "train loss:0.9200438985051459\n",
      "train loss:0.8666165469324152\n",
      "train loss:1.0269161586456648\n",
      "train loss:0.9590077079039752\n",
      "train loss:0.8728895212522607\n",
      "train loss:0.9632738165475849\n",
      "train loss:0.7513345477173371\n",
      "train loss:0.7184981740491981\n",
      "train loss:1.0866367243083532\n",
      "train loss:0.8371618270102857\n",
      "train loss:0.8659912064569995\n",
      "train loss:0.6831871901741693\n",
      "train loss:0.8434669027051035\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9913\n"
     ]
    }
   ],
   "source": [
    "network = DeepConvNet()\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test, epochs=20, mini_batch_size=100, optimizer='Adam',\n",
    "       optimizer_param={'lr': 0.0001}, evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae37b04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71b39441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "844d7e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = DeepConvNet()\n",
    "network.load_params(\"deep_convnet_params.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "87abb4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled = 10000\n",
    "x_test = x_test[:sampled]\n",
    "t_test = t_test[:sampled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9fe2bf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caluculate accuracy (float64) ... \n",
      "0.9935\n"
     ]
    }
   ],
   "source": [
    "print(\"caluculate accuracy (float64) ... \")\n",
    "print(network.accuracy(x_test, t_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "98a8cf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.astype(np.float16)\n",
    "for param in network.params.values():\n",
    "    param[...] = param.astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "744dd87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caluculate accuracy (float16) ... \n",
      "0.9935\n"
     ]
    }
   ],
   "source": [
    "print(\"caluculate accuracy (float16) ... \")\n",
    "print(network.accuracy(x_test, t_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47904c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
